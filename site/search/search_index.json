{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Herakleitos","text":"<p>Thales is a Python toolkit for EDA, causal inference (DoWhy/EconML, CausalPy), time series (Prophet), SHAP interpretability, GeoLift, A/B testing, association rules, and more.</p> <ul> <li>See Guides for task-oriented how-tos.</li> <li>See API for auto-generated reference.</li> </ul>"},{"location":"api/herakleitos/","title":"Herakleitos API","text":"Source code in <code>src/thales/herakleitos.py</code> <pre><code>@dataclass\nclass Herakleitos:\n    df_raw: pd.DataFrame\n    chat_model: Any\n    user_id: str\n    memory: Optional[Any] = None\n    eda_cleaned_df: Optional[pd.DataFrame] = None\n    causal_cleaned_df: Optional[pd.DataFrame] = None\n    ts_cleaned_df: Optional[pd.DataFrame] = None\n    console: Console = field(default_factory=Console)\n    checkpointer: Any = field(default_factory=InMemorySaver)\n    def __post_init__(self):\n        \"\"\"Clean and stage raw data on class instantiation.\n\n            Prepares datasets for downstream EDA, causal inference, and time-series analysis\n            (e.g., type coercions, missing-value handling, feature filtering).\n\n            Side Effects:\n                Populates cleaned data attributes (e.g., ``self.eda_cleaned_df``, ``self.ts_cleaned_df``,\n                ``self.causal_cleaned_df``).\n            \"\"\"\n        pandas2ri.activate()\n\n        # ---------- EDA Cleaning ----------\n        if self.eda_cleaned_df is None:\n            print(\"\ud83d\udd39 Cleaning Data For EDA:\")\n            df_eda_target = self.df_raw.copy()\n\n            dict_or_list_cols = [\n                col for col in df_eda_target.columns\n                if df_eda_target[col].apply(lambda x: isinstance(x, (dict, list))).any()\n            ]\n\n            safe_df = df_eda_target.drop(columns=dict_or_list_cols)\n            #convert numeric\n            safe_df = auto_convert_numeric(safe_df)\n            eda_cleaned = cleaningData(safe_df)\n            eda_cleaned = pandas2ri.rpy2py_dataframe(eda_cleaned)\n\n            dict_data = df_eda_target[dict_or_list_cols]\n            flattened = flatten_columns(dict_data, drop_original=False)\n\n            self.eda_cleaned_df = pd.concat([\n                eda_cleaned.reset_index(drop=True),\n                flattened.reset_index(drop=True)\n            ], axis=1)\n\n            print(\"\u2705 EDA data is converted...\")\n\n        # ---------- Causal Cleaning ----------\n        if self.causal_cleaned_df is None:\n            print(\"\ud83d\udd39 Cleaning Data For Causal:\")\n            df_causal_target = self.df_raw.copy()\n\n            dict_or_list_cols = [\n                col for col in df_causal_target.columns\n                if df_causal_target[col].apply(lambda x: isinstance(x, (dict, list))).any()\n            ]\n\n            safe_df = df_causal_target.drop(columns=dict_or_list_cols)\n            safe_df = auto_convert_numeric(safe_df)\n\n            causal_cleaned,*_ = full_data_cleaning(safe_df)\n\n            dict_data = df_causal_target[dict_or_list_cols]\n            flattened = flatten_columns(dict_data, drop_original=False)\n\n            self.causal_cleaned_df = pd.concat([\n                causal_cleaned.reset_index(drop=True),\n                flattened.reset_index(drop=True)\n            ], axis=1)\n\n            print(\"\u2705 Causal data is converted...\")\n\n        if self.ts_cleaned_df is None:\n            print(\"\ud83d\udd39 Cleaning Data For Time Series:\")\n            df_ts_target = self.df_raw.copy()\n\n            dict_or_list_cols = [\n                col for col in df_ts_target.columns\n                if df_ts_target[col].apply(lambda x: isinstance(x, (dict, list))).any()\n            ]\n\n            ts_safe_df = df_ts_target.drop(columns=dict_or_list_cols)\n            ts_safe_df = auto_convert_numeric(safe_df)\n            imputer = SmartImputer(strategy=\"auto\")\n            num_cols = ts_safe_df.select_dtypes(include=[np.number]).columns.tolist()\n            for col in num_cols:\n                ts_safe_df = imputer.impute_campaign_summary(ts_safe_df, target_column=col)\n\n\n            self.ts_cleaned_df = ts_safe_df.copy()\n\n            print(\"\u2705 Time Series data is converted...\")\n\n        # ---------- df_raw Flatten ----------\n        self.df_raw = flatten_columns(self.df_raw)\n\n        # ---------- Memory ----------\n        if self.memory:\n            print(\"\ud83d\udcbe Saving cleaned data to memory...\")\n            self._save_context_to_memory(\"eda\")\n            self._save_context_to_memory(\"causal\")\n            self._save_context_to_memory(\"ts\")\n\n\n    def _save_context_to_memory(self, query_type: str):\n        \"\"\"Persist cleaned data context in memory for agent pipelines.\n\n            Args:\n                query_type: One of ``{\"eda\", \"causal\", \"ts\"}`` to select which cleaned view\n                    should be cached and reused by agents.\n\n            Side Effects:\n                Updates in-memory stores/checkpointer for subsequent agent calls.\n            \"\"\"\n        if query_type == \"eda\":\n            df = self.eda_cleaned_df\n        elif query_type == \"causal\":\n            df = self.causal_cleaned_df\n        else:\n            df = self.ts_cleaned_df\n        df_copy = df.copy()\n\n        for col in df_copy.select_dtypes(include=[\"datetime64\"]).columns:\n            df_copy[col] = df_copy[col].astype(str)\n\n        self.memory.save_context(\n            {\"input\": f\"{query_type.capitalize()} Data\"},\n            {\"output\": json.dumps({\"data\": df_copy.to_dict(orient='list'), \"date_col\": \"date\"})}\n        )\n\n    @staticmethod\n    def load_docs_from_file(path: str, source_name: str) -&gt; list[Document]:\n        \"\"\"Load a document from disk and prepare it for vector indexing.\n\n            Args:\n                path: Absolute or relative path to the source document.\n                source_name: Logical source identifier to tag the document with.\n\n            Returns:\n                A normalized document object or list of chunks, ready for embedding/indexing.\n\n            Raises:\n                FileNotFoundError: If ``path`` does not exist.\n                ValueError: If file type is unsupported.\n            \"\"\"\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n        return [Document(page_content=content, metadata={\"source\": source_name})]\n\n    @staticmethod\n    def init_pgvector_retriever(docs, collection_name: str, namespace: str, embeddings_model):\n        \"\"\"Initialize a PgVector-backed retriever.\n\n            Args:\n                docs: Iterable of documents/chunks to index.\n                collection_name: PgVector collection/table name.\n                namespace: Logical namespace to isolate indexes.\n                embeddings_model: Embedding model instance or identifier.\n\n            Returns:\n                A configured retriever object usable by RAG agents.\n            \"\"\"\n        connection = config(\"PGVECTOR_CONNECTION_STRING\")\n\n        vectorstore = PGVector(\n            embeddings=embeddings_model,\n            collection_name=collection_name,\n            connection=connection,\n            use_jsonb=True,\n        )\n\n        record_manager = SQLRecordManager(\n            namespace,\n            db_url=connection,\n        )\n        record_manager.create_schema()\n\n        index(\n            docs,\n            record_manager,\n            vectorstore,\n            cleanup=\"incremental\",\n            source_id_key=\"source\"\n        )\n\n        return vectorstore.as_retriever(search_kwargs={\"k\": 5})\n\n    @staticmethod\n    def init_pg_rag_retriever(\n            agent_name: str,\n            lang: str,\n            file_path: str = None,\n            embedding_model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n    ):\n        \"\"\"Build a complete RAG pipeline (load \u2192 embed \u2192 index \u2192 retrieve).\n\n            Args:\n                agent_name: Identifier for the consumer agent.\n                lang: Language code used for prompt templates (e.g., ``\"tr\"``, ``\"en\"``).\n                file_path: Path of the document to ingest.\n                embedding_model_name: Name or handle of the embedding model.\n\n            Returns:\n                A ready-to-use retriever bound to the ingested corpus.\n            \"\"\"\n        source = f\"{agent_name}_{lang}\"\n        collection = f\"{source}_col\"\n        namespace = f\"{source}_ns\"\n\n        if file_path is None:\n            file_path = f\"services/AI/RAG/texts/{source}.txt\"\n\n        docs = Herakleitos.load_docs_from_file(file_path, source_name=source)\n\n        embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n\n        retriever = Herakleitos.init_pgvector_retriever(\n            docs=docs,\n            collection_name=collection,\n            namespace=namespace,\n            embeddings_model=embeddings\n        )\n\n        return retriever\n\n\n    def generate_prompt(self, query, prompt_tr, prompt_en, lang=\"tr\", **kwargs):\n        \"\"\"Create a chat prompt template from the user query and language.\n\n            Args:\n                query: End-user query in natural language.\n                prompt_tr: Turkish system template string.\n                prompt_en: English system template string.\n                lang: Language selector (``\"tr\"`` or ``\"en\"``).\n                **kwargs: Extra template variables.\n\n            Returns:\n                A ``ChatPromptTemplate`` (or equivalent) ready for the LLM.\n            \"\"\"\n\n        # \ud83d\udccc 1. Sistem rol\u00fc her zaman ayn\u0131\n        system_prompt = SystemMessagePromptTemplate.from_template(\n            \"You are a helpful assistant who answers clearly and with context.\"\n        )\n\n        # \ud83d\udccc 2. Kullan\u0131c\u0131 mesaj\u0131 \u015fablonu se\u00e7ilir\n        human_prompt_template = prompt_tr if lang == \"tr\" else prompt_en\n        human_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n\n        # \ud83d\udccc 3. ChatPromptTemplate olu\u015fturulur\n        chat_prompt = ChatPromptTemplate.from_messages([\n            system_prompt,\n            human_prompt\n        ])\n\n        # \ud83d\udccc 4. input dictionary\u2019yi haz\u0131rla\n        prompt_inputs = {\"query\": query, **kwargs}\n\n        return chat_prompt, prompt_inputs\n\n    async def analyze_single_column(self, column, query):\n        \"\"\"Run deep analysis for a single column using an agent + RAG context.\n\n            Args:\n                column: Target column name in the dataset.\n                query: Natural language question to steer the analysis.\n\n            Yields:\n                Text or Markdown chunks describing insights, tests, and plots.\n            \"\"\"\n        df = self.eda_cleaned_df.copy()\n        time_cols = [col for col in df.columns if \"date\" in col.lower() or \"start\" in col.lower()]\n        if time_cols:\n            date_col = time_cols[0]\n            try:\n                df = df.sort_values(by=date_col)\n                df = df.set_index(date_col)\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Can't convert date column: {e}\")\n\n        # Agent olu\u015ftur\n        python_tool = PythonREPLTool()\n        create_agent = create_pandas_dataframe_agent(\n            llm=self.chat_model,\n            df=df,\n            allow_dangerous_code=True,\n            handle_parsing_errors=True,\n            verbose=True,\n            tools=[python_tool],\n            callbacks=[StreamingStdOutCallbackHandler()]\n        )\n\n        # Agent \u00e7al\u0131\u015ft\u0131r\n        try:\n            response = await create_agent.ainvoke(query)\n            agent_analysis = response.get(\"output\", \"\") if isinstance(response, dict) else str(response)\n            if not agent_analysis.strip():\n                yield \"\u26a0\ufe0f Agent returned empty analysis.\"\n                return\n        except Exception as e:\n            yield f\"\u26a0\ufe0f Agent error: {e}\"\n            return\n\n        # Dil tespiti\n        try:\n            lang = detect(query)\n        except:\n            lang = \"en\"\n\n        # RAG\n        retriever = Herakleitos.init_pg_rag_retriever(agent_name=\"analyze_agent\", lang=lang)\n        try:\n            documents = retriever.get_relevant_documents(query)\n            rag_context = \"\\n\".join([doc.page_content for doc in documents])\n        except Exception as e:\n            rag_context = \"\"\n            print(f\"\u26a0\ufe0f Failed to fetch RAG context: {e}\")\n\n        # Promptlar\n        prompt_en = \"\"\"\n        \ud83c\udfaf **Your Role:** You are a data scientist with access to two inputs:\n\n        \ud83d\udcca **Agent Analysis (focused on column '{column}'):**\n        {agent_analysis}\n\n        \ud83d\udcda **Contextual Knowledge from Domain:**\n        {rag_context}\n\n        \u2753 Based on the above, explain the situation related to '{column}' and the user query: '{query}'.\n        \"\"\".strip()\n\n        prompt_tr = \"\"\"\n        \ud83e\udde0 **Rol\u00fcn:** Bir veri bilimci olarak iki girdiye sahipsiniz:\n\n        \ud83d\udcca **Veriden Elde Edilen Agent Analizi ('{column}' kolonu \u00fczerine):**\n        {agent_analysis}\n\n        \ud83d\udcda **Alan Bilgisinden Gelen Ba\u011flamsal Bilgi:**\n        {rag_context}\n\n        \u2753 Yukar\u0131daki bilgilere g\u00f6re '{column}' kolonu ve '{query}' hakk\u0131nda durumu a\u00e7\u0131klay\u0131n.\n        \"\"\".strip()\n\n        chat_prompt, inputs = self.generate_prompt(\n            query=query,\n            prompt_tr=prompt_tr,\n            prompt_en=prompt_en,\n            lang=lang,\n            column=column,\n            agent_analysis=agent_analysis,\n            rag_context=rag_context\n        )\n\n        chain = chat_prompt | self.chat_model\n\n        async for chunk in chain.astream(inputs):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n\n    async def analyze_agent(self, query):\n        \"\"\"Execute general exploratory analysis with a LangChain-style agent.\n\n            Args:\n                query: Free-form exploratory question across multiple columns/metrics.\n\n            Yields:\n                Streaming analysis outputs (text/Markdown) with referenced visuals.\n            \"\"\"\n        detected_columns = self.extract_columns_from_query(query, self.eda_cleaned_df.columns.tolist())\n\n        if len(detected_columns) &lt; 1:\n            yield \"\u274c Please specify at least one valid column.\"\n            return\n\n        if len(detected_columns) == 1:\n            async for chunk in self.analyze_single_column(detected_columns[0], query):\n                yield chunk\n            return\n\n        df = self.eda_cleaned_df.copy()\n        time_cols = [col for col in df.columns if \"date\" in col.lower() or \"start\" in col.lower()]\n        if time_cols:\n            date_col = time_cols[0]\n            try:\n                df = df.sort_values(by=date_col)\n                df = df.set_index(date_col)\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Can't convert date column: {e}\")\n\n        python_tool = PythonREPLTool()\n\n        agent = create_pandas_dataframe_agent(\n            self.chat_model,\n            df,\n            allow_dangerous_code=True,\n            handle_parsing_errors=True,\n            verbose=True,\n            tools=[python_tool],\n            callbacks=[StreamingStdOutCallbackHandler()]\n        )\n\n        try:\n            response = await agent.ainvoke({\"input\": query})\n            agent_analysis = response.get(\"output\", \"\") if isinstance(response, dict) else str(response)\n            if not agent_analysis.strip():\n                yield \"\u26a0\ufe0f Agent returned empty analysis.\"\n                return\n        except Exception as e:\n            yield f\"\u26a0\ufe0f Error occurred while running agent: {str(e)}\"\n            return\n\n        try:\n            lang = detect(query)\n        except:\n            lang = \"en\"\n\n        retriever = Herakleitos.init_pg_rag_retriever(agent_name=\"analyze_agent\", lang=lang)\n        try:\n            docs = retriever.get_relevant_documents(query)\n            rag_context = \"\\n\".join([doc.page_content for doc in docs])\n        except Exception as e:\n            rag_context = \"\"\n            print(f\"\u26a0\ufe0f Failed to fetch RAG context: {e}\")\n\n        prompt_en = \"\"\"\n        \ud83c\udfaf **Your Role:** You are a data scientist with access to two inputs:\n\n        \ud83d\udcca **Agent Analysis:**\n        {agent_analysis}\n\n        \ud83d\udcda **Contextual Knowledge from Domain:**\n        {rag_context}\n\n        \u2753 Based on the above, explain the situation in light of the user's question: '{query}'.\n        \"\"\".strip()\n\n        prompt_tr = \"\"\"\n        \ud83e\udde0 **Rol\u00fcn:** Bir veri bilimci olarak iki girdiye sahipsiniz:\n\n        \ud83d\udcca **Veriden Elde Edilen Agent Analizi:**\n        {agent_analysis}\n\n        \ud83d\udcda **Alan Bilgisinden Gelen Ba\u011flamsal Bilgi:**\n        {rag_context}\n\n        \u2753 Yukar\u0131daki bilgilere g\u00f6re '{query}' sorusunu yan\u0131tlay\u0131n\u0131z.\n        \"\"\".strip()\n\n        chat_prompt, inputs = self.generate_prompt(\n            query=query,\n            prompt_tr=prompt_tr,\n            prompt_en=prompt_en,\n            lang=lang,\n            agent_analysis=agent_analysis,\n            rag_context=rag_context\n        )\n\n        chain = chat_prompt | self.chat_model\n\n        async for chunk in chain.astream(inputs):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n\n    @traceable\n    async def wiki_agent(self, query):\n        \"\"\"Answer knowledge questions via search tools (Wikipedia/DuckDuckGo/WolframAlpha).\n\n            Args:\n                query: Concept/definition question (e.g., \u201cWhat is CTR?\u201d).\n\n            Yields:\n                Short, sourced explanations suitable for quick reference.\n            \"\"\"\n        if \"WOLFRAM_ALPHA_APPID\" not in os.environ:\n            os.environ[\"WOLFRAM_ALPHA_APPID\"] = config(\"WOLFRAM_ALPHA_APPID\")\n\n\n        wolfram_wrapper = WolframAlphaAPIWrapper()\n        wolfram = WolframAlphaQueryRun(api_wrapper=wolfram_wrapper)\n        wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n        search = DuckDuckGoSearchRun()\n        tools = [search, wikipedia, wolfram]\n\n        tool_node = ToolNode(tools=tools)\n        graph = StateGraph(MessagesState)\n\n\n\n        llm_node = RunnableLambda(\n            lambda state: {\"messages\": state[\"messages\"] + [self.chat_model.invoke(state[\"messages\"])]}\n            )\n\n\n        graph.add_node(\"llm\", llm_node)\n        graph.add_node(\"tools\", tool_node)\n\n        graph.set_entry_point(\"llm\")\n        graph.add_conditional_edges(\"llm\", tools_condition)\n        graph.add_edge(\"tools\", \"llm\")\n        graph.add_edge(\"llm\", END)\n\n        builder = graph.compile(checkpointer=self.checkpointer)\n\n        config = {\n            \"configurable\": {\n                \"thread_id\": self.user_id,\n            }\n        }\n\n\n        input_msg = HumanMessage(content=query)\n\n        try:\n            async for chunk in builder.astream({\"messages\": [input_msg]}, config, stream_mode=\"values\"):\n                latest = chunk[\"messages\"][-1]\n                content = getattr(latest, \"content\", None)\n                if content:\n                    cleaned = content.strip()\n                    if cleaned.lower().startswith(query.lower()):\n                        cleaned = cleaned[len(query):].lstrip(\":\").strip()\n                    yield cleaned\n        except Exception as e:\n            print(\"\u274c Wiki Agent Stream Exception:\", str(e))\n            yield \"\u274c Wikipedia agent stream failed. Please try again later.\"\n\n    async def geo_agent(self, json_path, query):\n        \"\"\"Explain GeoLift power/impact results produced by ``powerAnalysis``.\n\n            Args:\n                json_path: Path to the model summaries JSON.\n                query: User question that frames the interpretation.\n\n            Returns:\n                A natural-language summary of lift, power, and experimental design notes.\n            \"\"\"\n        with open(json_path, \"r\") as file:\n            geo_results = json.load(file)\n\n        test_summary = geo_results[\"Test_Model\"]\n        best_summary = geo_results[\"Best_Model\"]\n\n        weight_table = \"\\n\".join(\n            f\"| {w['location'].title()} | {w['weight']:.4f} | {bw['weight']:.4f} |\"\n            for w, bw in zip(test_summary['weights'], best_summary['weights'])\n        )\n        effect_timeline = json.dumps(best_summary[\"ATT\"], indent=4)\n        try:\n            lang = detect(query)\n        except:\n            lang = \"en\"\n\n        prompt_en = \"\"\"\n        \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n\n        ## \ud83d\udcca **GeoLift Experiment Analysis**\n\n        \ud83d\ude80 **IMPORTANT: This is a GeoLift analysis designed to measure the causal impact of an advertising campaign.**\n        We are testing whether **spending a budget of `{budget}`** led to a **significant lift** in `{y_id}`.\n\n        **\u2757 READ CAREFULLY:**\n        - **This is NOT a population analysis. DO NOT analyze location populations or city sizes.**\n        - **The goal is to measure the causal effect of an advertising campaign using GeoLift.**\n        - **We compare a Test Model (initial experiment) with a Best Model (optimized version with lowest imbalance).**\n        - **We are looking for statistical evidence that the advertising spend increased `{y_id}`.**\n\n        ---\n\n        ## \ud83d\udccc Experiment Summary\n        - \ud83d\udcc5 Treatment Period: `{start} to {end}`\n        - \ud83d\udcb0 Ad Budget Used: `{budget}`\n        - \ud83d\udd2c Experiment Type: `{type}`\n        - \ud83d\udcc8 Incremental Lift Observed: `{incremental}`\n        - \u2696\ufe0f Bias Adjustment (Best Model): `{bias}`\n        - \ud83d\udcca L2 Imbalance Comparison (Test vs Best Model): `{l2_test} / {l2_best}`\n        - \ud83d\udcca Scaled L2 Imbalance: `{l2_scaled_test} / {l2_scaled_best}`\n        - \ud83d\udd0d Significance Level (Alpha): `{alpha}`\n\n        ---\n\n        ## \ud83d\udcce Key Metrics Comparison\n\n        | Metric                                      | Test Model              | Best Model             |\n        |--------------------------------------------|--------------------------|------------------------|\n        | **ATT Estimate (Effect Size)**             | `{att_est_test}`         | `{att_est_best}`       |\n        | **Percentage Lift (Change in {y_id})**     | `{perc_lift_test}%`      | `{perc_lift_best}%`    |\n        | **P-Value (Statistical Significance)**     | `{pvalue_test}`          | `{pvalue_best}`        |\n        | **Incremental Effect**                     | `{incremental_test}`     | `{incremental_best}`   |\n\n        \ud83d\udccc Interpretation Guidelines:\n        - If p-value &lt; 0.05, the effect is statistically significant.\n        - If L2 imbalance is high, the models are not well-matched.\n        - A high percentage lift indicates a successful campaign.\n\n        ---\n\n        ## \ud83d\udccd Weight Distribution Across Locations\n\n        | Location | Test Model Weight | Best Model Weight |\n        |----------|-------------------|-------------------|\n        {weight_table}\n\n        ---\n\n        ## \ud83d\udcca Effect of Advertising Over Time\n\n        ```json\n        {effect_timeline}\n        ```\n\n        **\ud83d\udd0e Key Insights:**\n        - **Look for time periods where the effect was strongest.**\n        - **Check if the confidence intervals are narrow (meaning stable estimates) or wide (meaning high uncertainty).**\n        - **If most time points have a p-value &gt; 0.05, the effect is likely due to random variation rather than the ad campaign.**\n\n        ---\n\n        \ud83c\udfaf **Final Task: Summarize whether the advertising budget resulted in a meaningful lift in `{y_id}` and whether the experiment was statistically valid.**\n        \"\"\"\n\n        prompt_tr = \"\"\"\n        \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. L\u00fctfen a\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131, bir veri bilimcinin sahip oldu\u011fu teknik ve analitik bak\u0131\u015f a\u00e7\u0131s\u0131yla de\u011ferlendir.\n\n        ## \ud83d\udcca GeoLift Deneyi Analizi\n\n        \ud83d\ude80 **D\u0130KKAT:** Bu analiz, bir reklam kampanyas\u0131n\u0131n nedensel etkisini \u00f6l\u00e7mek i\u00e7in yap\u0131lm\u0131\u015ft\u0131r.\n        Amac\u0131m\u0131z, `{budget}` b\u00fct\u00e7esi harcand\u0131\u011f\u0131nda `{y_id}` de\u011fi\u015fkeninde anlaml\u0131 bir art\u0131\u015f (lift) olup olmad\u0131\u011f\u0131n\u0131 test etmektir.\n\n        \u2757 **D\u0130KKAT ED\u0130LMES\u0130 GEREKENLER:**\n        - Bu bir n\u00fcfus analizi de\u011fildir. Lokasyon b\u00fcy\u00fckl\u00fcklerine odaklanmay\u0131n\u0131z.\n        - Ama\u00e7, reklam harcamas\u0131n\u0131n nedensel etkisini \u00f6l\u00e7mektir.\n        - Test modeli ile dengesizli\u011fi en d\u00fc\u015f\u00fck model kar\u015f\u0131la\u015ft\u0131r\u0131l\u0131r.\n        - `{y_id}` \u00fczerindeki art\u0131\u015f i\u00e7in istatistiksel kan\u0131t aran\u0131r.\n\n        ---\n\n        ## \ud83d\udccc Deney \u00d6zeti\n        - \ud83d\udcc5 Tedavi D\u00f6nemi: `{start} - {end}`\n        - \ud83d\udcb0 Reklam B\u00fct\u00e7esi: `{budget}`\n        - \ud83d\udd2c Deney T\u00fcr\u00fc: `{type}`\n        - \ud83d\udcc8 G\u00f6zlemlenen Art\u0131\u015f: `{incremental}`\n        - \u2696\ufe0f Bias D\u00fczeltmesi: `{bias}`\n        - \ud83d\udcca L2 Dengesizlik (Test / Best): `{l2_test} / {l2_best}`\n        - \ud83d\udcca \u00d6l\u00e7ekli L2 Dengesizlik: `{l2_scaled_test} / {l2_scaled_best}`\n        - \ud83d\udd0d Anlaml\u0131l\u0131k Seviyesi (Alpha): `{alpha}`\n\n        ---\n\n        ## \ud83d\udcce Temel Metrik Kar\u015f\u0131la\u015ft\u0131rmalar\u0131\n\n        | Metrik                                    | Test Modeli            | En \u0130yi Model           |\n        |------------------------------------------|------------------------|------------------------|\n        | **ATT Tahmini (Etki B\u00fcy\u00fckl\u00fc\u011f\u00fc)**         | `{att_est_test}`       | `{att_est_best}`       |\n        | **Y\u00fczdelik Art\u0131\u015f ({y_id})**              | `{perc_lift_test}%`    | `{perc_lift_best}%`    |\n        | **P-De\u011feri (Anlaml\u0131l\u0131k)**                | `{pvalue_test}`        | `{pvalue_best}`        |\n        | **Artan Etki (Ek Kazan\u00e7/Etkile\u015fim)**     | `{incremental_test}`   | `{incremental_best}`   |\n\n        \ud83d\udccc Yorumlama Rehberi:\n        - p-de\u011feri &lt; 0.05 ise, sonu\u00e7 anlaml\u0131d\u0131r.\n        - L2 dengesizlik ne kadar d\u00fc\u015f\u00fckse, e\u015fle\u015ftirme o kadar iyidir.\n        - Y\u00fcksek y\u00fczdelik art\u0131\u015f kampanyan\u0131n ba\u015far\u0131l\u0131 oldu\u011funu g\u00f6sterir.\n\n        ---\n\n        ## \ud83d\udccd Lokasyon A\u011f\u0131rl\u0131klar\u0131\n\n        | Lokasyon | Test Modeli A\u011f\u0131rl\u0131\u011f\u0131 | En \u0130yi Model A\u011f\u0131rl\u0131\u011f\u0131 |\n        |----------|----------------------|------------------------|\n        {weight_table}\n\n        ---\n\n        ## \ud83d\udcca Zaman \u0130\u00e7inde Reklam\u0131n Etkisi\n\n        ```json\n        {effect_timeline}\n        ```\n        **\ud83d\udd0e \u00d6nemli \u0130\u00e7g\u00f6r\u00fcler:**\n        - Etkinin en g\u00fc\u00e7l\u00fc oldu\u011fu zaman aral\u0131klar\u0131n\u0131 inceleyin.  \n        - G\u00fcven aral\u0131klar\u0131 dar ise bu, tahminlerin kararl\u0131 oldu\u011funu g\u00f6sterir; geni\u015fse belirsizlik y\u00fcksektir.  \n        - E\u011fer \u00e7o\u011fu zaman noktas\u0131nda p-de\u011feri &gt; 0.05 ise, g\u00f6zlenen etki reklam kampanyas\u0131ndan de\u011fil, rastlant\u0131sal dalgalanmalardan kaynaklan\u0131yor olabilir.\n\n        ---\n\n        \ud83c\udfaf Son G\u00f6rev: Reklam b\u00fct\u00e7esi, `{y_id}` de\u011fi\u015fkeninde anlaml\u0131 bir art\u0131\u015f sa\u011flam\u0131\u015f m\u0131? Ve bu deney istatistiksel olarak ge\u00e7erli mi? A\u00e7\u0131klay\u0131n\u0131z.\n        \"\"\"\n\n        chat_prompt, inputs = self.generate_prompt(\n            query=query,\n            prompt_tr=prompt_tr,\n            prompt_en=prompt_en,\n            lang=lang,\n            budget=best_summary.get(\"budget\", \"Unknown\"),\n            y_id=best_summary[\"Y_id\"],\n            start=best_summary[\"start\"],\n            end=best_summary[\"end\"],\n            type=best_summary[\"type\"],\n            incremental=best_summary[\"incremental\"],\n            bias=best_summary.get(\"bias\", \"N/A\"),\n            alpha=best_summary[\"alpha\"],\n            att_est_best=best_summary[\"ATT_est\"],\n            att_est_test=test_summary[\"ATT_est\"],\n            perc_lift_best=best_summary[\"PercLift\"],\n            perc_lift_test=test_summary[\"PercLift\"],\n            pvalue_best=best_summary[\"pvalue\"],\n            pvalue_test=test_summary[\"pvalue\"],\n            incremental_best=best_summary[\"incremental\"],\n            incremental_test=test_summary[\"incremental\"],\n            l2_test=test_summary[\"L2Imbalance\"],\n            l2_best=best_summary[\"L2Imbalance\"],\n            l2_scaled_test=test_summary[\"L2ImbalanceScaled\"],\n            l2_scaled_best=best_summary[\"L2ImbalanceScaled\"],\n            weight_table=weight_table,\n            effect_timeline=effect_timeline\n        )\n\n        chain = chat_prompt | self.chat_model\n\n        try:\n            async for chunk in chain.astream(inputs):\n                yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n        except Exception as e:\n            print(\"\u274c LLM stream exception:\", str(e))\n            yield \"\u274c LLM model stream failed. Please try again later.\"\n\n\n    async def eda_agent(self, json_files, df, col1, col2, query):\n        \"\"\"Summarize statistical tests and visuals between two columns.\n\n            Args:\n                json_files: Mapping of pair-type \u2192 JSON path (e.g., ``{\"num_num\": \"...\", ...}``).\n                df: DataFrame used for EDA.\n                col1: First column name.\n                col2: Second column name.\n                query: Analysis question guiding the narrative.\n\n            Yields:\n                Interpreted EDA findings (distributions, correlations, tests) in chunks.\n            \"\"\"\n        is_col1_numeric = pd.api.types.is_numeric_dtype(df[col1])\n        is_col2_numeric = pd.api.types.is_numeric_dtype(df[col2])\n\n        is_col1_categorical = pd.api.types.is_categorical_dtype(df[col1]) or df[col1].dtype == \"object\"\n        is_col2_categorical = pd.api.types.is_categorical_dtype(df[col2]) or df[col2].dtype == \"object\"\n\n        if is_col1_numeric and is_col2_numeric:\n            json_path = json_files[\"num_num\"]\n            analysis_type = \"Numerical-Numerical Analysis\"\n        elif is_col1_numeric and is_col2_categorical or is_col1_categorical and is_col2_numeric:\n            json_path = json_files[\"num_cat\"]\n            analysis_type = \"Numerical-Categorical Analysis\"\n        elif is_col1_categorical and is_col2_categorical:\n            json_path = json_files[\"cat_cat\"]\n            analysis_type = \"Categorical-Categorical Analysis\"\n        else:\n            yield f\"\u26a0\ufe0f Could not determine the analysis type for {col1} and {col2}.\"\n            return\n\n        with open(json_path, \"r\") as file:\n            analysis_results = json.load(file)\n\n        col1_levels = df[col1].unique().tolist() if is_col1_categorical else \"N/A\"\n        col2_levels = df[col2].unique().tolist() if is_col2_categorical else \"N/A\"\n\n        graph_results = {}\n        graph_path = \"plots/scientific_image_analysis.json\"\n        if os.path.exists(graph_path):\n            with open(graph_path, \"r\") as file:\n                graph_results = json.load(file)\n\n        graph_section_en = f\"\"\"\n        #### **Graphical Analysis Insights**\n        ```json\n        {json.dumps(graph_results, indent=4)}\n        ```\"\"\" if graph_results else \"\"\n\n        prompt_en = \"\"\"\n        \ud83d\udcd8 Note:\n        The ISKIN Score is a custom statistical measure designed to detect complex and non-linear relationships between numerical variables. It ranges from 0 to 1, where higher scores indicate stronger relationships. Unlike traditional correlation tests (e.g., Kendall or Pearson), ISKIN may detect subtle dependencies that do not manifest linearly. A score above 0.9 is typically considered strong.\n\n        \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n        ### \ud83d\udcca Exploratory Data Analysis (EDA)\n\n        **Analyzing the relationship between:** `{col1}` and `{col2}`\n        - **Analysis Type:** {analysis_type}\n        - **Data Types:** `{col1}` ({col1_type}), `{col2}` ({col2_type})\n        - **Levels for Categorical Columns:**\n        - `{col1}`: {col1_levels}\n        - `{col2}`: {col2_levels}\n\n        #### **Raw JSON Data:**\n        ```json\n        {analysis_results}\n        ```\n\n        \u2753 **Interpretation Request**\n        1\ufe0f\u20e3 **Analyze the statistical test results.**  \n        2\ufe0f\u20e3 **Based on the p-values, determine if there is a significant relationship.**  \n        3\ufe0f\u20e3 **Explain the effect sizes and power of the tests.**  \n        4\ufe0f\u20e3 **Compare different statistical tests and identify inconsistencies.**  \n        5\ufe0f\u20e3 **Provide actionable insights based on the results.**  \n        {graph_section_en}\n        \"\"\".strip()\n\n        graph_section_tr = f\"\"\"\n        #### **Grafiksel Analiz Bulgular\u0131**\n        ```json\n        {json.dumps(graph_results, indent=4, ensure_ascii=False)}\n        ```\"\"\" if graph_results else \"\"\n\n        prompt_tr = \"\"\"\n        \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. L\u00fctfen a\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131, bir veri bilimcinin sahip oldu\u011fu teknik ve analitik bak\u0131\u015f a\u00e7\u0131s\u0131yla de\u011ferlendir.    \n        ### \ud83d\udcca Ke\u015fifsel Veri Analizi (EDA)\n\n        **\u0130ncelenen ili\u015fki:** `{col1}` ile `{col2}` aras\u0131ndaki ili\u015fki  \n        - **Analiz T\u00fcr\u00fc:** {analysis_type}  \n        - **Veri T\u00fcrleri:** `{col1}` ({'Say\u0131sal' if is_col1_numeric else 'Kategorik'}), `{col2}` ({'Say\u0131sal' if is_col2_numeric else 'Kategorik'})  \n        - **Kategorik De\u011fi\u015fkenlerin Seviyeleri:**\n        - `{col1}`: {col1_levels}\n        - `{col2}`: {col2_levels}\n\n        #### **Ham JSON Verisi:**\n        ```json\n        {analysis_results}\n        ```\n        \u2753 **Yorumlama Talebi**  \n        1\ufe0f\u20e3 **\u0130statistiksel test sonu\u00e7lar\u0131n\u0131 analiz edin.**  \n        2\ufe0f\u20e3 **p-de\u011ferlerine g\u00f6re anlaml\u0131 bir ili\u015fki olup olmad\u0131\u011f\u0131n\u0131 belirleyin.**  \n        3\ufe0f\u20e3 **Etki b\u00fcy\u00fckl\u00fcklerini (effect size) ve test g\u00fcc\u00fcn\u00fc (statistical power) a\u00e7\u0131klay\u0131n.**  \n        4\ufe0f\u20e3 **Farkl\u0131 istatistiksel testleri kar\u015f\u0131la\u015ft\u0131r\u0131n ve varsa tutars\u0131zl\u0131klar\u0131 belirleyin.**  \n        5\ufe0f\u20e3 **Sonu\u00e7lara dayanarak uygulanabilir i\u00e7g\u00f6r\u00fcler sunun.**\n        {graph_section_tr}\n        \"\"\".strip()\n        try:\n            lang = detect(query)\n        except:\n            lang = \"en\"\n\n        chat_prompt, prompt_inputs = self.generate_prompt(\n            query=query,\n            prompt_tr=prompt_tr,\n            prompt_en=prompt_en,\n            lang=lang,\n            col1=col1,\n            col2=col2,\n            col1_type=\"Numeric\" if is_col1_numeric else \"Categorical\",\n            col2_type=\"Numeric\" if is_col2_numeric else \"Categorical\",\n            col1_type_tr=\"Say\u0131sal\" if is_col1_numeric else \"Kategorik\",\n            col2_type_tr=\"Say\u0131sal\" if is_col2_numeric else \"Kategorik\",\n            analysis_type=analysis_type,\n            col1_levels=col1_levels,\n            col2_levels=col2_levels,\n            analysis_results=analysis_results,\n            graph_section_en=graph_section_en,\n            graph_section_tr=graph_section_tr\n        )\n\n        chain = chat_prompt | self.chat_model\n\n        try:\n            async for chunk in chain.astream(prompt_inputs):\n                yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n        except Exception as e:\n            print(\"\u274c LLM stream exception:\", str(e))\n            yield \"\u274c LLM model stream failed. Please try again later.\"\n\n    async def ab_agent(self, user_query):\n        \"\"\"Analyze A/B tests and report significance across methods.\n\n            Args:\n                user_query: Experiment question (variants, metric, horizon).\n\n            Yields:\n                Test summaries with p-values, effect sizes, and decision guidance.\n            \"\"\"\n        with open('services/AI/data/ab_test.json', 'r') as file:\n            ab_test_results = json.load(file)\n\n        prompt = f\"\"\"\n            \ud83c\udf93 Note:\n            You are a highly experienced data scientist and statistician with over 30 years of expertise in experimental design and A/B testing methodologies. You are asked to provide a detailed interpretation of an A/B testing analysis.\n\n            ### \ud83d\udcdd User Query:\n            \"{user_query}\"\n\n            ### \ud83d\udcca A/B Testing Results:\n            The following JSON represents the results of various A/B testing methodologies (e.g., Z-Test, Fisher's Exact Test, T-Test, Chi-Square Test, ANOVA). Each result includes key metrics like p-values, effect sizes, and significance levels.\n\n            ```json\n            {ab_test_results}\n            ```\n\n            #### \ud83c\udfaf Your Analytical Task:\n            1\ufe0f\u20e3 **Analyze the test results** \u2014 Describe what the p-values, test types, and effect sizes indicate about the performance difference between groups.\n            2\ufe0f\u20e3 **Assess Statistical Significance** \u2014 For each test, determine if the results are statistically significant based on the p-value thresholds.\n            3\ufe0f\u20e3 **Interpret Effect Sizes** \u2014 Explain how large or meaningful the observed effect sizes are in practical/business terms.\n            4\ufe0f\u20e3 **Compare Methods** \u2014 Identify if there are discrepancies between different statistical methods (e.g., Fisher vs Z-Test), and explain why such inconsistencies may occur.\n            5\ufe0f\u20e3 **Provide Data-Driven Recommendations** \u2014 Based on these results, suggest actionable next steps (e.g., scale experiment, gather more data, validate findings).\n            6\ufe0f\u20e3 **Mention Limitations** \u2014 Highlight any limitations or assumptions inherent to the test results (e.g., sample size concerns, test type appropriateness).\n\n            \ud83c\udf93 You are expected to give a structured, precise, and scientific response.\n            \"\"\".strip()\n\n        try:\n            async for chunk in self.chat_model.astream(prompt):\n                yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n        except Exception as e:\n            print(\"\u274c LLM stream exception:\", str(e))\n            yield \"\u274c LLM model stream failed. Please try again later.\"\n\n    async def assoc_agent(self, user_query: str, json_path: str = \"data/assoc_rules.json\", top_n: int = 50):\n        \"\"\"Stream an LLM-based interpretation of association rules.\n\n            Loads a JSON file containing association rules (e.g., Apriori, FP-Growth),\n            trims to the top-N rules by lift/confidence/support, and builds a structured\n            interpretation prompt. The prompt guides the LLM to summarize patterns,\n            highlight entity-linked vs. metric-only rules, and produce actionable insights.\n\n            Args:\n                user_query: Natural language question or focus area for interpretation.\n                json_path: Path to the JSON file containing precomputed association rules.\n                top_n: Number of top-ranked rules to include (default = 50).\n\n            Yields:\n                Streaming text chunks with:\n                  - Summarized association patterns (ranked by lift, confidence, support)\n                  - Entity-specific vs. general metric findings\n                  - Conflicts, trivialities, and caveats\n                  - Actionable recommendations for campaigns or experiments\n                  - Limitations and notes on interpretability\n            \"\"\"\n        # 1) Load JSON\n        if not os.path.exists(json_path):\n            yield f\"\u274c JSON not found at {json_path}\"\n            return\n\n        try:\n            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n                rules_obj = json.load(f)\n        except Exception as e:\n            yield f\"\u274c JSON load error: {e}\"\n            return\n\n        # 2) Optional top_n trimming for large files\n        trimmed = rules_obj\n        if isinstance(rules_obj, list) and top_n and top_n &gt; 0:\n            def _as_num(x):\n                try:\n                    return float(x)\n                except:\n                    return -1e9\n\n            def sort_key(r):\n                return (-_as_num(r.get(\"lift\", 0)),\n                        -_as_num(r.get(\"confidence\", 0)),\n                        -_as_num(r.get(\"support\", 0)))\n\n            trimmed = sorted(rules_obj, key=sort_key)[:top_n]\n\n        try:\n            rules_json_str = json.dumps(trimmed, ensure_ascii=False, indent=2)\n        except Exception:\n            rules_json_str = str(trimmed)\n\n        # 3) Prompt for Association Rules interpretation\n        prompt = f\"\"\"\n    \ud83c\udf93 Note:\n    You are a senior data scientist specializing in **Association Rule Mining** (Apriori / FP-Growth / ECLAT) for marketing analytics. \n    Your task is to provide a clear, precise, and business-focused interpretation of the given rules.\n\n    ### \ud83d\udcdd User Query\n    \"{user_query}\"\n\n    ### \ud83d\udcca Association Rules (JSON)\n    Below is the rules output (top {top_n} shown if large):\n    ```json\n    {rules_json_str}\n    \ud83d\udcd8 Quick Primer (interpretation guide)\n    Antecedents \u2192 Consequents: Read as \"If antecedents, then consequents\".\n\n    support = P(A \u2227 B): Frequency of both conditions occurring together. Higher support = more common pattern.\n\n    confidence = P(B|A): Probability of B given A. Ranges 0\u20131.\n\n    lift = P(B|A) / P(B): &gt;1 = positive association, \u22481 = no association, &lt;1 = negative association.\n\n    antecedent support / consequent support: P(A) and P(B) individually.\n\n    leverage = P(A\u2227B) \u2212 P(A)P(B): Distance from independence. Larger magnitude = stronger deviation.\n\n    conviction = (1\u2212P(B)) / (1\u2212P(B|A)): Higher means B is less likely to be absent when A occurs.\n\n    Entity items (e.g., campaign_name:\u2026, adset_name:\u2026, ad_name:\u2026, Level:\u2026) show rules tied to specific campaigns/ad sets/ads.\n\n    Binning (low/mid/high): Metrics (CTR, CPC, SPEND, IMPR, CONV) are bucketed; interpret relatively.\n\n    \ud83c\udfaf Your Analytical Task\n    Core findings: Summarize key patterns, prioritizing by lift, then confidence, then support.\n\n    Entity-aware insights: Identify which campaigns/adsets/ads are linked to positive patterns (e.g., CTR:high, CPC:low) or negative ones (CTR:low, CPC:high).\n\n    Metric-only vs entity-linked: Distinguish between general metric rules and entity-specific ones.\n\n    Trivialities &amp; conflicts: Downrank obvious relationships (e.g., SPEND:high \u2192 IMPR:high). Note conflicting outcomes from same antecedents and explain potential causes.\n\n    Actionable recommendations: Suggest campaign budget shifts, creative/targeting changes, A/B tests, or follow-up analysis. Prioritize actions.\n\n    Limitations: Note binning artifacts, low support, imbalanced classes, limited entity coverage, and that association \u2260 causation. Suggest possible data improvements.\n\n    Please answer in clear sections with bullet points, keeping the response concise but insight-rich.\n    \"\"\".strip()\n\n        try:\n            async for chunk in self.chat_model.astream(prompt):\n                yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n        except Exception as e:\n            print(\"\u274c LLM stream exception:\", str(e))\n            yield \"\u274c LLM model stream failed. Please try again later.\"\n\n\n\n    async def shap_agent(self, col, query):\n        \"\"\"Produce SHAP interpretability narrative for a trained regression model.\n\n            Args:\n                col: Target variable analyzed with SHAP.\n                query: User question to focus the explanation.\n\n            Yields:\n                Explanations of global/local importance and interaction hints.\n            \"\"\"\n        with open(\"services/AI/data/best_regression_results.json\", \"r\") as file:\n            result_model = json.load(file)\n\n        with open(\"services/AI/data/final_result_regress.json\", \"r\") as file:\n            result_shap = json.load(file)\n\n        prompt_en = \"\"\"\n        \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n        ### \ud83d\udcca Regression Agent Analysis\n\n        **{query}:**  \n        - **Target Variable:** `{col}`  \n        - **Best Regression Model:** `{best_model}`  \n        - **Evaluation Metrics:**  \n            - `R\u00b2`: {best_r2}  \n            - `MAE`: {best_mae}  \n            - `RMSE`: {best_rmse}  \n\n        #### **Suggested Feature Contributions (SHAP Score Analysis)**  \n        ```json\n        {shap_scores}\n        ```\n\n        \u2753 **Interpretation Request**  \n        1\ufe0f\u20e3 Analyze how each feature contributes to the target change.  \n        2\ufe0f\u20e3 Determine the significance using SHAP values.  \n        3\ufe0f\u20e3 Compare feature rankings and highlight key drivers.  \n        4\ufe0f\u20e3 Assess the reliability of predictions.  \n        5\ufe0f\u20e3 Suggest actionable strategies.  \n        \"\"\".strip()\n\n        prompt_tr = \"\"\"\n        \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. A\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131 yorumla:  \n        ### \ud83d\udcca Regresyon Ajan\u0131 Analizi\n\n        **{query}:**  \n        - **Hedef De\u011fi\u015fken:** `{col}`  \n        - **En \u0130yi Regresyon Modeli:** `{best_model}`  \n        - **De\u011ferlendirme Metrikleri:**  \n            - `R\u00b2`: {best_r2}  \n            - `MAE`: {best_mae}  \n            - `RMSE`: {best_rmse}  \n\n        #### **\u00d6zellik Katk\u0131lar\u0131 (SHAP Skorlar\u0131)**  \n        ```json\n        {shap_scores}\n        ```\n\n        \u2753 **Yorumlama Talebi:**  \n        1\ufe0f\u20e3 Hangi de\u011fi\u015fken ne kadar katk\u0131 sa\u011flad\u0131?  \n        2\ufe0f\u20e3 SHAP de\u011feriyle \u00f6nem derecesini belirt.  \n        3\ufe0f\u20e3 Etkili de\u011fi\u015fkenleri s\u0131rala.  \n        4\ufe0f\u20e3 Tahmin g\u00fcvenilirli\u011fini de\u011ferlendir.  \n        5\ufe0f\u20e3 Stratejik \u00f6nerilerde bulun.\n        \"\"\".strip()\n\n        try:\n            lang = detect(query)\n        except:\n            lang = \"en\"\n\n        chat_prompt, prompt_inputs = self.generate_prompt(\n            query=query,\n            prompt_tr=prompt_tr,\n            prompt_en=prompt_en,\n            lang=lang,\n            col=col,\n            best_model=result_model[\"best_model\"],\n            best_r2=result_model[\"best_r2\"],\n            best_mae=result_model[\"best_mae\"],\n            best_rmse=result_model[\"best_rmse\"],\n            shap_scores=json.dumps(result_shap, indent=4, ensure_ascii=(lang != \"tr\"))\n        )\n\n        chain = chat_prompt | self.chat_model\n        try:\n            async for chunk in chain.astream(prompt_inputs):\n                yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n        except Exception as e:\n            print(\"\u274c LLM stream exception:\", str(e))\n            yield \"\u274c LLM model stream failed. Please try again later.\"\n\n\n\n\n    async def ts_agent(self, user_query: str, dashboard=None):\n        \"\"\"Explain time-series forecasts/causality with optional dashboard rendering.\n\n            Args:\n                user_query: Forecasting/causality question (may contain horizon or series).\n                dashboard: Optional dashboard object to render or export.\n\n            Yields:\n                Forecast summaries, uncertainty notes, and causal diagnostics.\n            \"\"\"\n        try:\n            with open(\"services/AI/data/ts_metrics.json\", \"r\") as file:\n                results = json.load(file)\n\n            chat_prompt = PromptTemplate.from_template(\"\"\"\n    \ud83d\udccc **Your Role:** You are a data scientist assigned to interpret the results of a time series and causal analysis.\n\n    You are provided with the following data (may include forecasting and/or causality information):\n\n    \ud83e\uddfe **Analysis Result**:\n    {analysis_result}\n\n    \ud83d\udde3\ufe0f **User Query**:\n    {user_query}\n\n    ---\n\n    \u2705 Based on the data above, answer the following:\n\n    1. If forecast results are included:\n       - Are the predictions statistically reliable? (e.g. MAE, MAPE, R\u00b2)\n       - Are there major trend shifts or changepoints?\n       - Do holidays have a visible influence on predictions?\n\n    2. If multiple metrics are analyzed:\n       - Which metrics show strongest trends or weakest prediction accuracy?\n       - Are there any that should be prioritized, flagged, or adjusted?\n\n    3. If Granger causality information is present:\n       - Is there statistical causality between metrics?\n       - What does the p-value and optimal lag indicate?\n       - Is this relationship useful for decision-making?\n\n    4. Finally, considering the user query, write a narrative interpretation and provide concrete, business-relevant insights or recommendations.\n    \"\"\")\n\n            chain = chat_prompt | self.chat_model\n\n            prompt_inputs = {\n                \"analysis_result\": json.dumps(results, indent=2),\n                \"user_query\": user_query\n            }\n\n            async for chunk in chain.astream(prompt_inputs):\n                yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n\n            if dashboard is not None:\n                dashboard_name = \"forecast_dashboard\"\n                dashboard.servable(\"Forecast Dashboard\")\n                dashboard_url = f\"http://localhost:5006/{dashboard_name}\"\n                yield f\"\\n\ud83d\udcca [Open Forecast Dashboard]({dashboard_url})\"\n        except Exception as e:\n            print(\"\u274c LLM stream exception:\", str(e))\n            yield \"\u274c LLM model stream failed. Please try again later.\"\n\n    async def dowhy_agent(self, json_file, query):\n        \"\"\"Interpret DoWhy/EconML causal outputs from persisted JSON.\n\n            Args:\n                json_file: Path to the causal results JSON.\n                query: Causal question (treatment/outcome scope).\n\n            Returns:\n                A human-readable summary of effects, assumptions, and robustness checks.\n            \"\"\"\n        with open(json_file, \"r\") as file:\n            analysis_results = json.load(file)\n\n        analysis_file = \"services/AI/data/dowhy_econml_causal.json\"\n        graph_results = {}\n        if os.path.exists(analysis_file):\n            with open(analysis_file, \"r\") as file:\n                graph_results = json.load(file)\n\n        prompt_en = \"\"\"\n        \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n        ### \ud83d\udd0d **Causal Inference Analysis Using DoWhy &amp; EconML**\n\n        \ud83d\udcdd **User Query:** \"{query}\"\n\n        - The system has conducted a **causal analysis** using DoWhy and EconML.\n        - The dataset has been processed, and the estimated **causal effects** are extracted.\n        - The results include **treatment effects, statistical refutations, and graphical model insights**.\n\n        #### **\ud83d\udcca Causal Inference Results**\n        ```json\n        {analysis_results}\n        ```\n\n        #### **\ud83d\udcc9 Graphical Analysis Insights**\n        ```json\n        {graph_results}\n        ```\n\n        \u2753 **Interpretation Request**\n        1\ufe0f\u20e3 Explain the estimated causal effects in plain terms.  \n        2\ufe0f\u20e3 Analyze how the treatment variable influences the outcome variable.  \n        3\ufe0f\u20e3 Evaluate whether the model assumptions are valid.  \n        4\ufe0f\u20e3 Identify potential biases or inconsistencies in the analysis.  \n        5\ufe0f\u20e3 Compare different causal estimation methods used in the analysis.  \n        6\ufe0f\u20e3 Suggest improvements or refinements for a more robust causal inference.\n        \"\"\".strip()\n\n        prompt_tr = \"\"\"\n        \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. L\u00fctfen a\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131, bir veri bilimcinin sahip oldu\u011fu teknik ve analitik bak\u0131\u015f a\u00e7\u0131s\u0131yla de\u011ferlendir.   \n        ### \ud83d\udd0d **DoWhy &amp; EconML Kullanarak Nedensel \u00c7\u0131kar\u0131m Analizi**\n\n        \ud83d\udcdd **Kullan\u0131c\u0131 Sorgusu:** \"{query}\"\n\n        - Sistem, DoWhy ve EconML k\u00fct\u00fcphanelerini kullanarak bir **nedensel analiz** ger\u00e7ekle\u015ftirmi\u015ftir.  \n        - Veri k\u00fcmesi i\u015flenmi\u015f ve tahmin edilen **nedensel etkiler** \u00e7\u0131kar\u0131lm\u0131\u015ft\u0131r.  \n        - Sonu\u00e7lar aras\u0131nda **tedavi (treatment) etkileri, istatistiksel do\u011frulamalar ve grafiksel model i\u00e7g\u00f6r\u00fcleri** yer almaktad\u0131r.\n\n        #### **\ud83d\udcca Nedensel \u00c7\u0131kar\u0131m Sonu\u00e7lar\u0131**\n        ```json\n        {analysis_results}\n        ```\n\n        #### **\ud83d\udcc9 Grafiksel Analiz \u0130\u00e7g\u00f6r\u00fcleri**\n        ```json\n        {graph_results}\n        ```\n\n        \u2753 **Yorumlama Talebi**  \n        1\ufe0f\u20e3 Tahmin edilen nedensel etkileri sade ve anla\u015f\u0131l\u0131r bir dille a\u00e7\u0131klay\u0131n\u0131z.  \n        2\ufe0f\u20e3 Tedavi (m\u00fcdahale) de\u011fi\u015fkeninin sonu\u00e7 (ba\u011f\u0131ml\u0131) de\u011fi\u015fken \u00fczerindeki etkisini analiz ediniz.  \n        3\ufe0f\u20e3 Model varsay\u0131mlar\u0131n\u0131n ge\u00e7erlili\u011fini de\u011ferlendiriniz.  \n        4\ufe0f\u20e3 Analizdeki olas\u0131 \u00f6nyarg\u0131 (bias) veya tutars\u0131zl\u0131klar\u0131 belirleyiniz.  \n        5\ufe0f\u20e3 Kullan\u0131lan farkl\u0131 nedensel tahmin y\u00f6ntemlerini kar\u015f\u0131la\u015ft\u0131r\u0131n\u0131z.  \n        6\ufe0f\u20e3 Daha sa\u011flam bir nedensel \u00e7\u0131kar\u0131m i\u00e7in iyile\u015ftirme veya geli\u015ftirme \u00f6nerileri sununuz.\n        \"\"\".strip()\n\n        try:\n            lang = detect(query)\n        except:\n            lang = \"en\"\n\n        chat_prompt, prompt_inputs = self.generate_prompt(\n            query=query,\n            prompt_tr=prompt_tr,\n            prompt_en=prompt_en,\n            lang=lang,\n            analysis_results=json.dumps(analysis_results, indent=4, ensure_ascii=(lang != \"tr\")),\n            graph_results=json.dumps(graph_results, indent=4, ensure_ascii=(lang != \"tr\"))\n        )\n\n        chain = chat_prompt | self.chat_model\n        try:\n            async for chunk in chain.astream(prompt_inputs):\n                yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n        except Exception as e:\n            print(\"\u274c LLM stream exception:\", str(e))\n            yield \"\u274c LLM model stream failed. Please try again later.\"\n\n    async def causalpy_agent(self, json_file, query):\n        \"\"\"Interpret CausalPy synthetic-control (Sklearn/Bayesian) outputs.\n\n            Args:\n                json_file: Path to synthetic control summaries JSON.\n                query: User question to contextualize the causal impact.\n\n            Returns:\n                Narrative explaining pre/post fit, counterfactuals, and estimated impact.\n            \"\"\"\n        with open(\"services/AI/data/sklearn_and_bayesian_causal_impact_summary.json\", \"r\") as file:\n            analysis_results = json.load(file)\n\n        graph_results = {}\n        if os.path.exists(json_file):\n            with open(json_file, \"r\") as file:\n                graph_results = json.load(file)\n\n        try:\n            lang = detect(query)\n        except:\n            lang = \"en\"\n\n        prompt_en = \"\"\"\n        \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n        ### \ud83d\udd0d **Causal Inference Analysis Using CausalPy**\n\n        \ud83d\udcdd **User Query:** \"{query}\"\n\n        - The system has conducted a **causal analysis** using CausalPy.\n        - The dataset has been processed using both **Bayesian (PyMC)** and **Sklearn-based** Synthetic Control models.\n        - The results include **causal impact estimates, model fit scores, and graphical model insights**.\n\n        #### **\ud83d\udcca Bayesian &amp; Sklearn-Based Causal Analysis Results**\n        ```json\n        {analysis_results}\n        ```\n\n        #### **\ud83d\udcc9 Graphical Analysis Insights**\n        ```json\n        {graph_results}\n        ```\n\n        \u2753 **Interpretation Request**\n\n        Please provide a structured and in-depth interpretation of the results based on the following points:\n\n        ---\n\n        ### 1\ufe0f\u20e3 **Comparison: Bayesian vs. Sklearn-Based Models**\n        - How do the causal effect estimates differ between the two models?\n        - Which model demonstrates a better pre-intervention fit to the observed data?\n        - Does the Bayesian model offer better uncertainty quantification (e.g., credible intervals)?\n        - Are the model assumptions consistent across both methods?\n\n        ---\n\n        ### 2\ufe0f\u20e3 **Evaluation of Causal Impact Results**\n        - Is the estimated treatment effect statistically and practically significant?\n        - How closely does the counterfactual prediction match the actual observations?\n        - Are there any deviations or surprises in the post-intervention period?\n        - Is there evidence of delayed or cumulative treatment effects?\n\n        ---\n\n        ### 3\ufe0f\u20e3 **Model Robustness and Bias Assessment**\n        - Does either model show signs of overfitting or instability?\n        - How sensitive are the results to changes in predictor variables or treatment timing?\n        - Are the causal estimates stable across different time frames or subgroups?\n\n        ---\n\n        ### 4\ufe0f\u20e3 **Graphical Analysis Insights**\n        - How do the pre-intervention fit, causal impact plot, and cumulative impact chart support the conclusions?\n        - Are the trends in the graphical outputs consistent with numerical estimates?\n        - Do the graphs highlight any anomalies, structural breaks, or unexpected outliers?\n        - How do visual elements improve understanding of model performance and reliability?\n\n        ---\n\n        ### 5\ufe0f\u20e3 **Scientific Insights and Recommendations**\n        - What is the overall conclusion regarding the presence and magnitude of causal impact?\n        - Which model is more appropriate for making business or policy decisions?\n        - What additional checks (e.g., placebo tests, sensitivity analysis) could strengthen the findings?\n        - Are there alternative causal inference methods you would recommend testing?\n\n        ---\n\n        \ud83d\udccc Present your answer as if you are preparing a data science report for a technical audience. Include justifications, references to visual cues, and actionable recommendations based on the analysis.\n\n        \"\"\".strip()\n\n        prompt_tr = \"\"\"\n        \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. L\u00fctfen a\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131, bir veri bilimcinin sahip oldu\u011fu teknik ve analitik bak\u0131\u015f a\u00e7\u0131s\u0131yla de\u011ferlendir.  \n        ### \ud83d\udd0d **CausalPy Kullanarak Nedensel \u00c7\u0131kar\u0131m Analizi**\n\n        \ud83d\udcdd **Kullan\u0131c\u0131 Sorgusu:** \"{query}\"\n\n        - Sistem, **CausalPy** kullanarak bir **nedensel analiz** ger\u00e7ekle\u015ftirmi\u015ftir.  \n        - Veri k\u00fcmesi, hem **Bayesyen (PyMC)** hem de **Sklearn tabanl\u0131** Sentetik Kontrol modelleriyle i\u015flenmi\u015ftir.  \n        - Sonu\u00e7lar, **nedensel etki tahminleri**, **model uyum skorlar\u0131** ve **grafiksel model i\u00e7g\u00f6r\u00fcleri** i\u00e7ermektedir.\n\n        #### **\ud83d\udcca Bayesyen ve Sklearn Tabanl\u0131 Nedensel Analiz Sonu\u00e7lar\u0131**\n        ```json\n        {analysis_results}\n        ```\n\n        #### **\ud83d\udcc9 Grafiksel Analiz \u0130\u00e7g\u00f6r\u00fcleri**\n        ```json\n        {graph_results}\n        ```\n\n        1\ufe0f\u20e3 Bayesyen ve Sklearn Tabanl\u0131 Modelleri Kar\u015f\u0131la\u015ft\u0131r\u0131n\u0131z:\n            - Tahmin edilen nedensel etkiler aras\u0131nda nas\u0131l farklar var?\n            - Hangi model m\u00fcdahale \u00f6ncesi d\u00f6nemde daha iyi bir uyum sa\u011fl\u0131yor?\n            - Bayesyen \u00e7\u0131kar\u0131m, belirsizliklerin \u00f6l\u00e7\u00fcm\u00fcnde daha ba\u015far\u0131l\u0131 m\u0131?\n\n        2\ufe0f\u20e3 Nedensel Etki Sonu\u00e7lar\u0131n\u0131 De\u011ferlendiriniz:\n            - Tahmin edilen tedavi etkisi ne kadar anlaml\u0131?\n            - Kar\u015f\u0131 olgusal (counterfactual) tahminler beklentilerle \u00f6rt\u00fc\u015f\u00fcyor mu?\n            - M\u00fcdahale sonras\u0131 d\u00f6nemde ciddi sapmalar var m\u0131?\n\n        3\ufe0f\u20e3 Model Sapmalar\u0131 ve S\u0131n\u0131rl\u0131l\u0131klar\u0131 \u00dczerine Analiz:\n            - Modellerden biri a\u015f\u0131r\u0131 \u00f6\u011frenmeye (overfitting) maruz kal\u0131yor mu?\n            - Farkl\u0131 tahminci se\u00e7imlerine kar\u015f\u0131 sonu\u00e7lar ne kadar sa\u011flam?\n            - Nedensel etkiler zaman boyunca istikrarl\u0131 m\u0131?\n\n        4\ufe0f\u20e3 Bilimsel \u0130\u00e7g\u00f6r\u00fcler ve \u00d6nerilen Geli\u015ftirmeler:\n            - Hangi y\u00f6ntem karar verme a\u00e7\u0131s\u0131ndan daha g\u00fcvenilirdir?\n            - Ek sa\u011flaml\u0131k kontrolleri yap\u0131lmal\u0131 m\u0131?\n            - Test edilebilecek alternatif nedensel tahmin y\u00f6ntemleri nelerdir?\n\n        5\ufe0f\u20e3 Grafiksel \u0130\u00e7g\u00f6r\u00fcler ve Yorumlama:\n            - M\u00fcdahale \u00f6ncesi uyum, nedensel etki grafi\u011fi ve k\u00fcm\u00fclatif nedensel etki grafiklerinin yoruma katk\u0131s\u0131 nedir?\n            - Grafiksel \u00e7\u0131kt\u0131lardaki e\u011filimler, say\u0131sal nedensel tahminlerle tutarl\u0131 m\u0131?\n            - G\u00f6rseller, say\u0131sal \u00e7\u0131kt\u0131larda g\u00f6r\u00fclmeyen \u00f6nyarg\u0131lar ya da ayk\u0131r\u0131 de\u011ferler ortaya koyuyor mu?\n            - Grafiksel bulgular, nedensel \u00e7\u0131kar\u0131m sonu\u00e7lar\u0131n\u0131n g\u00fcvenilirli\u011fini ve sa\u011flaml\u0131\u011f\u0131n\u0131 nas\u0131l etkiler?\n\n        \ud83d\udccc L\u00fctfen yan\u0131t\u0131n\u0131z\u0131 a\u00e7\u0131k bilimsel a\u00e7\u0131klamalarla ve net \u00e7\u0131kar\u0131mlarla yap\u0131land\u0131r\u0131lm\u0131\u015f \u015fekilde sununuz.\n        \"\"\".strip()\n\n        chat_prompt, prompt_inputs = self.generate_prompt(\n            query=query,\n            prompt_tr=prompt_tr,\n            prompt_en=prompt_en,\n            lang=lang,\n            analysis_results=json.dumps(analysis_results, indent=4, ensure_ascii=(lang != \"tr\")),\n            graph_results=json.dumps(graph_results, indent=4, ensure_ascii=(lang != \"tr\"))\n        )\n\n        chain = chat_prompt | self.chat_model\n\n        try:\n            async for chunk in chain.astream(prompt_inputs):\n                yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n        except Exception as e:\n            print(\"\u274c LLM stream exception:\", str(e))\n            yield \"\u274c LLM model stream failed. Please try again later.\"\n\n\n\n    @staticmethod\n    def filter_data_last_n_days(data, n_days):\n        \"\"\"Filter dataset to the last ``n_days`` based on available date columns.\n\n            Args:\n                data: Input DataFrame.\n                n_days: Number of trailing days to keep.\n\n            Returns:\n                Filtered DataFrame restricted to the latest period.\n            \"\"\"\n        df = pd.DataFrame(data)\n        if 'date' in df.columns:\n            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n            latest_date = df['date'].max()\n            earliest_date = df['date'].min()\n\n            max_available_days = (latest_date - earliest_date).days\n            if n_days &gt; max_available_days:\n                return None, f\"\u26a0\ufe0f Warning: The dataset only contains data for the last {max_available_days} days. Please adjust your query.\"\n\n            cutoff_date = latest_date - timedelta(days=n_days)\n            filtered_df = df[df['date'] &gt;= cutoff_date]\n\n            if filtered_df.empty:\n                return None, f\"\u26a0\ufe0f Warning: No data available for the last {n_days} days.\"\n\n            return filtered_df, None\n\n        start_cols = [col for col in df.columns if re.search(r'\\b(starts|begins)\\b', col.lower())]\n        end_cols = [col for col in df.columns if re.search(r'\\b(ends|finishes)\\b', col.lower())]\n\n        if not start_cols or not end_cols:\n            return None, \"\u26a0\ufe0f Warning: No valid date column ('date', 'start-*', 'end-*') found in the dataset.\"\n\n        start_col = start_cols[0]\n        end_col = end_cols[0]\n\n        df[start_col] = pd.to_datetime(df[start_col], errors='coerce')\n        df[end_col] = pd.to_datetime(df[end_col], errors='coerce')\n\n        latest_end = df[end_col].max()\n        earliest_start = df[start_col].min()\n\n        max_available_days = (latest_end - earliest_start).days\n        if n_days &gt; max_available_days:\n            return None, f\"\u26a0\ufe0f Warning: The maximum available date range is {max_available_days} days. Please adjust your query.\"\n\n        cutoff_date = latest_end - timedelta(days=n_days)\n\n        filtered_df = df[(df[start_col] &gt;= cutoff_date) &amp; (df[end_col] &lt;= latest_end)]\n\n        if filtered_df.empty:\n            return None, f\"\u26a0\ufe0f Warning: No data available for the last {n_days} days.\"\n\n        return filtered_df, None\n\n    def extract_columns_from_query(self, query, available_columns):\n        \"\"\"Detect potential column names mentioned in a natural-language query.\n\n            Args:\n                query: Free-form user text.\n                available_columns: List of column names to match against.\n\n            Returns:\n                A list of best-guess column names (may be empty if none found).\n            \"\"\"\n        words = re.findall(r'\\w+', query.lower())\n        seen = set()\n        detected_columns = []\n\n        for word in words:\n            if len(word) &lt; 2:\n                continue\n\n            match = self.find_best_column_match(word, available_columns)\n            if match and match not in seen:\n                detected_columns.append(match)\n                seen.add(match)\n\n        detected_columns = [col for col in detected_columns if col in available_columns]\n        return detected_columns\n\n    def extract_column_name(self, query, field_name):\n        \"\"\"Extract a column referred to as ``as &lt;FIELD_NAME&gt;`` in the query.\n\n            Args:\n                query: User text potentially containing the pattern.\n                field_name: Logical field label to search for (e.g., ``\"metric\"``).\n\n            Returns:\n                Extracted column name or ``None`` if not present.\n            \"\"\"\n        import re\n\n        # Sadece 'X as FIELD' e\u015fle\u015fmeleri yakalan\u0131r\n        pattern = rf\"(\\w+)\\s+as\\s+{field_name}\"\n        match = re.search(pattern, query, re.IGNORECASE)\n        if match:\n            candidate = match.group(1).lower()\n            stopwords = {\"and\", \"as\", \"with\", \"or\", \"not\"}\n            if candidate in stopwords:\n                return None\n            return candidate\n        return None\n\n    @staticmethod\n    def extract_days_from_query(query):\n        \"\"\"Parse phrases like \u201clast N days\u201d from the user query.\n\n            Args:\n                query: Input text.\n\n            Returns:\n                Integer number of days if detected; otherwise ``None``.\n            \"\"\"\n        match = re.search(r'(?:last\\s*)?(\\d+)\\s*(?:days|day)', query, re.IGNORECASE)\n        return int(match.group(1)) if match else None\n\n    def generate_plots(self, data, columns):\n        \"\"\"Generate appropriate plots based on column-type combinations.\n\n            Args:\n                data: Source DataFrame used to draw figures.\n                columns: Iterable of column pairs to visualize.\n\n            Returns:\n                A collection of figure objects or file paths to saved plots.\n            \"\"\"\n        data = pd.DataFrame(data)\n        for col1, col2 in columns:\n            if col1 in data.columns and col2 in data.columns:\n                if os.path.exists(\"data/num_num.json\"):\n                    with open(\"data/num_num.json\") as file:\n                        result = json.loads(file.read())\n                    correlation_method = next(iter(result.keys())).lower()\n                else:\n                    edaAnalysis(self.eda_cleaned_df, col1, col2)\n                    with open(\"data/num_num.json\") as file:\n                        result = json.loads(file.read())\n                    correlation_method = next(iter(result.keys())).lower()\n\n                return all_graphs(data, col1, col2, correlation_method)\n\n    async def determine_query_type(self, query):\n        \"\"\"Classify the user query into an analysis category.\n\n            Uses LLM-based streaming classification with keyword fallbacks.\n\n            Args:\n                query: End-user prompt.\n\n            Returns:\n                One of ``{\"eda\",\"analyze\",\"shap\",\"geolift\",\"dowecon\",\"causalpy\",\n                \"ts\",\"wiki\",\"plot\",\"ab\",\"assoc\",\"unknown\"}``.\n            \"\"\"\n        classification_prompt = f\"\"\"\n        You are a smart AI assistant that classifies user queries into one of the following categories:\n\n        - eda \u2192 Summary statistics, distributions, correlation tests, variable types\n        - analyze \u2192 Metric behavior over time, performance trends, metric-level changes\n        - shap \u2192 SHAP values, feature importance, model interpretability\n        - geolift \u2192 Regional or geo-based impact, marketing uplift\n        - dowEcon \u2192 DoWhy/EconML causal inference, DAG-based reasoning\n        - causalPy \u2192 Bayesian or time-series causal analysis (e.g. synthetic control)\n        - ts \u2192 Time series analysis, Prophet, forecasting, seasonal decomposition\n        - wiki \u2192 General knowledge or definitions (e.g. \"What is CTR?\")\n        - plot \u2192 Requests for visualizations or chart generation\n        - ab \u2192 A/B testing, experiment comparison, statistical significance tests\n        - assoc \u2192 Association rules, market basket analysis, frequent itemset mining\n\n        Your task: Based on the user query, return ONLY the category name (`eda`, `analyze`, etc.) with no explanation or formatting.\n\n        User query:\n        \\\"{query}\\\"\n\n        Your answer:\n        \"\"\"\n\n        collected = \"\"\n        async for chunk in self.chat_model.astream(classification_prompt):\n            collected += chunk.content\n\n        response = collected.strip().lower()\n\n        valid_categories = {\n            \"eda\", \"analyze\", \"shap\", \"geolift\", \"dowecon\", \"causalpy\", \"ts\", \"wiki\", \"plot\", \"ab\", \"assoc\"\n        }\n\n        for cat in valid_categories:\n            if cat in response:\n                return cat\n\n        # Fallback keyword-based detection for AB Testing\n        ab_keywords = [\"a/b test\", \"ab test\", \"split test\", \"ab testing\", \"experiment comparison\", \"significance test\"]\n        if any(kw in query.lower() for kw in ab_keywords):\n            return \"ab\"\n\n        # Fallback keyword-based detection for Association Rules\n        assoc_keywords = [\n            \"association rules\", \"market basket\", \"apriori\", \"fpgrowth\", \"fp-growth\",\n            \"frequent itemset\", \"lift\", \"confidence\", \"support\"\n        ]\n        if any(kw in query.lower() for kw in assoc_keywords):\n            return \"assoc\"\n\n        if self.parse_causal_query(query):\n            return \"dowecon\"\n        elif self.parse_causalpy_query(query):\n            return \"causalpy\"\n        elif \"time series\" in query.lower() or \"forecast\" in query.lower():\n            return \"ts\"\n\n        return \"unknown\"\n\n\n    @staticmethod\n    def normalize(text):\n        \"\"\"Lowercase and strip special characters for robust matching.\n\n            Args:\n                text: Input string.\n\n            Returns:\n                Normalized string suitable for comparisons.\n            \"\"\"\n        return re.sub(r'[^a-zA-Z0-9]', '', text.lower())\n\n    def find_best_column_match(self, user_column, available_columns, verbose=True):\n        \"\"\"Fuzzy-match the requested column name to the closest available one.\n\n            Args:\n                user_column: Column name as provided by the user.\n                available_columns: Valid columns in the dataset.\n\n            Returns:\n                The best-matching column name, or ``None`` if no acceptable match.\n            \"\"\"\n        user_column_cleaned = self.normalize(user_column)\n\n        column_mapping = {\n            self.normalize(col): col for col in available_columns\n        }\n\n        if user_column_cleaned in column_mapping:\n            matched = column_mapping[user_column_cleaned]\n            if verbose:\n                print(f\"\u2705 [EXACT MATCH] '{user_column}' \u2192 '{matched}'\")\n            return matched\n\n        for norm_col, original_col in column_mapping.items():\n            if user_column_cleaned in norm_col or norm_col.startswith(user_column_cleaned):\n                if verbose:\n                    print(f\"\ud83d\udd0e [SUBSTRING MATCH] '{user_column}' \u2192 '{original_col}'\")\n                return original_col\n\n        closest_match = difflib.get_close_matches(\n            user_column_cleaned, column_mapping.keys(), n=1, cutoff=0.85\n        )\n        if closest_match:\n            matched = column_mapping[closest_match[0]]\n            if verbose:\n                print(f\"\ud83c\udf00 [FUZZY MATCH] '{user_column}' \u2192 '{matched}' (score \u2248 close)\")\n            return matched\n\n        if verbose:\n            print(f\"\u274c [NO MATCH] '{user_column}' \u2192 None\")\n\n        return None\n\n    @staticmethod\n    def validate_columns(cols, cleaned_df, raw_df=None):\n        \"\"\"Validate that requested columns exist in cleaned/raw datasets.\n\n            Args:\n                cols: Column names to validate.\n                cleaned_df: Cleaned DataFrame.\n                raw_df: Optional raw DataFrame for cross-checks.\n\n            Returns:\n                ``None`` if all columns are valid; otherwise a descriptive error message.\n            \"\"\"\n        raw_columns = raw_df.columns.tolist() if raw_df is not None else []\n        for col in cols:\n            if col is None:\n                return \"\u274c One of the columns could not be matched.\"\n            if col not in cleaned_df.columns:\n                if raw_df is not None and col in raw_columns:\n                    return f\"\u26a0\ufe0f Column '{col}' was removed during data cleaning.\"\n                return f\"\u274c Column '{col}' does not exist in the dataset.\"\n        return None\n\n    async def eda_analysis(self, user_query, cleaned_df):\n        \"\"\"Run EDA on two columns detected from the query.\n\n            Detects/validates columns, executes statistical tests and plots\n            (e.g., posterior predictive checks, MCMC traces, ACF), and streams an\n            interpreted summary via ``eda_agent``.\n\n            Args:\n                user_query: Natural language request (must imply \u22652 columns).\n                cleaned_df: EDA-ready DataFrame.\n\n            Yields:\n                Markdown/text chunks summarizing EDA results and visuals.\n            \"\"\"\n        detected_columns = self.extract_columns_from_query(user_query, cleaned_df.columns.tolist())\n\n        if len(detected_columns) &lt; 2:\n            yield \"Please specify at least two valid columns.\"\n            return\n\n        validate_msg = self.validate_columns(detected_columns, cleaned_df, self.df_raw)\n        if validate_msg:\n            yield validate_msg\n            return\n\n        print(\"\ud83e\udde0 Detected columns:\", detected_columns)\n        col1, col2 = detected_columns[:2]\n        print(\"\u27a1\ufe0f Using columns:\", col1, col2)\n\n        edaAnalysis(cleaned_df, col1, col2)\n\n        image_paths = [\"services/AI/plots/pp_check.png\", \"services/AI/plots/mcmc_trace.png\", \"services/AI/plots/mcmc_acf.png\"]\n        predefined_titles = [\"Posterior Predictive Check\", \"MCMC Trace Plot\", \"Autocorrelation Function (ACF)\"]\n        predefined_filenames = [\"pp_check.png\", \"mcmc_trace.png\", \"mcmc_acf.png\"]\n        json_files = {\n            \"num_num\": \"services/AI/data/num_num.json\",\n            \"num_cat\": \"services/AI/data/num_cat.json\",\n            \"cat_cat\": \"services/AI/data/cat_cat.json\"\n        }\n\n        run_test(image_paths, predefined_titles, predefined_filenames, \"services/AI/plots/scientific_image_analysis.json\", \"eda\")\n\n        try:\n            async for chunk in self.eda_agent(json_files, cleaned_df, col1, col2, user_query):\n                yield chunk\n        except Exception as e:\n            print(\"\u274c EDA Agent Exception:\", str(e))\n            yield \"EDA analysis failed due to internal error.\"\n\n    @staticmethod\n    def extract_shap_target_column(query: str, available_columns: list[str]) -&gt; str:\n        query = query.lower()\n        for col in available_columns:\n            if col.lower() in query:\n                return col\n        return None\n\n    async def shap_analysis(self, user_query, cleaned_df):\n        \"\"\"Compute and explain SHAP values for a detected target variable.\n\n            Trains the best-fit model for the target and streams SHAP interpretation\n            via ``shap_agent``.\n\n            Args:\n                user_query: Query mentioning a target metric (e.g., ``\"CTR\"``).\n                cleaned_df: Cleaned DataFrame used for modeling.\n\n            Yields:\n                Narrative chunks covering global/local importance and caveats.\n            \"\"\"\n        available_columns = cleaned_df.columns.tolist()\n        target_var = self.extract_shap_target_column(user_query, available_columns)\n\n        if not target_var:\n            yield \"\u274c Could not detect a target variable for SHAP analysis. Try asking about a specific variable like 'CTR' or 'conversions'.\"\n            return\n\n        validate_msg = self.validate_columns([target_var], cleaned_df, self.df_raw)\n        if validate_msg:\n            yield validate_msg\n            return\n\n        try:\n            getBestModel(cleaned_df, target_var, query=user_query)\n        except Exception as e:\n            print(\"\u274c Error in SHAP model training:\", str(e))\n            yield f\"\u274c Failed to compute SHAP analysis: {e}\"\n            return\n\n        try:\n            async for chunk in self.shap_agent(target_var, user_query):\n                yield chunk\n        except Exception as e:\n            print(\"\u274c Shap Agent Exception:\", str(e))\n            yield \"Shap analysis failed due to internal error.\"\n\n    async def ts_analysis(self, user_query, cleaned_df):\n        \"\"\"Perform time-series analysis (Prophet forecasts / Granger tests).\n\n            Expands ranges to daily level, infers forecast horizon and metric(s),\n            runs forecasts and/or Granger causality, optionally builds a dashboard,\n            and streams explanations via ``ts_agent``.\n\n            Args:\n                user_query: Forecast/causality question (may include horizon like \u201cnext 30 days\u201d).\n                cleaned_df: Time-series-ready DataFrame.\n\n            Yields:\n                Stepwise summaries and final conclusions with saved artifacts.\n            \"\"\"\n        expander = DailyDistributionExpander()\n        metrics_to_expand = cleaned_df.select_dtypes(include=[np.number]).columns.tolist()\n        dashboard=None\n        daily_df = expander.expand(\n            cleaned_df,\n            metrics_to_expand,\n            start_col='date_start',\n            end_col='date_stop',\n            id_col='campaign_name'\n        )\n\n        daily_df.columns = [\n            col.replace(\"daily_\", \"\") if col.startswith(\"daily_\") else col\n            for col in daily_df.columns\n        ]\n\n        query = user_query.lower()\n        found_cols = [col for col in metrics_to_expand if col.lower() in query]\n        forecast_horizon = 30\n\n        day_match = re.search(r\"(\\d+)\\s*(g[\u00fcu]n|day[s]?)\", query)\n        company = None\n        for c in daily_df[\"campaign_name\"].unique().tolist():\n            if re.search(rf\"\\b{re.escape(c.lower())}\\b\", query.lower()):\n                company = c\n                break\n        if day_match:\n            forecast_horizon = int(day_match.group(1))\n        if len(found_cols) == 0:\n            process = {\"mode\": \"general\", \"forecast\": False, \"granger\": False, \"columns\": [], \"horizon\": forecast_horizon}\n\n        elif len(found_cols) == 1:\n            process= {\"mode\": \"single_metric\", \"forecast\": True, \"granger\": True, \"columns\": found_cols,\n                    \"horizon\": forecast_horizon}\n\n        elif len(found_cols) == 2:\n            process= {\"mode\": \"pairwise_granger\", \"forecast\": False, \"granger\": True, \"columns\": found_cols,\n                    \"horizon\": None}\n\n        else:\n            process= {\"mode\": \"multi_column_ambiguous\", \"forecast\": False, \"granger\": False, \"columns\": found_cols,\n                    \"horizon\": None}\n\n        analyzer = TimeSeriesAnalyzer(df=daily_df, company=company, country=\"TR\")\n\n        if process[\"mode\"] == \"general\":\n            all_columns = metrics_to_expand\n            all_results = []\n\n            for col in all_columns:\n                result = analyzer.run_prophet(col=col, horizon=process[\"horizon\"])\n                result[\"metric\"] = col\n                all_results.append(result)\n\n            with open(f\"services/AI/data/ts_metrics.json\", \"w\") as f:\n                json.dump(all_results, f, indent=4)\n\n\n        elif process[\"mode\"] == \"single_metric\" and len(process[\"columns\"]) == 1:\n            col = process[\"columns\"][0]\n\n            forecast_result = analyzer.run_prophet(col=col, horizon=process[\"horizon\"])\n\n            granger_result = analyzer.run_granger(col1=col, col2=None)\n\n            dashboard = analyzer.plot_forecast_dashboard()\n\n            combined_result = {\n                \"metric\": col,\n                \"forecast_result\": forecast_result,\n                \"granger_result\": granger_result\n            }\n            output_path = f\"services/AI/data/ts_metrics.json\"\n            with open(output_path, \"w\") as f:\n                json.dump(combined_result, f, indent=4)\n\n            # dashboard.servable(\"Forecast Dashboard\")\n\n\n        elif process[\"mode\"] == \"pairwise_granger\" and len(process[\"columns\"]) == 2:\n            col1, col2 = process[\"columns\"]\n\n            granger_result = analyzer.run_granger(col1=col1, col2=col2)\n\n            result_data = {\n                \"mode\": \"pairwise_granger\",\n                \"col1\": col1,\n                \"col2\": col2,\n                \"granger_result\": granger_result\n            }\n\n            filename = f\"services/AI/data/ts_metrics.json\"\n\n            with open(filename, \"w\") as f:\n                json.dump(result_data, f, indent=4)\n\n            print(f\"Granger result saved to {filename}\")\n\n\n        else:\n            print(\"No valid processing mode matched.\")\n\n        try:\n            async for chunk in self.ts_agent(user_query, dashboard):\n                yield chunk\n        except Exception as e:\n            print(\"\u274c Time Series Agent Exception:\", str(e))\n            yield \"Time Series analysis failed due to internal error.\"\n\n\n    def parse_geolift_query(self, user_query: str):\n        import re\n\n        patterns = [\n            r\"using (\\w+) as metric.*?(\\w+) as location.*?(\\w+) as date\",\n            r\"metric\\s*[:=]\\s*(\\w+).*?location\\s*[:=]\\s*(\\w+).*?date\\s*[:=]\\s*(\\w+)\",\n            r\"(\\w+)\\s+for\\s+metric.*?(\\w+)\\s+for\\s+location.*?(\\w+)\\s+for\\s+date\",\n            r\"metric is (\\w+).*?location is (\\w+).*?date is (\\w+)\",\n        ]\n\n        for pattern in patterns:\n            match = re.search(pattern, user_query, re.IGNORECASE)\n            if match:\n                groups = match.groups()\n                return {\n                    \"metric\": groups[0],\n                    \"location\": groups[1],\n                    \"date\": groups[2]\n                }\n        return None\n\n    def geo_analysis(self, user_query, df):\n        \"\"\"Run GeoLift power/impact analysis from a structured query.\n\n            Parses metric/location/date, optional hyperparameters (budget, cpic, alpha,\n            treatment start/duration), renames columns to GeoLift schema, executes\n            ``powerAnalysis``, and returns an interpreted summary via ``geo_agent``.\n\n            Args:\n                user_query: Structured query (e.g., ``Using revenue as metric ...``).\n                df: DataFrame containing metric, location, and date columns.\n\n            Returns:\n                Natural-language explanation of the GeoLift setup and results.\n            \"\"\"\n        import os\n        import re\n\n        budget_value = 10000\n        cpic = None\n        alpha = 0.05\n        treatment_start = None\n        treatment_duration = None\n        #df = pd.read_csv(\"geo_data.csv\")\n        #raw_columns = df.columns.tolist()\n        raw_columns = self.df_raw.columns.tolist()\n        available_columns = df.columns.tolist()\n        removed = []\n\n        # \ud83e\udde0 Kolonlar\u0131 query'den \u00e7\u0131karmaya \u00e7al\u0131\u015f\n        parsed = self.parse_geolift_query(user_query)\n        if not parsed:\n            return \"\u274c Could not extract metric, location, and date columns from your query. Use formats like: 'Using spend as metric and region as location and date as date'.\"\n\n        metric_col = self.find_best_column_match(parsed[\"metric\"], available_columns)\n        location_col = self.find_best_column_match(parsed[\"location\"], available_columns)\n        date_col = self.find_best_column_match(parsed[\"date\"], available_columns)\n\n        # \u2705 Kolonlar\u0131n mevcudiyetini kontrol et\n        for col_name, var in [(\"Metric\", metric_col), (\"Location\", location_col), (\"Date\", date_col)]:\n            if not var:\n                removed.append(f\"\u274c {col_name} column not specified or matched in the dataset.\")\n            elif var not in raw_columns:\n                removed.append(f\"\u274c {col_name} column '{var}' does not exist in the dataset.\")\n            elif var not in available_columns:\n                removed.append(f\"\u26a0\ufe0f {col_name} column '{var}' was removed during data cleaning.\")\n\n        if any(msg.startswith(\"\u274c\") or msg.startswith(\"\u26a0\ufe0f Metric\") for msg in removed):\n            return \"\\n\".join(removed) + \"\\n\u274c Cannot proceed with GeoLift analysis.\"\n\n        if match := re.search(r\"budget (\\d+(?:\\.\\d+)?)\", user_query, re.IGNORECASE):\n            budget_value = float(match.group(1))\n\n        if match := re.search(r\"cpic (\\d+(?:\\.\\d+)?)\", user_query, re.IGNORECASE):\n            cpic = float(match.group(1))\n\n        if match := re.search(r\"alpha (\\d+(?:\\.\\d+)?)\", user_query, re.IGNORECASE):\n            alpha = float(match.group(1))\n\n        if match := re.search(r\"treatment start (\\d{4}-\\d{2}-\\d{2})\", user_query, re.IGNORECASE):\n            treatment_start = match.group(1)\n\n        if match := re.search(r\"treatment duration (\\d+)\", user_query, re.IGNORECASE):\n            treatment_duration = int(match.group(1))\n\n        # \ud83d\udd04 GeoLift i\u00e7in rename et\n        df = df.rename(columns={\n            date_col: \"time\",\n            location_col: \"location\",\n            metric_col: \"Y\"\n        })\n\n        os.makedirs(\"services/AI/data\", exist_ok=True)\n\n        powerAnalysis(\n            df=df,\n            date_id=\"time\",\n            location_id=\"location\",\n            y_id=\"Y\",\n            budget=budget_value,\n            cpic=cpic,\n            treatment_start=treatment_start,\n            treatment_duration=treatment_duration,\n            alpha=alpha\n        )\n\n        return self.geo_agent(\"services/AI/data/model_summaries.json\", user_query)\n\n    @staticmethod\n    def parse_causal_query(user_query: str):\n        import re\n\n        patterns = [\n            # 1. Original explicit format\n            r\"Using (\\w+) as treatment and (\\w+) as outcome,? analyze the causal effect(?: with confounders \\[(.*?)\\])?(?: and instrument (\\w+))?(?: at time (\\d+))?(?: with target unit (\\w+))?\",\n\n            # 2. Simpler natural language\n            r\"effect of (\\w+) on (\\w+)(?: with confounders \\[(.*?)\\])?(?: instrument (\\w+))?(?: time (\\d+))?(?: target unit (\\w+))?\",\n\n            # 3. Very relaxed key=value style\n            r\"treatment\\s*=\\s*(\\w+).*?outcome\\s*=\\s*(\\w+)(?:.*?confounders\\s*=\\s*\\[(.*?)\\])?(?:.*?instrument\\s*=\\s*(\\w+))?(?:.*?time\\s*=\\s*(\\d+))?(?:.*?target\\s*unit\\s*=\\s*(\\w+))?\"\n        ]\n\n        for pattern in patterns:\n            match = re.search(pattern, user_query, re.IGNORECASE)\n            if match:\n                groups = match.groups()\n                return {\n                    \"treatment\": groups[0],\n                    \"outcome\": groups[1],\n                    \"confounders\": [x.strip() for x in groups[2].split(\",\")] if groups[2] else [],\n                    \"instrument\": groups[3] if len(groups) &gt; 3 else None,\n                    \"treatment_time\": int(groups[4]) if len(groups) &gt; 4 and groups[4] else None,\n                    \"target_unit\": groups[5] if len(groups) &gt; 5 else None\n                }\n\n        return None\n\n    @staticmethod\n    def parse_causalpy_query(user_query: str):\n        import re\n\n        patterns = [\n            # 1. Net format: Using outcome with predictors\n            r\"Using (\\w+) as outcome.*?with predictors \\[(.*?)\\](?:.*?at time (\\d+))?\",\n\n            # 2. Key=value format\n            r\"outcome\\s*=\\s*(\\w+).*?predictors\\s*=\\s*\\[(.*?)\\](?:.*?time\\s*=\\s*(\\d+))?\",\n\n            # 3. Basit do\u011fal dil\n            r\"effect on (\\w+) with predictors \\[(.*?)\\](?: time (\\d+))?\"\n        ]\n\n        for pattern in patterns:\n            match = re.search(pattern, user_query, re.IGNORECASE)\n            if match:\n                groups = match.groups()\n                return {\n                    \"outcome\": groups[0],\n                    \"predictors\": [x.strip() for x in groups[1].split(\",\")] if groups[1] else [],\n                    \"treatment_time\": int(groups[2]) if len(groups) &gt; 2 and groups[2] else None\n                }\n\n        return None\n\n    def dowhy_econml_analysis(self, user_query, cleaned_df):\n        \"\"\"Estimate causal effects with DoWhy/EconML and interpret results.\n\n            Parses treatment/outcome/confounders (and optional instrument, treatment_time,\n            target_unit), validates variables, runs ``causalModel``, generates diagnostics,\n            and summarizes results via ``dowhy_agent``.\n\n            Args:\n                user_query: Causal query (key-value format).\n                cleaned_df: Cleaned DataFrame suitable for causal estimation.\n\n            Returns:\n                Final narrative; prepended with warnings if variables were missing/removed.\n            \"\"\"\n        import os\n\n        parsed = self.parse_causal_query(user_query)\n\n        if not parsed:\n            return \"\u274c Could not parse the query format...\"\n\n        treatment_var = parsed[\"treatment\"]\n        outcome_var = parsed[\"outcome\"]\n        confounders_var = parsed[\"confounders\"]\n        instrument_var = parsed.get(\"instrument\")\n        treatment_time_var = parsed.get(\"treatment_time\")\n        target_unit_var = parsed.get(\"target_unit\") or treatment_var\n\n        raw_columns = self.df_raw.columns.tolist()\n        available_columns = cleaned_df.columns.tolist()\n        removed = []\n\n        # 1. treatment\n        if treatment_var not in raw_columns:\n            removed.append(f\"\u274c Treatment column '{treatment_var}' does not exist in the dataset.\")\n        elif treatment_var not in available_columns:\n            removed.append(f\"\u26a0\ufe0f Treatment column '{treatment_var}' was removed due to high VIF.\")\n\n        # 2. outcome\n        if outcome_var not in raw_columns:\n            removed.append(f\"\u274c Outcome column '{outcome_var}' does not exist in the dataset.\")\n        elif outcome_var not in available_columns:\n            removed.append(f\"\u26a0\ufe0f Outcome column '{outcome_var}' was removed due to high VIF.\")\n\n        # 3. instrument\n        if instrument_var:\n            if instrument_var not in raw_columns:\n                removed.append(f\"\u274c Instrument column '{instrument_var}' does not exist in the dataset.\")\n                instrument_var = None\n            elif instrument_var not in available_columns:\n                removed.append(f\"\u26a0\ufe0f Instrument column '{instrument_var}' was removed due to high VIF.\")\n                instrument_var = None\n\n        # 4. target_unit\n        if target_unit_var not in raw_columns:\n            removed.append(f\"\u274c Target unit column '{target_unit_var}' does not exist in the dataset.\")\n            target_unit_var = treatment_var\n        elif target_unit_var not in available_columns:\n            removed.append(f\"\u26a0\ufe0f Target unit column '{target_unit_var}' was removed due to high VIF.\")\n            target_unit_var = treatment_var\n\n        # 5. confounders\n        valid_confounders = []\n        removed_confounders = []\n        missing_confounders = []\n\n        for c in confounders_var:\n            if c not in raw_columns:\n                missing_confounders.append(c)\n            elif c not in available_columns:\n                removed_confounders.append(c)\n            else:\n                valid_confounders.append(c)\n\n        if missing_confounders:\n            removed.append(f\"\u274c These confounders do not exist in the dataset: {missing_confounders}\")\n        if removed_confounders:\n            removed.append(f\"\u26a0\ufe0f These confounders were removed due to high VIF: {removed_confounders}\")\n\n        confounders_var = valid_confounders\n\n        # 6. Kritik eksikler varsa i\u015flemi iptal et\n        if any(msg.startswith(\"\u274c\") or msg.startswith(\"\u26a0\ufe0f Treatment\") or msg.startswith(\"\u26a0\ufe0f Outcome\") for msg in\n               removed):\n            return \"\\n\".join(removed) + \"\\n\u274c Cannot proceed with analysis due to missing key variables.\"\n\n        # 4. Kolon isimlerini normalize et\n        treatment_var = self.find_best_column_match(treatment_var, available_columns)\n        outcome_var = self.find_best_column_match(outcome_var, available_columns)\n        if instrument_var:\n            instrument_var = self.find_best_column_match(instrument_var, available_columns)\n        confounders_var = [self.find_best_column_match(c, available_columns) for c in confounders_var]\n        target_unit_var = self.find_best_column_match(target_unit_var, available_columns)\n\n        # 5. Son kontrol\n        validate_msg = self.validate_columns(\n            [treatment_var, outcome_var, target_unit_var] +\n            ([instrument_var] if instrument_var else []) +\n            confounders_var,\n            cleaned_df,\n            self.df_raw\n        )\n        if validate_msg:\n            return validate_msg\n\n        # 6. Analizi \u00e7al\u0131\u015ft\u0131r\n        os.makedirs(\"services/AI/data\", exist_ok=True)\n        os.makedirs(\"services/AI/plots\", exist_ok=True)\n\n        causalModel(\n            cleaned_df,\n            treatment=treatment_var,\n            outcome=outcome_var,\n            confounders=confounders_var,\n            instrument=instrument_var,\n            treatment_time=treatment_time_var,\n            target_unit=target_unit_var\n        )\n\n        image_paths = [\"services/AI/plots/unobserved_confounder_heatmap.png\"]\n        predefined_titles = [\"DoWhy Unobserved Confounder Heatmap\"]\n        predefined_filenames = [\"unobserved_confounder_heatmap.png\"]\n        json_file = \"services/AI/data/dowhy_econml_causal.json\"\n\n        run_test(image_paths, predefined_titles, predefined_filenames, \"services/AI/plots/dowhy_image_analysis.json\",\n                 \"dowhy\")\n        dowhy_result = self.dowhy_agent(json_file, user_query)\n\n        # 7. Uyar\u0131lar\u0131 analizin ba\u015f\u0131na ekleyerek d\u00f6nd\u00fcr\n        if removed:\n            return \"\\n\".join(removed) + \"\\n\\n\u2705 Analysis completed:\\n\" + dowhy_result\n        else:\n            return dowhy_result\n\n    def causalPy_analysis(self, user_query, cleaned_df):\n        \"\"\"Run CausalPy synthetic control (Sklearn and Bayesian) and explain impact.\n\n            Parses outcome/predictors/treatment_time, validates variables, executes\n            ``synthetic_control`` variants, saves plots/JSON, and summarizes via\n            ``causalpy_agent``.\n\n            Args:\n                user_query: CausalPy query (e.g., ``Using revenue as outcome, ...``).\n                cleaned_df: Cleaned DataFrame.\n\n            Returns:\n                Narrative summary; warnings (if any) are prepended to the final text.\n            \"\"\"\n        parsed = self.parse_causalpy_query(user_query)  # \u2705 Ayn\u0131 regex yap\u0131s\u0131 kullan\u0131l\u0131r\n\n        if not parsed:\n            return \"\u274c Could not parse the query format for CausalPy. Use formats like: 'Using X as outcome, analyze the causal effect with predictors [A, B, C] at time 10'.\"\n\n        outcome_var = parsed[\"outcome\"]\n        predictors_var = parsed[\"predictors\"]\n        treatment_time_var = parsed.get(\"treatment_time\")\n\n        raw_columns = self.df_raw.columns.tolist()\n        available_columns = cleaned_df.columns.tolist()\n        removed = []\n\n        # Outcome\n        if outcome_var not in raw_columns:\n            removed.append(f\"\u274c Outcome column '{outcome_var}' does not exist in the dataset.\")\n        elif outcome_var not in available_columns:\n            removed.append(f\"\u26a0\ufe0f Outcome column '{outcome_var}' was removed due to high VIF.\")\n\n        # Predictors\n        valid_predictors = []\n        removed_predictors = []\n        missing_predictors = []\n\n        for c in predictors_var:\n            if c not in raw_columns:\n                missing_predictors.append(c)\n            elif c not in available_columns:\n                removed_predictors.append(c)\n            else:\n                valid_predictors.append(c)\n\n        if missing_predictors:\n            removed.append(f\"\u274c These predictors do not exist in the dataset: {missing_predictors}\")\n        if removed_predictors:\n            removed.append(f\"\u26a0\ufe0f These predictors were removed due to high VIF: {removed_predictors}\")\n\n        predictors_var = valid_predictors\n\n        # Check if critical elements are missing\n        if any(msg.startswith(\"\u274c\") or msg.startswith(\"\u26a0\ufe0f Outcome\") for msg in removed):\n            return \"\\n\".join(removed) + \"\\n\u274c Cannot proceed with analysis due to missing key variables.\"\n\n        # Match actual column names (fuzzy matching)\n        outcome_var = self.find_best_column_match(outcome_var, available_columns)\n        predictors_var = [self.find_best_column_match(c, available_columns) for c in predictors_var]\n\n        validate_msg = self.validate_columns([outcome_var] + predictors_var, cleaned_df, self.df_raw)\n        if validate_msg:\n            return validate_msg\n\n        # Run analysis\n        os.makedirs(\"services/AI/data\", exist_ok=True)\n        os.makedirs(\"services/AI/plots\", exist_ok=True)\n\n        try:\n            synthetic_control(\n                df=cleaned_df,\n                outcome=outcome_var,\n                predictors=predictors_var,\n                treatment_time=treatment_time_var\n            )\n\n            image_paths = [\n                \"services/AI/plots/synthetic_control_with_sklearn.png\",\n                \"services/AI/plots/synthetic_control_with_bayesian.png\"\n            ]\n            predefined_titles = [\n                \"Synthetic Control (Sklearn-Based)\",\n                \"Bayesian Synthetic Control (PyMC)\"\n            ]\n            predefined_filenames = [\n                \"synthetic_control_with_sklearn.png\",\n                \"synthetic_control_with_bayesian.png\"\n            ]\n            json_file = \"services/AI/data/sklearn_and_bayesian_causal_impact_summary.json\"\n\n            if not os.path.exists(json_file):\n                return \"\u274c Error: JSON file containing causal analysis results was not created.\"\n\n            run_test(image_paths, predefined_titles, predefined_filenames,\n                     \"services/AI/plots/bayesian_sklearn_image_analysis.json\", \"causalpy\")\n            result = self.causalpy_agent(json_file, user_query)\n\n        except Exception as e:\n            result = f\"\u274c An error occurred during CausalPy analysis: {str(e)}\"\n\n        return \"\\n\".join(removed) + \"\\n\\n\u2705 Analysis completed:\\n\" + result if removed else result\n\n    async def combined_analysis(self, query):\n        \"\"\"Route a user query to the appropriate analysis pipeline and stream outputs.\n\n            Uses ``determine_query_type`` and clears previous state (non-wiki). Dispatches to\n            EDA/SHAP/TS/GeoLift/DoWhy-EconML/CausalPy/AB/Assoc or general agent/search.\n\n            Args:\n                query: End-user question.\n\n            Yields:\n                Streaming results produced by the selected pipeline.\n            \"\"\"\n        query_type = await self.determine_query_type(query)\n        print(f\"\ud83e\udde0 DEBUG: Determined Query Type \u2192 {query_type}\")\n        if query_type != \"wiki\":\n            self.checkpointer.delete_thread(self.user_id)\n        if query_type == \"dowecon\":\n            print(\"\ud83d\udd0d Running **Causal Inference Analysis With DoWhy and EconML**...\")\n            dowhy_results = self.dowhy_econml_analysis(query, self.df_raw.copy())\n            self.console.print(Markdown(dowhy_results))\n            print(\"\u2705 Analysis results saved.\")\n            yield dowhy_results\n\n        elif query_type == \"causalpy\":\n            print(\"\ud83d\udd0d Running **Bayesian CausalPy Analysis**...\")\n            causalPy_res = self.causalPy_analysis(query, self.df_raw.copy())\n            self.console.print(Markdown(causalPy_res))\n            print(\"\u2705 Analysis results saved.\")\n            yield causalPy_res\n\n        elif query_type == \"eda\":\n            print(\"\ud83d\udd0d Running **EDA Analysis**...\")\n            async for chunk in self.eda_analysis(query, self.eda_cleaned_df):\n                yield chunk\n\n        elif query_type == \"shap\":\n            print(\"\ud83d\udd0d Running **SHAP Analysis**...\")\n            async for chunk in self.shap_analysis(query, self.causal_cleaned_df):\n                yield chunk\n\n        elif query_type == \"geolift\":\n            print(\"\ud83d\udd0d Running **GeoLift Analysis**...\")\n            geo_df = self.df_raw.copy().dropna()\n            async for chunk in self.geo_analysis(query, geo_df):\n                yield chunk\n\n        elif query_type == \"analyze\":\n            print(\"\ud83d\udd0d Running **General Agent Analysis**...\")\n            async for chunk in self.analyze_agent(query):\n                yield chunk\n\n        elif query_type == \"wiki\":\n            print(\"\ud83d\udd0d Running **Wikipedia Searching**...\")\n            async for chunk in self.wiki_agent(query):\n                yield chunk\n\n        elif query_type == \"ts\":\n            print(\"\ud83d\udd0d Running **Time Series Analysis**...\")\n            async for chunk in self.ts_analysis(query, self.ts_cleaned_df):\n                yield chunk\n\n\n        elif query_type == \"ab\":\n            print(\"\ud83d\udd0d Running **A-B Testing Analysis**...\")\n            get_analysis(self.ts_cleaned_df, query)\n            async for chunk in self.ab_agent(query):\n                yield chunk\n\n        elif query_type == \"assoc\":\n            print(\"\ud83d\udd0d Running **Association Rules**...\")\n            run_assoc(self.ts_cleaned_df, query)\n            async for chunk in self.assoc_agent(query):\n                yield chunk\n        else:\n            yield \"\u274c Could not determine the analysis type. Please refine your query.\"\n\n    async def combined_analysis_plots(self, query):\n        \"\"\"Generate visualizations when the query intent is plotting.\n\n            Detects plotting intent, coerces datetime-like object columns, extracts target\n            columns, forms pairwise combinations, and produces figures via ``generate_plots``.\n\n            Args:\n                query: Visualization request mentioning \u22652 columns.\n\n            Returns:\n                A list of figure objects or saved file paths (implementation-specific).\n            \"\"\"\n        query_type = await self.determine_query_type(query)\n        print(f\"\ud83e\udde0 DEBUG: Determined Query Type \u2192 {query_type}\")\n\n        if query_type == \"plot\":\n            print(\"\ud83d\udd0d Running **PLOT Analysis**...\")\n\n            plot_df = self.df_raw.dropna()\n            datetime_cols = []\n            for col in plot_df.select_dtypes(include=['object']).columns:\n                try:\n                    converted = pd.to_datetime(plot_df[col], errors='coerce')\n                    if converted.notna().sum() / len(converted) &gt; 0.7:\n                        datetime_cols.append(col)\n                        plot_df[col] = converted\n                except Exception:\n                    pass\n\n            print(f\"\u2705 Identified datetime columns: {datetime_cols}\")\n            available_columns = plot_df.columns.tolist()\n            detected_columns = self.extract_columns_from_query(query, available_columns)\n\n            if len(detected_columns) &lt; 2:\n                print(\"\u274c Please specify at least two valid columns for visualization.\")\n                return\n\n            column_combinations = list(combinations(detected_columns, 2))\n            plots = self.generate_plots(plot_df, column_combinations)\n            print(\"\u2705 Plot successfully generated!\")\n            return plots\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.load_docs_from_file","title":"load_docs_from_file  <code>staticmethod</code>","text":"<pre><code>load_docs_from_file(path, source_name)\n</code></pre> <p>Load a document from disk and prepare it for vector indexing.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Absolute or relative path to the source document.</p> required <code>source_name</code> <code>str</code> <p>Logical source identifier to tag the document with.</p> required <p>Returns:</p> Type Description <code>list[Document]</code> <p>A normalized document object or list of chunks, ready for embedding/indexing.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>path</code> does not exist.</p> <code>ValueError</code> <p>If file type is unsupported.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>@staticmethod\ndef load_docs_from_file(path: str, source_name: str) -&gt; list[Document]:\n    \"\"\"Load a document from disk and prepare it for vector indexing.\n\n        Args:\n            path: Absolute or relative path to the source document.\n            source_name: Logical source identifier to tag the document with.\n\n        Returns:\n            A normalized document object or list of chunks, ready for embedding/indexing.\n\n        Raises:\n            FileNotFoundError: If ``path`` does not exist.\n            ValueError: If file type is unsupported.\n        \"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        content = f.read()\n    return [Document(page_content=content, metadata={\"source\": source_name})]\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.init_pgvector_retriever","title":"init_pgvector_retriever  <code>staticmethod</code>","text":"<pre><code>init_pgvector_retriever(\n    docs, collection_name, namespace, embeddings_model\n)\n</code></pre> <p>Initialize a PgVector-backed retriever.</p> <p>Parameters:</p> Name Type Description Default <code>docs</code> <p>Iterable of documents/chunks to index.</p> required <code>collection_name</code> <code>str</code> <p>PgVector collection/table name.</p> required <code>namespace</code> <code>str</code> <p>Logical namespace to isolate indexes.</p> required <code>embeddings_model</code> <p>Embedding model instance or identifier.</p> required <p>Returns:</p> Type Description <p>A configured retriever object usable by RAG agents.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>@staticmethod\ndef init_pgvector_retriever(docs, collection_name: str, namespace: str, embeddings_model):\n    \"\"\"Initialize a PgVector-backed retriever.\n\n        Args:\n            docs: Iterable of documents/chunks to index.\n            collection_name: PgVector collection/table name.\n            namespace: Logical namespace to isolate indexes.\n            embeddings_model: Embedding model instance or identifier.\n\n        Returns:\n            A configured retriever object usable by RAG agents.\n        \"\"\"\n    connection = config(\"PGVECTOR_CONNECTION_STRING\")\n\n    vectorstore = PGVector(\n        embeddings=embeddings_model,\n        collection_name=collection_name,\n        connection=connection,\n        use_jsonb=True,\n    )\n\n    record_manager = SQLRecordManager(\n        namespace,\n        db_url=connection,\n    )\n    record_manager.create_schema()\n\n    index(\n        docs,\n        record_manager,\n        vectorstore,\n        cleanup=\"incremental\",\n        source_id_key=\"source\"\n    )\n\n    return vectorstore.as_retriever(search_kwargs={\"k\": 5})\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.init_pg_rag_retriever","title":"init_pg_rag_retriever  <code>staticmethod</code>","text":"<pre><code>init_pg_rag_retriever(\n    agent_name,\n    lang,\n    file_path=None,\n    embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n)\n</code></pre> <p>Build a complete RAG pipeline (load \u2192 embed \u2192 index \u2192 retrieve).</p> <p>Parameters:</p> Name Type Description Default <code>agent_name</code> <code>str</code> <p>Identifier for the consumer agent.</p> required <code>lang</code> <code>str</code> <p>Language code used for prompt templates (e.g., <code>\"tr\"</code>, <code>\"en\"</code>).</p> required <code>file_path</code> <code>str</code> <p>Path of the document to ingest.</p> <code>None</code> <code>embedding_model_name</code> <code>str</code> <p>Name or handle of the embedding model.</p> <code>'sentence-transformers/all-MiniLM-L6-v2'</code> <p>Returns:</p> Type Description <p>A ready-to-use retriever bound to the ingested corpus.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>@staticmethod\ndef init_pg_rag_retriever(\n        agent_name: str,\n        lang: str,\n        file_path: str = None,\n        embedding_model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n):\n    \"\"\"Build a complete RAG pipeline (load \u2192 embed \u2192 index \u2192 retrieve).\n\n        Args:\n            agent_name: Identifier for the consumer agent.\n            lang: Language code used for prompt templates (e.g., ``\"tr\"``, ``\"en\"``).\n            file_path: Path of the document to ingest.\n            embedding_model_name: Name or handle of the embedding model.\n\n        Returns:\n            A ready-to-use retriever bound to the ingested corpus.\n        \"\"\"\n    source = f\"{agent_name}_{lang}\"\n    collection = f\"{source}_col\"\n    namespace = f\"{source}_ns\"\n\n    if file_path is None:\n        file_path = f\"services/AI/RAG/texts/{source}.txt\"\n\n    docs = Herakleitos.load_docs_from_file(file_path, source_name=source)\n\n    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n\n    retriever = Herakleitos.init_pgvector_retriever(\n        docs=docs,\n        collection_name=collection,\n        namespace=namespace,\n        embeddings_model=embeddings\n    )\n\n    return retriever\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.generate_prompt","title":"generate_prompt","text":"<pre><code>generate_prompt(\n    query, prompt_tr, prompt_en, lang=\"tr\", **kwargs\n)\n</code></pre> <p>Create a chat prompt template from the user query and language.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>End-user query in natural language.</p> required <code>prompt_tr</code> <p>Turkish system template string.</p> required <code>prompt_en</code> <p>English system template string.</p> required <code>lang</code> <p>Language selector (<code>\"tr\"</code> or <code>\"en\"</code>).</p> <code>'tr'</code> <code>**kwargs</code> <p>Extra template variables.</p> <code>{}</code> <p>Returns:</p> Type Description <p>A <code>ChatPromptTemplate</code> (or equivalent) ready for the LLM.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>def generate_prompt(self, query, prompt_tr, prompt_en, lang=\"tr\", **kwargs):\n    \"\"\"Create a chat prompt template from the user query and language.\n\n        Args:\n            query: End-user query in natural language.\n            prompt_tr: Turkish system template string.\n            prompt_en: English system template string.\n            lang: Language selector (``\"tr\"`` or ``\"en\"``).\n            **kwargs: Extra template variables.\n\n        Returns:\n            A ``ChatPromptTemplate`` (or equivalent) ready for the LLM.\n        \"\"\"\n\n    # \ud83d\udccc 1. Sistem rol\u00fc her zaman ayn\u0131\n    system_prompt = SystemMessagePromptTemplate.from_template(\n        \"You are a helpful assistant who answers clearly and with context.\"\n    )\n\n    # \ud83d\udccc 2. Kullan\u0131c\u0131 mesaj\u0131 \u015fablonu se\u00e7ilir\n    human_prompt_template = prompt_tr if lang == \"tr\" else prompt_en\n    human_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n\n    # \ud83d\udccc 3. ChatPromptTemplate olu\u015fturulur\n    chat_prompt = ChatPromptTemplate.from_messages([\n        system_prompt,\n        human_prompt\n    ])\n\n    # \ud83d\udccc 4. input dictionary\u2019yi haz\u0131rla\n    prompt_inputs = {\"query\": query, **kwargs}\n\n    return chat_prompt, prompt_inputs\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.analyze_single_column","title":"analyze_single_column  <code>async</code>","text":"<pre><code>analyze_single_column(column, query)\n</code></pre> <p>Run deep analysis for a single column using an agent + RAG context.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <p>Target column name in the dataset.</p> required <code>query</code> <p>Natural language question to steer the analysis.</p> required <p>Yields:</p> Type Description <p>Text or Markdown chunks describing insights, tests, and plots.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def analyze_single_column(self, column, query):\n    \"\"\"Run deep analysis for a single column using an agent + RAG context.\n\n        Args:\n            column: Target column name in the dataset.\n            query: Natural language question to steer the analysis.\n\n        Yields:\n            Text or Markdown chunks describing insights, tests, and plots.\n        \"\"\"\n    df = self.eda_cleaned_df.copy()\n    time_cols = [col for col in df.columns if \"date\" in col.lower() or \"start\" in col.lower()]\n    if time_cols:\n        date_col = time_cols[0]\n        try:\n            df = df.sort_values(by=date_col)\n            df = df.set_index(date_col)\n        except Exception as e:\n            print(f\"\u26a0\ufe0f Can't convert date column: {e}\")\n\n    # Agent olu\u015ftur\n    python_tool = PythonREPLTool()\n    create_agent = create_pandas_dataframe_agent(\n        llm=self.chat_model,\n        df=df,\n        allow_dangerous_code=True,\n        handle_parsing_errors=True,\n        verbose=True,\n        tools=[python_tool],\n        callbacks=[StreamingStdOutCallbackHandler()]\n    )\n\n    # Agent \u00e7al\u0131\u015ft\u0131r\n    try:\n        response = await create_agent.ainvoke(query)\n        agent_analysis = response.get(\"output\", \"\") if isinstance(response, dict) else str(response)\n        if not agent_analysis.strip():\n            yield \"\u26a0\ufe0f Agent returned empty analysis.\"\n            return\n    except Exception as e:\n        yield f\"\u26a0\ufe0f Agent error: {e}\"\n        return\n\n    # Dil tespiti\n    try:\n        lang = detect(query)\n    except:\n        lang = \"en\"\n\n    # RAG\n    retriever = Herakleitos.init_pg_rag_retriever(agent_name=\"analyze_agent\", lang=lang)\n    try:\n        documents = retriever.get_relevant_documents(query)\n        rag_context = \"\\n\".join([doc.page_content for doc in documents])\n    except Exception as e:\n        rag_context = \"\"\n        print(f\"\u26a0\ufe0f Failed to fetch RAG context: {e}\")\n\n    # Promptlar\n    prompt_en = \"\"\"\n    \ud83c\udfaf **Your Role:** You are a data scientist with access to two inputs:\n\n    \ud83d\udcca **Agent Analysis (focused on column '{column}'):**\n    {agent_analysis}\n\n    \ud83d\udcda **Contextual Knowledge from Domain:**\n    {rag_context}\n\n    \u2753 Based on the above, explain the situation related to '{column}' and the user query: '{query}'.\n    \"\"\".strip()\n\n    prompt_tr = \"\"\"\n    \ud83e\udde0 **Rol\u00fcn:** Bir veri bilimci olarak iki girdiye sahipsiniz:\n\n    \ud83d\udcca **Veriden Elde Edilen Agent Analizi ('{column}' kolonu \u00fczerine):**\n    {agent_analysis}\n\n    \ud83d\udcda **Alan Bilgisinden Gelen Ba\u011flamsal Bilgi:**\n    {rag_context}\n\n    \u2753 Yukar\u0131daki bilgilere g\u00f6re '{column}' kolonu ve '{query}' hakk\u0131nda durumu a\u00e7\u0131klay\u0131n.\n    \"\"\".strip()\n\n    chat_prompt, inputs = self.generate_prompt(\n        query=query,\n        prompt_tr=prompt_tr,\n        prompt_en=prompt_en,\n        lang=lang,\n        column=column,\n        agent_analysis=agent_analysis,\n        rag_context=rag_context\n    )\n\n    chain = chat_prompt | self.chat_model\n\n    async for chunk in chain.astream(inputs):\n        yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.analyze_agent","title":"analyze_agent  <code>async</code>","text":"<pre><code>analyze_agent(query)\n</code></pre> <p>Execute general exploratory analysis with a LangChain-style agent.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>Free-form exploratory question across multiple columns/metrics.</p> required <p>Yields:</p> Type Description <p>Streaming analysis outputs (text/Markdown) with referenced visuals.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def analyze_agent(self, query):\n    \"\"\"Execute general exploratory analysis with a LangChain-style agent.\n\n        Args:\n            query: Free-form exploratory question across multiple columns/metrics.\n\n        Yields:\n            Streaming analysis outputs (text/Markdown) with referenced visuals.\n        \"\"\"\n    detected_columns = self.extract_columns_from_query(query, self.eda_cleaned_df.columns.tolist())\n\n    if len(detected_columns) &lt; 1:\n        yield \"\u274c Please specify at least one valid column.\"\n        return\n\n    if len(detected_columns) == 1:\n        async for chunk in self.analyze_single_column(detected_columns[0], query):\n            yield chunk\n        return\n\n    df = self.eda_cleaned_df.copy()\n    time_cols = [col for col in df.columns if \"date\" in col.lower() or \"start\" in col.lower()]\n    if time_cols:\n        date_col = time_cols[0]\n        try:\n            df = df.sort_values(by=date_col)\n            df = df.set_index(date_col)\n        except Exception as e:\n            print(f\"\u26a0\ufe0f Can't convert date column: {e}\")\n\n    python_tool = PythonREPLTool()\n\n    agent = create_pandas_dataframe_agent(\n        self.chat_model,\n        df,\n        allow_dangerous_code=True,\n        handle_parsing_errors=True,\n        verbose=True,\n        tools=[python_tool],\n        callbacks=[StreamingStdOutCallbackHandler()]\n    )\n\n    try:\n        response = await agent.ainvoke({\"input\": query})\n        agent_analysis = response.get(\"output\", \"\") if isinstance(response, dict) else str(response)\n        if not agent_analysis.strip():\n            yield \"\u26a0\ufe0f Agent returned empty analysis.\"\n            return\n    except Exception as e:\n        yield f\"\u26a0\ufe0f Error occurred while running agent: {str(e)}\"\n        return\n\n    try:\n        lang = detect(query)\n    except:\n        lang = \"en\"\n\n    retriever = Herakleitos.init_pg_rag_retriever(agent_name=\"analyze_agent\", lang=lang)\n    try:\n        docs = retriever.get_relevant_documents(query)\n        rag_context = \"\\n\".join([doc.page_content for doc in docs])\n    except Exception as e:\n        rag_context = \"\"\n        print(f\"\u26a0\ufe0f Failed to fetch RAG context: {e}\")\n\n    prompt_en = \"\"\"\n    \ud83c\udfaf **Your Role:** You are a data scientist with access to two inputs:\n\n    \ud83d\udcca **Agent Analysis:**\n    {agent_analysis}\n\n    \ud83d\udcda **Contextual Knowledge from Domain:**\n    {rag_context}\n\n    \u2753 Based on the above, explain the situation in light of the user's question: '{query}'.\n    \"\"\".strip()\n\n    prompt_tr = \"\"\"\n    \ud83e\udde0 **Rol\u00fcn:** Bir veri bilimci olarak iki girdiye sahipsiniz:\n\n    \ud83d\udcca **Veriden Elde Edilen Agent Analizi:**\n    {agent_analysis}\n\n    \ud83d\udcda **Alan Bilgisinden Gelen Ba\u011flamsal Bilgi:**\n    {rag_context}\n\n    \u2753 Yukar\u0131daki bilgilere g\u00f6re '{query}' sorusunu yan\u0131tlay\u0131n\u0131z.\n    \"\"\".strip()\n\n    chat_prompt, inputs = self.generate_prompt(\n        query=query,\n        prompt_tr=prompt_tr,\n        prompt_en=prompt_en,\n        lang=lang,\n        agent_analysis=agent_analysis,\n        rag_context=rag_context\n    )\n\n    chain = chat_prompt | self.chat_model\n\n    async for chunk in chain.astream(inputs):\n        yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.wiki_agent","title":"wiki_agent  <code>async</code>","text":"<pre><code>wiki_agent(query)\n</code></pre> <p>Answer knowledge questions via search tools (Wikipedia/DuckDuckGo/WolframAlpha).</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>Concept/definition question (e.g., \u201cWhat is CTR?\u201d).</p> required <p>Yields:</p> Type Description <p>Short, sourced explanations suitable for quick reference.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>@traceable\nasync def wiki_agent(self, query):\n    \"\"\"Answer knowledge questions via search tools (Wikipedia/DuckDuckGo/WolframAlpha).\n\n        Args:\n            query: Concept/definition question (e.g., \u201cWhat is CTR?\u201d).\n\n        Yields:\n            Short, sourced explanations suitable for quick reference.\n        \"\"\"\n    if \"WOLFRAM_ALPHA_APPID\" not in os.environ:\n        os.environ[\"WOLFRAM_ALPHA_APPID\"] = config(\"WOLFRAM_ALPHA_APPID\")\n\n\n    wolfram_wrapper = WolframAlphaAPIWrapper()\n    wolfram = WolframAlphaQueryRun(api_wrapper=wolfram_wrapper)\n    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n    search = DuckDuckGoSearchRun()\n    tools = [search, wikipedia, wolfram]\n\n    tool_node = ToolNode(tools=tools)\n    graph = StateGraph(MessagesState)\n\n\n\n    llm_node = RunnableLambda(\n        lambda state: {\"messages\": state[\"messages\"] + [self.chat_model.invoke(state[\"messages\"])]}\n        )\n\n\n    graph.add_node(\"llm\", llm_node)\n    graph.add_node(\"tools\", tool_node)\n\n    graph.set_entry_point(\"llm\")\n    graph.add_conditional_edges(\"llm\", tools_condition)\n    graph.add_edge(\"tools\", \"llm\")\n    graph.add_edge(\"llm\", END)\n\n    builder = graph.compile(checkpointer=self.checkpointer)\n\n    config = {\n        \"configurable\": {\n            \"thread_id\": self.user_id,\n        }\n    }\n\n\n    input_msg = HumanMessage(content=query)\n\n    try:\n        async for chunk in builder.astream({\"messages\": [input_msg]}, config, stream_mode=\"values\"):\n            latest = chunk[\"messages\"][-1]\n            content = getattr(latest, \"content\", None)\n            if content:\n                cleaned = content.strip()\n                if cleaned.lower().startswith(query.lower()):\n                    cleaned = cleaned[len(query):].lstrip(\":\").strip()\n                yield cleaned\n    except Exception as e:\n        print(\"\u274c Wiki Agent Stream Exception:\", str(e))\n        yield \"\u274c Wikipedia agent stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.geo_agent","title":"geo_agent  <code>async</code>","text":"<pre><code>geo_agent(json_path, query)\n</code></pre> <p>Explain GeoLift power/impact results produced by <code>powerAnalysis</code>.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <p>Path to the model summaries JSON.</p> required <code>query</code> <p>User question that frames the interpretation.</p> required <p>Returns:</p> Type Description <p>A natural-language summary of lift, power, and experimental design notes.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def geo_agent(self, json_path, query):\n    \"\"\"Explain GeoLift power/impact results produced by ``powerAnalysis``.\n\n        Args:\n            json_path: Path to the model summaries JSON.\n            query: User question that frames the interpretation.\n\n        Returns:\n            A natural-language summary of lift, power, and experimental design notes.\n        \"\"\"\n    with open(json_path, \"r\") as file:\n        geo_results = json.load(file)\n\n    test_summary = geo_results[\"Test_Model\"]\n    best_summary = geo_results[\"Best_Model\"]\n\n    weight_table = \"\\n\".join(\n        f\"| {w['location'].title()} | {w['weight']:.4f} | {bw['weight']:.4f} |\"\n        for w, bw in zip(test_summary['weights'], best_summary['weights'])\n    )\n    effect_timeline = json.dumps(best_summary[\"ATT\"], indent=4)\n    try:\n        lang = detect(query)\n    except:\n        lang = \"en\"\n\n    prompt_en = \"\"\"\n    \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n\n    ## \ud83d\udcca **GeoLift Experiment Analysis**\n\n    \ud83d\ude80 **IMPORTANT: This is a GeoLift analysis designed to measure the causal impact of an advertising campaign.**\n    We are testing whether **spending a budget of `{budget}`** led to a **significant lift** in `{y_id}`.\n\n    **\u2757 READ CAREFULLY:**\n    - **This is NOT a population analysis. DO NOT analyze location populations or city sizes.**\n    - **The goal is to measure the causal effect of an advertising campaign using GeoLift.**\n    - **We compare a Test Model (initial experiment) with a Best Model (optimized version with lowest imbalance).**\n    - **We are looking for statistical evidence that the advertising spend increased `{y_id}`.**\n\n    ---\n\n    ## \ud83d\udccc Experiment Summary\n    - \ud83d\udcc5 Treatment Period: `{start} to {end}`\n    - \ud83d\udcb0 Ad Budget Used: `{budget}`\n    - \ud83d\udd2c Experiment Type: `{type}`\n    - \ud83d\udcc8 Incremental Lift Observed: `{incremental}`\n    - \u2696\ufe0f Bias Adjustment (Best Model): `{bias}`\n    - \ud83d\udcca L2 Imbalance Comparison (Test vs Best Model): `{l2_test} / {l2_best}`\n    - \ud83d\udcca Scaled L2 Imbalance: `{l2_scaled_test} / {l2_scaled_best}`\n    - \ud83d\udd0d Significance Level (Alpha): `{alpha}`\n\n    ---\n\n    ## \ud83d\udcce Key Metrics Comparison\n\n    | Metric                                      | Test Model              | Best Model             |\n    |--------------------------------------------|--------------------------|------------------------|\n    | **ATT Estimate (Effect Size)**             | `{att_est_test}`         | `{att_est_best}`       |\n    | **Percentage Lift (Change in {y_id})**     | `{perc_lift_test}%`      | `{perc_lift_best}%`    |\n    | **P-Value (Statistical Significance)**     | `{pvalue_test}`          | `{pvalue_best}`        |\n    | **Incremental Effect**                     | `{incremental_test}`     | `{incremental_best}`   |\n\n    \ud83d\udccc Interpretation Guidelines:\n    - If p-value &lt; 0.05, the effect is statistically significant.\n    - If L2 imbalance is high, the models are not well-matched.\n    - A high percentage lift indicates a successful campaign.\n\n    ---\n\n    ## \ud83d\udccd Weight Distribution Across Locations\n\n    | Location | Test Model Weight | Best Model Weight |\n    |----------|-------------------|-------------------|\n    {weight_table}\n\n    ---\n\n    ## \ud83d\udcca Effect of Advertising Over Time\n\n    ```json\n    {effect_timeline}\n    ```\n\n    **\ud83d\udd0e Key Insights:**\n    - **Look for time periods where the effect was strongest.**\n    - **Check if the confidence intervals are narrow (meaning stable estimates) or wide (meaning high uncertainty).**\n    - **If most time points have a p-value &gt; 0.05, the effect is likely due to random variation rather than the ad campaign.**\n\n    ---\n\n    \ud83c\udfaf **Final Task: Summarize whether the advertising budget resulted in a meaningful lift in `{y_id}` and whether the experiment was statistically valid.**\n    \"\"\"\n\n    prompt_tr = \"\"\"\n    \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. L\u00fctfen a\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131, bir veri bilimcinin sahip oldu\u011fu teknik ve analitik bak\u0131\u015f a\u00e7\u0131s\u0131yla de\u011ferlendir.\n\n    ## \ud83d\udcca GeoLift Deneyi Analizi\n\n    \ud83d\ude80 **D\u0130KKAT:** Bu analiz, bir reklam kampanyas\u0131n\u0131n nedensel etkisini \u00f6l\u00e7mek i\u00e7in yap\u0131lm\u0131\u015ft\u0131r.\n    Amac\u0131m\u0131z, `{budget}` b\u00fct\u00e7esi harcand\u0131\u011f\u0131nda `{y_id}` de\u011fi\u015fkeninde anlaml\u0131 bir art\u0131\u015f (lift) olup olmad\u0131\u011f\u0131n\u0131 test etmektir.\n\n    \u2757 **D\u0130KKAT ED\u0130LMES\u0130 GEREKENLER:**\n    - Bu bir n\u00fcfus analizi de\u011fildir. Lokasyon b\u00fcy\u00fckl\u00fcklerine odaklanmay\u0131n\u0131z.\n    - Ama\u00e7, reklam harcamas\u0131n\u0131n nedensel etkisini \u00f6l\u00e7mektir.\n    - Test modeli ile dengesizli\u011fi en d\u00fc\u015f\u00fck model kar\u015f\u0131la\u015ft\u0131r\u0131l\u0131r.\n    - `{y_id}` \u00fczerindeki art\u0131\u015f i\u00e7in istatistiksel kan\u0131t aran\u0131r.\n\n    ---\n\n    ## \ud83d\udccc Deney \u00d6zeti\n    - \ud83d\udcc5 Tedavi D\u00f6nemi: `{start} - {end}`\n    - \ud83d\udcb0 Reklam B\u00fct\u00e7esi: `{budget}`\n    - \ud83d\udd2c Deney T\u00fcr\u00fc: `{type}`\n    - \ud83d\udcc8 G\u00f6zlemlenen Art\u0131\u015f: `{incremental}`\n    - \u2696\ufe0f Bias D\u00fczeltmesi: `{bias}`\n    - \ud83d\udcca L2 Dengesizlik (Test / Best): `{l2_test} / {l2_best}`\n    - \ud83d\udcca \u00d6l\u00e7ekli L2 Dengesizlik: `{l2_scaled_test} / {l2_scaled_best}`\n    - \ud83d\udd0d Anlaml\u0131l\u0131k Seviyesi (Alpha): `{alpha}`\n\n    ---\n\n    ## \ud83d\udcce Temel Metrik Kar\u015f\u0131la\u015ft\u0131rmalar\u0131\n\n    | Metrik                                    | Test Modeli            | En \u0130yi Model           |\n    |------------------------------------------|------------------------|------------------------|\n    | **ATT Tahmini (Etki B\u00fcy\u00fckl\u00fc\u011f\u00fc)**         | `{att_est_test}`       | `{att_est_best}`       |\n    | **Y\u00fczdelik Art\u0131\u015f ({y_id})**              | `{perc_lift_test}%`    | `{perc_lift_best}%`    |\n    | **P-De\u011feri (Anlaml\u0131l\u0131k)**                | `{pvalue_test}`        | `{pvalue_best}`        |\n    | **Artan Etki (Ek Kazan\u00e7/Etkile\u015fim)**     | `{incremental_test}`   | `{incremental_best}`   |\n\n    \ud83d\udccc Yorumlama Rehberi:\n    - p-de\u011feri &lt; 0.05 ise, sonu\u00e7 anlaml\u0131d\u0131r.\n    - L2 dengesizlik ne kadar d\u00fc\u015f\u00fckse, e\u015fle\u015ftirme o kadar iyidir.\n    - Y\u00fcksek y\u00fczdelik art\u0131\u015f kampanyan\u0131n ba\u015far\u0131l\u0131 oldu\u011funu g\u00f6sterir.\n\n    ---\n\n    ## \ud83d\udccd Lokasyon A\u011f\u0131rl\u0131klar\u0131\n\n    | Lokasyon | Test Modeli A\u011f\u0131rl\u0131\u011f\u0131 | En \u0130yi Model A\u011f\u0131rl\u0131\u011f\u0131 |\n    |----------|----------------------|------------------------|\n    {weight_table}\n\n    ---\n\n    ## \ud83d\udcca Zaman \u0130\u00e7inde Reklam\u0131n Etkisi\n\n    ```json\n    {effect_timeline}\n    ```\n    **\ud83d\udd0e \u00d6nemli \u0130\u00e7g\u00f6r\u00fcler:**\n    - Etkinin en g\u00fc\u00e7l\u00fc oldu\u011fu zaman aral\u0131klar\u0131n\u0131 inceleyin.  \n    - G\u00fcven aral\u0131klar\u0131 dar ise bu, tahminlerin kararl\u0131 oldu\u011funu g\u00f6sterir; geni\u015fse belirsizlik y\u00fcksektir.  \n    - E\u011fer \u00e7o\u011fu zaman noktas\u0131nda p-de\u011feri &gt; 0.05 ise, g\u00f6zlenen etki reklam kampanyas\u0131ndan de\u011fil, rastlant\u0131sal dalgalanmalardan kaynaklan\u0131yor olabilir.\n\n    ---\n\n    \ud83c\udfaf Son G\u00f6rev: Reklam b\u00fct\u00e7esi, `{y_id}` de\u011fi\u015fkeninde anlaml\u0131 bir art\u0131\u015f sa\u011flam\u0131\u015f m\u0131? Ve bu deney istatistiksel olarak ge\u00e7erli mi? A\u00e7\u0131klay\u0131n\u0131z.\n    \"\"\"\n\n    chat_prompt, inputs = self.generate_prompt(\n        query=query,\n        prompt_tr=prompt_tr,\n        prompt_en=prompt_en,\n        lang=lang,\n        budget=best_summary.get(\"budget\", \"Unknown\"),\n        y_id=best_summary[\"Y_id\"],\n        start=best_summary[\"start\"],\n        end=best_summary[\"end\"],\n        type=best_summary[\"type\"],\n        incremental=best_summary[\"incremental\"],\n        bias=best_summary.get(\"bias\", \"N/A\"),\n        alpha=best_summary[\"alpha\"],\n        att_est_best=best_summary[\"ATT_est\"],\n        att_est_test=test_summary[\"ATT_est\"],\n        perc_lift_best=best_summary[\"PercLift\"],\n        perc_lift_test=test_summary[\"PercLift\"],\n        pvalue_best=best_summary[\"pvalue\"],\n        pvalue_test=test_summary[\"pvalue\"],\n        incremental_best=best_summary[\"incremental\"],\n        incremental_test=test_summary[\"incremental\"],\n        l2_test=test_summary[\"L2Imbalance\"],\n        l2_best=best_summary[\"L2Imbalance\"],\n        l2_scaled_test=test_summary[\"L2ImbalanceScaled\"],\n        l2_scaled_best=best_summary[\"L2ImbalanceScaled\"],\n        weight_table=weight_table,\n        effect_timeline=effect_timeline\n    )\n\n    chain = chat_prompt | self.chat_model\n\n    try:\n        async for chunk in chain.astream(inputs):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n    except Exception as e:\n        print(\"\u274c LLM stream exception:\", str(e))\n        yield \"\u274c LLM model stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.eda_agent","title":"eda_agent  <code>async</code>","text":"<pre><code>eda_agent(json_files, df, col1, col2, query)\n</code></pre> <p>Summarize statistical tests and visuals between two columns.</p> <p>Parameters:</p> Name Type Description Default <code>json_files</code> <p>Mapping of pair-type \u2192 JSON path (e.g., <code>{\"num_num\": \"...\", ...}</code>).</p> required <code>df</code> <p>DataFrame used for EDA.</p> required <code>col1</code> <p>First column name.</p> required <code>col2</code> <p>Second column name.</p> required <code>query</code> <p>Analysis question guiding the narrative.</p> required <p>Yields:</p> Type Description <p>Interpreted EDA findings (distributions, correlations, tests) in chunks.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def eda_agent(self, json_files, df, col1, col2, query):\n    \"\"\"Summarize statistical tests and visuals between two columns.\n\n        Args:\n            json_files: Mapping of pair-type \u2192 JSON path (e.g., ``{\"num_num\": \"...\", ...}``).\n            df: DataFrame used for EDA.\n            col1: First column name.\n            col2: Second column name.\n            query: Analysis question guiding the narrative.\n\n        Yields:\n            Interpreted EDA findings (distributions, correlations, tests) in chunks.\n        \"\"\"\n    is_col1_numeric = pd.api.types.is_numeric_dtype(df[col1])\n    is_col2_numeric = pd.api.types.is_numeric_dtype(df[col2])\n\n    is_col1_categorical = pd.api.types.is_categorical_dtype(df[col1]) or df[col1].dtype == \"object\"\n    is_col2_categorical = pd.api.types.is_categorical_dtype(df[col2]) or df[col2].dtype == \"object\"\n\n    if is_col1_numeric and is_col2_numeric:\n        json_path = json_files[\"num_num\"]\n        analysis_type = \"Numerical-Numerical Analysis\"\n    elif is_col1_numeric and is_col2_categorical or is_col1_categorical and is_col2_numeric:\n        json_path = json_files[\"num_cat\"]\n        analysis_type = \"Numerical-Categorical Analysis\"\n    elif is_col1_categorical and is_col2_categorical:\n        json_path = json_files[\"cat_cat\"]\n        analysis_type = \"Categorical-Categorical Analysis\"\n    else:\n        yield f\"\u26a0\ufe0f Could not determine the analysis type for {col1} and {col2}.\"\n        return\n\n    with open(json_path, \"r\") as file:\n        analysis_results = json.load(file)\n\n    col1_levels = df[col1].unique().tolist() if is_col1_categorical else \"N/A\"\n    col2_levels = df[col2].unique().tolist() if is_col2_categorical else \"N/A\"\n\n    graph_results = {}\n    graph_path = \"plots/scientific_image_analysis.json\"\n    if os.path.exists(graph_path):\n        with open(graph_path, \"r\") as file:\n            graph_results = json.load(file)\n\n    graph_section_en = f\"\"\"\n    #### **Graphical Analysis Insights**\n    ```json\n    {json.dumps(graph_results, indent=4)}\n    ```\"\"\" if graph_results else \"\"\n\n    prompt_en = \"\"\"\n    \ud83d\udcd8 Note:\n    The ISKIN Score is a custom statistical measure designed to detect complex and non-linear relationships between numerical variables. It ranges from 0 to 1, where higher scores indicate stronger relationships. Unlike traditional correlation tests (e.g., Kendall or Pearson), ISKIN may detect subtle dependencies that do not manifest linearly. A score above 0.9 is typically considered strong.\n\n    \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n    ### \ud83d\udcca Exploratory Data Analysis (EDA)\n\n    **Analyzing the relationship between:** `{col1}` and `{col2}`\n    - **Analysis Type:** {analysis_type}\n    - **Data Types:** `{col1}` ({col1_type}), `{col2}` ({col2_type})\n    - **Levels for Categorical Columns:**\n    - `{col1}`: {col1_levels}\n    - `{col2}`: {col2_levels}\n\n    #### **Raw JSON Data:**\n    ```json\n    {analysis_results}\n    ```\n\n    \u2753 **Interpretation Request**\n    1\ufe0f\u20e3 **Analyze the statistical test results.**  \n    2\ufe0f\u20e3 **Based on the p-values, determine if there is a significant relationship.**  \n    3\ufe0f\u20e3 **Explain the effect sizes and power of the tests.**  \n    4\ufe0f\u20e3 **Compare different statistical tests and identify inconsistencies.**  \n    5\ufe0f\u20e3 **Provide actionable insights based on the results.**  \n    {graph_section_en}\n    \"\"\".strip()\n\n    graph_section_tr = f\"\"\"\n    #### **Grafiksel Analiz Bulgular\u0131**\n    ```json\n    {json.dumps(graph_results, indent=4, ensure_ascii=False)}\n    ```\"\"\" if graph_results else \"\"\n\n    prompt_tr = \"\"\"\n    \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. L\u00fctfen a\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131, bir veri bilimcinin sahip oldu\u011fu teknik ve analitik bak\u0131\u015f a\u00e7\u0131s\u0131yla de\u011ferlendir.    \n    ### \ud83d\udcca Ke\u015fifsel Veri Analizi (EDA)\n\n    **\u0130ncelenen ili\u015fki:** `{col1}` ile `{col2}` aras\u0131ndaki ili\u015fki  \n    - **Analiz T\u00fcr\u00fc:** {analysis_type}  \n    - **Veri T\u00fcrleri:** `{col1}` ({'Say\u0131sal' if is_col1_numeric else 'Kategorik'}), `{col2}` ({'Say\u0131sal' if is_col2_numeric else 'Kategorik'})  \n    - **Kategorik De\u011fi\u015fkenlerin Seviyeleri:**\n    - `{col1}`: {col1_levels}\n    - `{col2}`: {col2_levels}\n\n    #### **Ham JSON Verisi:**\n    ```json\n    {analysis_results}\n    ```\n    \u2753 **Yorumlama Talebi**  \n    1\ufe0f\u20e3 **\u0130statistiksel test sonu\u00e7lar\u0131n\u0131 analiz edin.**  \n    2\ufe0f\u20e3 **p-de\u011ferlerine g\u00f6re anlaml\u0131 bir ili\u015fki olup olmad\u0131\u011f\u0131n\u0131 belirleyin.**  \n    3\ufe0f\u20e3 **Etki b\u00fcy\u00fckl\u00fcklerini (effect size) ve test g\u00fcc\u00fcn\u00fc (statistical power) a\u00e7\u0131klay\u0131n.**  \n    4\ufe0f\u20e3 **Farkl\u0131 istatistiksel testleri kar\u015f\u0131la\u015ft\u0131r\u0131n ve varsa tutars\u0131zl\u0131klar\u0131 belirleyin.**  \n    5\ufe0f\u20e3 **Sonu\u00e7lara dayanarak uygulanabilir i\u00e7g\u00f6r\u00fcler sunun.**\n    {graph_section_tr}\n    \"\"\".strip()\n    try:\n        lang = detect(query)\n    except:\n        lang = \"en\"\n\n    chat_prompt, prompt_inputs = self.generate_prompt(\n        query=query,\n        prompt_tr=prompt_tr,\n        prompt_en=prompt_en,\n        lang=lang,\n        col1=col1,\n        col2=col2,\n        col1_type=\"Numeric\" if is_col1_numeric else \"Categorical\",\n        col2_type=\"Numeric\" if is_col2_numeric else \"Categorical\",\n        col1_type_tr=\"Say\u0131sal\" if is_col1_numeric else \"Kategorik\",\n        col2_type_tr=\"Say\u0131sal\" if is_col2_numeric else \"Kategorik\",\n        analysis_type=analysis_type,\n        col1_levels=col1_levels,\n        col2_levels=col2_levels,\n        analysis_results=analysis_results,\n        graph_section_en=graph_section_en,\n        graph_section_tr=graph_section_tr\n    )\n\n    chain = chat_prompt | self.chat_model\n\n    try:\n        async for chunk in chain.astream(prompt_inputs):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n    except Exception as e:\n        print(\"\u274c LLM stream exception:\", str(e))\n        yield \"\u274c LLM model stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.ab_agent","title":"ab_agent  <code>async</code>","text":"<pre><code>ab_agent(user_query)\n</code></pre> <p>Analyze A/B tests and report significance across methods.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <p>Experiment question (variants, metric, horizon).</p> required <p>Yields:</p> Type Description <p>Test summaries with p-values, effect sizes, and decision guidance.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def ab_agent(self, user_query):\n    \"\"\"Analyze A/B tests and report significance across methods.\n\n        Args:\n            user_query: Experiment question (variants, metric, horizon).\n\n        Yields:\n            Test summaries with p-values, effect sizes, and decision guidance.\n        \"\"\"\n    with open('services/AI/data/ab_test.json', 'r') as file:\n        ab_test_results = json.load(file)\n\n    prompt = f\"\"\"\n        \ud83c\udf93 Note:\n        You are a highly experienced data scientist and statistician with over 30 years of expertise in experimental design and A/B testing methodologies. You are asked to provide a detailed interpretation of an A/B testing analysis.\n\n        ### \ud83d\udcdd User Query:\n        \"{user_query}\"\n\n        ### \ud83d\udcca A/B Testing Results:\n        The following JSON represents the results of various A/B testing methodologies (e.g., Z-Test, Fisher's Exact Test, T-Test, Chi-Square Test, ANOVA). Each result includes key metrics like p-values, effect sizes, and significance levels.\n\n        ```json\n        {ab_test_results}\n        ```\n\n        #### \ud83c\udfaf Your Analytical Task:\n        1\ufe0f\u20e3 **Analyze the test results** \u2014 Describe what the p-values, test types, and effect sizes indicate about the performance difference between groups.\n        2\ufe0f\u20e3 **Assess Statistical Significance** \u2014 For each test, determine if the results are statistically significant based on the p-value thresholds.\n        3\ufe0f\u20e3 **Interpret Effect Sizes** \u2014 Explain how large or meaningful the observed effect sizes are in practical/business terms.\n        4\ufe0f\u20e3 **Compare Methods** \u2014 Identify if there are discrepancies between different statistical methods (e.g., Fisher vs Z-Test), and explain why such inconsistencies may occur.\n        5\ufe0f\u20e3 **Provide Data-Driven Recommendations** \u2014 Based on these results, suggest actionable next steps (e.g., scale experiment, gather more data, validate findings).\n        6\ufe0f\u20e3 **Mention Limitations** \u2014 Highlight any limitations or assumptions inherent to the test results (e.g., sample size concerns, test type appropriateness).\n\n        \ud83c\udf93 You are expected to give a structured, precise, and scientific response.\n        \"\"\".strip()\n\n    try:\n        async for chunk in self.chat_model.astream(prompt):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n    except Exception as e:\n        print(\"\u274c LLM stream exception:\", str(e))\n        yield \"\u274c LLM model stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.assoc_agent","title":"assoc_agent  <code>async</code>","text":"<pre><code>assoc_agent(\n    user_query, json_path=\"data/assoc_rules.json\", top_n=50\n)\n</code></pre> <p>Stream an LLM-based interpretation of association rules.</p> <p>Loads a JSON file containing association rules (e.g., Apriori, FP-Growth), trims to the top-N rules by lift/confidence/support, and builds a structured interpretation prompt. The prompt guides the LLM to summarize patterns, highlight entity-linked vs. metric-only rules, and produce actionable insights.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>Natural language question or focus area for interpretation.</p> required <code>json_path</code> <code>str</code> <p>Path to the JSON file containing precomputed association rules.</p> <code>'data/assoc_rules.json'</code> <code>top_n</code> <code>int</code> <p>Number of top-ranked rules to include (default = 50).</p> <code>50</code> <p>Yields:</p> Type Description <p>Streaming text chunks with: - Summarized association patterns (ranked by lift, confidence, support) - Entity-specific vs. general metric findings - Conflicts, trivialities, and caveats - Actionable recommendations for campaigns or experiments - Limitations and notes on interpretability</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def assoc_agent(self, user_query: str, json_path: str = \"data/assoc_rules.json\", top_n: int = 50):\n    \"\"\"Stream an LLM-based interpretation of association rules.\n\n        Loads a JSON file containing association rules (e.g., Apriori, FP-Growth),\n        trims to the top-N rules by lift/confidence/support, and builds a structured\n        interpretation prompt. The prompt guides the LLM to summarize patterns,\n        highlight entity-linked vs. metric-only rules, and produce actionable insights.\n\n        Args:\n            user_query: Natural language question or focus area for interpretation.\n            json_path: Path to the JSON file containing precomputed association rules.\n            top_n: Number of top-ranked rules to include (default = 50).\n\n        Yields:\n            Streaming text chunks with:\n              - Summarized association patterns (ranked by lift, confidence, support)\n              - Entity-specific vs. general metric findings\n              - Conflicts, trivialities, and caveats\n              - Actionable recommendations for campaigns or experiments\n              - Limitations and notes on interpretability\n        \"\"\"\n    # 1) Load JSON\n    if not os.path.exists(json_path):\n        yield f\"\u274c JSON not found at {json_path}\"\n        return\n\n    try:\n        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n            rules_obj = json.load(f)\n    except Exception as e:\n        yield f\"\u274c JSON load error: {e}\"\n        return\n\n    # 2) Optional top_n trimming for large files\n    trimmed = rules_obj\n    if isinstance(rules_obj, list) and top_n and top_n &gt; 0:\n        def _as_num(x):\n            try:\n                return float(x)\n            except:\n                return -1e9\n\n        def sort_key(r):\n            return (-_as_num(r.get(\"lift\", 0)),\n                    -_as_num(r.get(\"confidence\", 0)),\n                    -_as_num(r.get(\"support\", 0)))\n\n        trimmed = sorted(rules_obj, key=sort_key)[:top_n]\n\n    try:\n        rules_json_str = json.dumps(trimmed, ensure_ascii=False, indent=2)\n    except Exception:\n        rules_json_str = str(trimmed)\n\n    # 3) Prompt for Association Rules interpretation\n    prompt = f\"\"\"\n\ud83c\udf93 Note:\nYou are a senior data scientist specializing in **Association Rule Mining** (Apriori / FP-Growth / ECLAT) for marketing analytics. \nYour task is to provide a clear, precise, and business-focused interpretation of the given rules.\n\n### \ud83d\udcdd User Query\n\"{user_query}\"\n\n### \ud83d\udcca Association Rules (JSON)\nBelow is the rules output (top {top_n} shown if large):\n```json\n{rules_json_str}\n\ud83d\udcd8 Quick Primer (interpretation guide)\nAntecedents \u2192 Consequents: Read as \"If antecedents, then consequents\".\n\nsupport = P(A \u2227 B): Frequency of both conditions occurring together. Higher support = more common pattern.\n\nconfidence = P(B|A): Probability of B given A. Ranges 0\u20131.\n\nlift = P(B|A) / P(B): &gt;1 = positive association, \u22481 = no association, &lt;1 = negative association.\n\nantecedent support / consequent support: P(A) and P(B) individually.\n\nleverage = P(A\u2227B) \u2212 P(A)P(B): Distance from independence. Larger magnitude = stronger deviation.\n\nconviction = (1\u2212P(B)) / (1\u2212P(B|A)): Higher means B is less likely to be absent when A occurs.\n\nEntity items (e.g., campaign_name:\u2026, adset_name:\u2026, ad_name:\u2026, Level:\u2026) show rules tied to specific campaigns/ad sets/ads.\n\nBinning (low/mid/high): Metrics (CTR, CPC, SPEND, IMPR, CONV) are bucketed; interpret relatively.\n\n\ud83c\udfaf Your Analytical Task\nCore findings: Summarize key patterns, prioritizing by lift, then confidence, then support.\n\nEntity-aware insights: Identify which campaigns/adsets/ads are linked to positive patterns (e.g., CTR:high, CPC:low) or negative ones (CTR:low, CPC:high).\n\nMetric-only vs entity-linked: Distinguish between general metric rules and entity-specific ones.\n\nTrivialities &amp; conflicts: Downrank obvious relationships (e.g., SPEND:high \u2192 IMPR:high). Note conflicting outcomes from same antecedents and explain potential causes.\n\nActionable recommendations: Suggest campaign budget shifts, creative/targeting changes, A/B tests, or follow-up analysis. Prioritize actions.\n\nLimitations: Note binning artifacts, low support, imbalanced classes, limited entity coverage, and that association \u2260 causation. Suggest possible data improvements.\n\nPlease answer in clear sections with bullet points, keeping the response concise but insight-rich.\n\"\"\".strip()\n\n    try:\n        async for chunk in self.chat_model.astream(prompt):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n    except Exception as e:\n        print(\"\u274c LLM stream exception:\", str(e))\n        yield \"\u274c LLM model stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.shap_agent","title":"shap_agent  <code>async</code>","text":"<pre><code>shap_agent(col, query)\n</code></pre> <p>Produce SHAP interpretability narrative for a trained regression model.</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <p>Target variable analyzed with SHAP.</p> required <code>query</code> <p>User question to focus the explanation.</p> required <p>Yields:</p> Type Description <p>Explanations of global/local importance and interaction hints.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def shap_agent(self, col, query):\n    \"\"\"Produce SHAP interpretability narrative for a trained regression model.\n\n        Args:\n            col: Target variable analyzed with SHAP.\n            query: User question to focus the explanation.\n\n        Yields:\n            Explanations of global/local importance and interaction hints.\n        \"\"\"\n    with open(\"services/AI/data/best_regression_results.json\", \"r\") as file:\n        result_model = json.load(file)\n\n    with open(\"services/AI/data/final_result_regress.json\", \"r\") as file:\n        result_shap = json.load(file)\n\n    prompt_en = \"\"\"\n    \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n    ### \ud83d\udcca Regression Agent Analysis\n\n    **{query}:**  \n    - **Target Variable:** `{col}`  \n    - **Best Regression Model:** `{best_model}`  \n    - **Evaluation Metrics:**  \n        - `R\u00b2`: {best_r2}  \n        - `MAE`: {best_mae}  \n        - `RMSE`: {best_rmse}  \n\n    #### **Suggested Feature Contributions (SHAP Score Analysis)**  \n    ```json\n    {shap_scores}\n    ```\n\n    \u2753 **Interpretation Request**  \n    1\ufe0f\u20e3 Analyze how each feature contributes to the target change.  \n    2\ufe0f\u20e3 Determine the significance using SHAP values.  \n    3\ufe0f\u20e3 Compare feature rankings and highlight key drivers.  \n    4\ufe0f\u20e3 Assess the reliability of predictions.  \n    5\ufe0f\u20e3 Suggest actionable strategies.  \n    \"\"\".strip()\n\n    prompt_tr = \"\"\"\n    \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. A\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131 yorumla:  \n    ### \ud83d\udcca Regresyon Ajan\u0131 Analizi\n\n    **{query}:**  \n    - **Hedef De\u011fi\u015fken:** `{col}`  \n    - **En \u0130yi Regresyon Modeli:** `{best_model}`  \n    - **De\u011ferlendirme Metrikleri:**  \n        - `R\u00b2`: {best_r2}  \n        - `MAE`: {best_mae}  \n        - `RMSE`: {best_rmse}  \n\n    #### **\u00d6zellik Katk\u0131lar\u0131 (SHAP Skorlar\u0131)**  \n    ```json\n    {shap_scores}\n    ```\n\n    \u2753 **Yorumlama Talebi:**  \n    1\ufe0f\u20e3 Hangi de\u011fi\u015fken ne kadar katk\u0131 sa\u011flad\u0131?  \n    2\ufe0f\u20e3 SHAP de\u011feriyle \u00f6nem derecesini belirt.  \n    3\ufe0f\u20e3 Etkili de\u011fi\u015fkenleri s\u0131rala.  \n    4\ufe0f\u20e3 Tahmin g\u00fcvenilirli\u011fini de\u011ferlendir.  \n    5\ufe0f\u20e3 Stratejik \u00f6nerilerde bulun.\n    \"\"\".strip()\n\n    try:\n        lang = detect(query)\n    except:\n        lang = \"en\"\n\n    chat_prompt, prompt_inputs = self.generate_prompt(\n        query=query,\n        prompt_tr=prompt_tr,\n        prompt_en=prompt_en,\n        lang=lang,\n        col=col,\n        best_model=result_model[\"best_model\"],\n        best_r2=result_model[\"best_r2\"],\n        best_mae=result_model[\"best_mae\"],\n        best_rmse=result_model[\"best_rmse\"],\n        shap_scores=json.dumps(result_shap, indent=4, ensure_ascii=(lang != \"tr\"))\n    )\n\n    chain = chat_prompt | self.chat_model\n    try:\n        async for chunk in chain.astream(prompt_inputs):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n    except Exception as e:\n        print(\"\u274c LLM stream exception:\", str(e))\n        yield \"\u274c LLM model stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.ts_agent","title":"ts_agent  <code>async</code>","text":"<pre><code>ts_agent(user_query, dashboard=None)\n</code></pre> <p>Explain time-series forecasts/causality with optional dashboard rendering.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>Forecasting/causality question (may contain horizon or series).</p> required <code>dashboard</code> <p>Optional dashboard object to render or export.</p> <code>None</code> <p>Yields:</p> Type Description <p>Forecast summaries, uncertainty notes, and causal diagnostics.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def ts_agent(self, user_query: str, dashboard=None):\n    \"\"\"Explain time-series forecasts/causality with optional dashboard rendering.\n\n        Args:\n            user_query: Forecasting/causality question (may contain horizon or series).\n            dashboard: Optional dashboard object to render or export.\n\n        Yields:\n            Forecast summaries, uncertainty notes, and causal diagnostics.\n        \"\"\"\n    try:\n        with open(\"services/AI/data/ts_metrics.json\", \"r\") as file:\n            results = json.load(file)\n\n        chat_prompt = PromptTemplate.from_template(\"\"\"\n\ud83d\udccc **Your Role:** You are a data scientist assigned to interpret the results of a time series and causal analysis.\n\nYou are provided with the following data (may include forecasting and/or causality information):\n\n\ud83e\uddfe **Analysis Result**:\n{analysis_result}\n\n\ud83d\udde3\ufe0f **User Query**:\n{user_query}\n\n---\n\n\u2705 Based on the data above, answer the following:\n\n1. If forecast results are included:\n   - Are the predictions statistically reliable? (e.g. MAE, MAPE, R\u00b2)\n   - Are there major trend shifts or changepoints?\n   - Do holidays have a visible influence on predictions?\n\n2. If multiple metrics are analyzed:\n   - Which metrics show strongest trends or weakest prediction accuracy?\n   - Are there any that should be prioritized, flagged, or adjusted?\n\n3. If Granger causality information is present:\n   - Is there statistical causality between metrics?\n   - What does the p-value and optimal lag indicate?\n   - Is this relationship useful for decision-making?\n\n4. Finally, considering the user query, write a narrative interpretation and provide concrete, business-relevant insights or recommendations.\n\"\"\")\n\n        chain = chat_prompt | self.chat_model\n\n        prompt_inputs = {\n            \"analysis_result\": json.dumps(results, indent=2),\n            \"user_query\": user_query\n        }\n\n        async for chunk in chain.astream(prompt_inputs):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n\n        if dashboard is not None:\n            dashboard_name = \"forecast_dashboard\"\n            dashboard.servable(\"Forecast Dashboard\")\n            dashboard_url = f\"http://localhost:5006/{dashboard_name}\"\n            yield f\"\\n\ud83d\udcca [Open Forecast Dashboard]({dashboard_url})\"\n    except Exception as e:\n        print(\"\u274c LLM stream exception:\", str(e))\n        yield \"\u274c LLM model stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.dowhy_agent","title":"dowhy_agent  <code>async</code>","text":"<pre><code>dowhy_agent(json_file, query)\n</code></pre> <p>Interpret DoWhy/EconML causal outputs from persisted JSON.</p> <p>Parameters:</p> Name Type Description Default <code>json_file</code> <p>Path to the causal results JSON.</p> required <code>query</code> <p>Causal question (treatment/outcome scope).</p> required <p>Returns:</p> Type Description <p>A human-readable summary of effects, assumptions, and robustness checks.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def dowhy_agent(self, json_file, query):\n    \"\"\"Interpret DoWhy/EconML causal outputs from persisted JSON.\n\n        Args:\n            json_file: Path to the causal results JSON.\n            query: Causal question (treatment/outcome scope).\n\n        Returns:\n            A human-readable summary of effects, assumptions, and robustness checks.\n        \"\"\"\n    with open(json_file, \"r\") as file:\n        analysis_results = json.load(file)\n\n    analysis_file = \"services/AI/data/dowhy_econml_causal.json\"\n    graph_results = {}\n    if os.path.exists(analysis_file):\n        with open(analysis_file, \"r\") as file:\n            graph_results = json.load(file)\n\n    prompt_en = \"\"\"\n    \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n    ### \ud83d\udd0d **Causal Inference Analysis Using DoWhy &amp; EconML**\n\n    \ud83d\udcdd **User Query:** \"{query}\"\n\n    - The system has conducted a **causal analysis** using DoWhy and EconML.\n    - The dataset has been processed, and the estimated **causal effects** are extracted.\n    - The results include **treatment effects, statistical refutations, and graphical model insights**.\n\n    #### **\ud83d\udcca Causal Inference Results**\n    ```json\n    {analysis_results}\n    ```\n\n    #### **\ud83d\udcc9 Graphical Analysis Insights**\n    ```json\n    {graph_results}\n    ```\n\n    \u2753 **Interpretation Request**\n    1\ufe0f\u20e3 Explain the estimated causal effects in plain terms.  \n    2\ufe0f\u20e3 Analyze how the treatment variable influences the outcome variable.  \n    3\ufe0f\u20e3 Evaluate whether the model assumptions are valid.  \n    4\ufe0f\u20e3 Identify potential biases or inconsistencies in the analysis.  \n    5\ufe0f\u20e3 Compare different causal estimation methods used in the analysis.  \n    6\ufe0f\u20e3 Suggest improvements or refinements for a more robust causal inference.\n    \"\"\".strip()\n\n    prompt_tr = \"\"\"\n    \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. L\u00fctfen a\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131, bir veri bilimcinin sahip oldu\u011fu teknik ve analitik bak\u0131\u015f a\u00e7\u0131s\u0131yla de\u011ferlendir.   \n    ### \ud83d\udd0d **DoWhy &amp; EconML Kullanarak Nedensel \u00c7\u0131kar\u0131m Analizi**\n\n    \ud83d\udcdd **Kullan\u0131c\u0131 Sorgusu:** \"{query}\"\n\n    - Sistem, DoWhy ve EconML k\u00fct\u00fcphanelerini kullanarak bir **nedensel analiz** ger\u00e7ekle\u015ftirmi\u015ftir.  \n    - Veri k\u00fcmesi i\u015flenmi\u015f ve tahmin edilen **nedensel etkiler** \u00e7\u0131kar\u0131lm\u0131\u015ft\u0131r.  \n    - Sonu\u00e7lar aras\u0131nda **tedavi (treatment) etkileri, istatistiksel do\u011frulamalar ve grafiksel model i\u00e7g\u00f6r\u00fcleri** yer almaktad\u0131r.\n\n    #### **\ud83d\udcca Nedensel \u00c7\u0131kar\u0131m Sonu\u00e7lar\u0131**\n    ```json\n    {analysis_results}\n    ```\n\n    #### **\ud83d\udcc9 Grafiksel Analiz \u0130\u00e7g\u00f6r\u00fcleri**\n    ```json\n    {graph_results}\n    ```\n\n    \u2753 **Yorumlama Talebi**  \n    1\ufe0f\u20e3 Tahmin edilen nedensel etkileri sade ve anla\u015f\u0131l\u0131r bir dille a\u00e7\u0131klay\u0131n\u0131z.  \n    2\ufe0f\u20e3 Tedavi (m\u00fcdahale) de\u011fi\u015fkeninin sonu\u00e7 (ba\u011f\u0131ml\u0131) de\u011fi\u015fken \u00fczerindeki etkisini analiz ediniz.  \n    3\ufe0f\u20e3 Model varsay\u0131mlar\u0131n\u0131n ge\u00e7erlili\u011fini de\u011ferlendiriniz.  \n    4\ufe0f\u20e3 Analizdeki olas\u0131 \u00f6nyarg\u0131 (bias) veya tutars\u0131zl\u0131klar\u0131 belirleyiniz.  \n    5\ufe0f\u20e3 Kullan\u0131lan farkl\u0131 nedensel tahmin y\u00f6ntemlerini kar\u015f\u0131la\u015ft\u0131r\u0131n\u0131z.  \n    6\ufe0f\u20e3 Daha sa\u011flam bir nedensel \u00e7\u0131kar\u0131m i\u00e7in iyile\u015ftirme veya geli\u015ftirme \u00f6nerileri sununuz.\n    \"\"\".strip()\n\n    try:\n        lang = detect(query)\n    except:\n        lang = \"en\"\n\n    chat_prompt, prompt_inputs = self.generate_prompt(\n        query=query,\n        prompt_tr=prompt_tr,\n        prompt_en=prompt_en,\n        lang=lang,\n        analysis_results=json.dumps(analysis_results, indent=4, ensure_ascii=(lang != \"tr\")),\n        graph_results=json.dumps(graph_results, indent=4, ensure_ascii=(lang != \"tr\"))\n    )\n\n    chain = chat_prompt | self.chat_model\n    try:\n        async for chunk in chain.astream(prompt_inputs):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n    except Exception as e:\n        print(\"\u274c LLM stream exception:\", str(e))\n        yield \"\u274c LLM model stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.causalpy_agent","title":"causalpy_agent  <code>async</code>","text":"<pre><code>causalpy_agent(json_file, query)\n</code></pre> <p>Interpret CausalPy synthetic-control (Sklearn/Bayesian) outputs.</p> <p>Parameters:</p> Name Type Description Default <code>json_file</code> <p>Path to synthetic control summaries JSON.</p> required <code>query</code> <p>User question to contextualize the causal impact.</p> required <p>Returns:</p> Type Description <p>Narrative explaining pre/post fit, counterfactuals, and estimated impact.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def causalpy_agent(self, json_file, query):\n    \"\"\"Interpret CausalPy synthetic-control (Sklearn/Bayesian) outputs.\n\n        Args:\n            json_file: Path to synthetic control summaries JSON.\n            query: User question to contextualize the causal impact.\n\n        Returns:\n            Narrative explaining pre/post fit, counterfactuals, and estimated impact.\n        \"\"\"\n    with open(\"services/AI/data/sklearn_and_bayesian_causal_impact_summary.json\", \"r\") as file:\n        analysis_results = json.load(file)\n\n    graph_results = {}\n    if os.path.exists(json_file):\n        with open(json_file, \"r\") as file:\n            graph_results = json.load(file)\n\n    try:\n        lang = detect(query)\n    except:\n        lang = \"en\"\n\n    prompt_en = \"\"\"\n    \ud83c\udfaf **Your Role:** You are a data scientist. Please interpret the following results with the technical and analytical mindset of a data scientist.\n    ### \ud83d\udd0d **Causal Inference Analysis Using CausalPy**\n\n    \ud83d\udcdd **User Query:** \"{query}\"\n\n    - The system has conducted a **causal analysis** using CausalPy.\n    - The dataset has been processed using both **Bayesian (PyMC)** and **Sklearn-based** Synthetic Control models.\n    - The results include **causal impact estimates, model fit scores, and graphical model insights**.\n\n    #### **\ud83d\udcca Bayesian &amp; Sklearn-Based Causal Analysis Results**\n    ```json\n    {analysis_results}\n    ```\n\n    #### **\ud83d\udcc9 Graphical Analysis Insights**\n    ```json\n    {graph_results}\n    ```\n\n    \u2753 **Interpretation Request**\n\n    Please provide a structured and in-depth interpretation of the results based on the following points:\n\n    ---\n\n    ### 1\ufe0f\u20e3 **Comparison: Bayesian vs. Sklearn-Based Models**\n    - How do the causal effect estimates differ between the two models?\n    - Which model demonstrates a better pre-intervention fit to the observed data?\n    - Does the Bayesian model offer better uncertainty quantification (e.g., credible intervals)?\n    - Are the model assumptions consistent across both methods?\n\n    ---\n\n    ### 2\ufe0f\u20e3 **Evaluation of Causal Impact Results**\n    - Is the estimated treatment effect statistically and practically significant?\n    - How closely does the counterfactual prediction match the actual observations?\n    - Are there any deviations or surprises in the post-intervention period?\n    - Is there evidence of delayed or cumulative treatment effects?\n\n    ---\n\n    ### 3\ufe0f\u20e3 **Model Robustness and Bias Assessment**\n    - Does either model show signs of overfitting or instability?\n    - How sensitive are the results to changes in predictor variables or treatment timing?\n    - Are the causal estimates stable across different time frames or subgroups?\n\n    ---\n\n    ### 4\ufe0f\u20e3 **Graphical Analysis Insights**\n    - How do the pre-intervention fit, causal impact plot, and cumulative impact chart support the conclusions?\n    - Are the trends in the graphical outputs consistent with numerical estimates?\n    - Do the graphs highlight any anomalies, structural breaks, or unexpected outliers?\n    - How do visual elements improve understanding of model performance and reliability?\n\n    ---\n\n    ### 5\ufe0f\u20e3 **Scientific Insights and Recommendations**\n    - What is the overall conclusion regarding the presence and magnitude of causal impact?\n    - Which model is more appropriate for making business or policy decisions?\n    - What additional checks (e.g., placebo tests, sensitivity analysis) could strengthen the findings?\n    - Are there alternative causal inference methods you would recommend testing?\n\n    ---\n\n    \ud83d\udccc Present your answer as if you are preparing a data science report for a technical audience. Include justifications, references to visual cues, and actionable recommendations based on the analysis.\n\n    \"\"\".strip()\n\n    prompt_tr = \"\"\"\n    \ud83e\udde0 **Rol\u00fcn:** Sen bir veri bilimcisin. L\u00fctfen a\u015fa\u011f\u0131daki \u00e7\u0131kt\u0131lar\u0131, bir veri bilimcinin sahip oldu\u011fu teknik ve analitik bak\u0131\u015f a\u00e7\u0131s\u0131yla de\u011ferlendir.  \n    ### \ud83d\udd0d **CausalPy Kullanarak Nedensel \u00c7\u0131kar\u0131m Analizi**\n\n    \ud83d\udcdd **Kullan\u0131c\u0131 Sorgusu:** \"{query}\"\n\n    - Sistem, **CausalPy** kullanarak bir **nedensel analiz** ger\u00e7ekle\u015ftirmi\u015ftir.  \n    - Veri k\u00fcmesi, hem **Bayesyen (PyMC)** hem de **Sklearn tabanl\u0131** Sentetik Kontrol modelleriyle i\u015flenmi\u015ftir.  \n    - Sonu\u00e7lar, **nedensel etki tahminleri**, **model uyum skorlar\u0131** ve **grafiksel model i\u00e7g\u00f6r\u00fcleri** i\u00e7ermektedir.\n\n    #### **\ud83d\udcca Bayesyen ve Sklearn Tabanl\u0131 Nedensel Analiz Sonu\u00e7lar\u0131**\n    ```json\n    {analysis_results}\n    ```\n\n    #### **\ud83d\udcc9 Grafiksel Analiz \u0130\u00e7g\u00f6r\u00fcleri**\n    ```json\n    {graph_results}\n    ```\n\n    1\ufe0f\u20e3 Bayesyen ve Sklearn Tabanl\u0131 Modelleri Kar\u015f\u0131la\u015ft\u0131r\u0131n\u0131z:\n        - Tahmin edilen nedensel etkiler aras\u0131nda nas\u0131l farklar var?\n        - Hangi model m\u00fcdahale \u00f6ncesi d\u00f6nemde daha iyi bir uyum sa\u011fl\u0131yor?\n        - Bayesyen \u00e7\u0131kar\u0131m, belirsizliklerin \u00f6l\u00e7\u00fcm\u00fcnde daha ba\u015far\u0131l\u0131 m\u0131?\n\n    2\ufe0f\u20e3 Nedensel Etki Sonu\u00e7lar\u0131n\u0131 De\u011ferlendiriniz:\n        - Tahmin edilen tedavi etkisi ne kadar anlaml\u0131?\n        - Kar\u015f\u0131 olgusal (counterfactual) tahminler beklentilerle \u00f6rt\u00fc\u015f\u00fcyor mu?\n        - M\u00fcdahale sonras\u0131 d\u00f6nemde ciddi sapmalar var m\u0131?\n\n    3\ufe0f\u20e3 Model Sapmalar\u0131 ve S\u0131n\u0131rl\u0131l\u0131klar\u0131 \u00dczerine Analiz:\n        - Modellerden biri a\u015f\u0131r\u0131 \u00f6\u011frenmeye (overfitting) maruz kal\u0131yor mu?\n        - Farkl\u0131 tahminci se\u00e7imlerine kar\u015f\u0131 sonu\u00e7lar ne kadar sa\u011flam?\n        - Nedensel etkiler zaman boyunca istikrarl\u0131 m\u0131?\n\n    4\ufe0f\u20e3 Bilimsel \u0130\u00e7g\u00f6r\u00fcler ve \u00d6nerilen Geli\u015ftirmeler:\n        - Hangi y\u00f6ntem karar verme a\u00e7\u0131s\u0131ndan daha g\u00fcvenilirdir?\n        - Ek sa\u011flaml\u0131k kontrolleri yap\u0131lmal\u0131 m\u0131?\n        - Test edilebilecek alternatif nedensel tahmin y\u00f6ntemleri nelerdir?\n\n    5\ufe0f\u20e3 Grafiksel \u0130\u00e7g\u00f6r\u00fcler ve Yorumlama:\n        - M\u00fcdahale \u00f6ncesi uyum, nedensel etki grafi\u011fi ve k\u00fcm\u00fclatif nedensel etki grafiklerinin yoruma katk\u0131s\u0131 nedir?\n        - Grafiksel \u00e7\u0131kt\u0131lardaki e\u011filimler, say\u0131sal nedensel tahminlerle tutarl\u0131 m\u0131?\n        - G\u00f6rseller, say\u0131sal \u00e7\u0131kt\u0131larda g\u00f6r\u00fclmeyen \u00f6nyarg\u0131lar ya da ayk\u0131r\u0131 de\u011ferler ortaya koyuyor mu?\n        - Grafiksel bulgular, nedensel \u00e7\u0131kar\u0131m sonu\u00e7lar\u0131n\u0131n g\u00fcvenilirli\u011fini ve sa\u011flaml\u0131\u011f\u0131n\u0131 nas\u0131l etkiler?\n\n    \ud83d\udccc L\u00fctfen yan\u0131t\u0131n\u0131z\u0131 a\u00e7\u0131k bilimsel a\u00e7\u0131klamalarla ve net \u00e7\u0131kar\u0131mlarla yap\u0131land\u0131r\u0131lm\u0131\u015f \u015fekilde sununuz.\n    \"\"\".strip()\n\n    chat_prompt, prompt_inputs = self.generate_prompt(\n        query=query,\n        prompt_tr=prompt_tr,\n        prompt_en=prompt_en,\n        lang=lang,\n        analysis_results=json.dumps(analysis_results, indent=4, ensure_ascii=(lang != \"tr\")),\n        graph_results=json.dumps(graph_results, indent=4, ensure_ascii=(lang != \"tr\"))\n    )\n\n    chain = chat_prompt | self.chat_model\n\n    try:\n        async for chunk in chain.astream(prompt_inputs):\n            yield chunk.content if hasattr(chunk, \"content\") else str(chunk)\n    except Exception as e:\n        print(\"\u274c LLM stream exception:\", str(e))\n        yield \"\u274c LLM model stream failed. Please try again later.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.filter_data_last_n_days","title":"filter_data_last_n_days  <code>staticmethod</code>","text":"<pre><code>filter_data_last_n_days(data, n_days)\n</code></pre> <p>Filter dataset to the last <code>n_days</code> based on available date columns.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Input DataFrame.</p> required <code>n_days</code> <p>Number of trailing days to keep.</p> required <p>Returns:</p> Type Description <p>Filtered DataFrame restricted to the latest period.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>@staticmethod\ndef filter_data_last_n_days(data, n_days):\n    \"\"\"Filter dataset to the last ``n_days`` based on available date columns.\n\n        Args:\n            data: Input DataFrame.\n            n_days: Number of trailing days to keep.\n\n        Returns:\n            Filtered DataFrame restricted to the latest period.\n        \"\"\"\n    df = pd.DataFrame(data)\n    if 'date' in df.columns:\n        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n        latest_date = df['date'].max()\n        earliest_date = df['date'].min()\n\n        max_available_days = (latest_date - earliest_date).days\n        if n_days &gt; max_available_days:\n            return None, f\"\u26a0\ufe0f Warning: The dataset only contains data for the last {max_available_days} days. Please adjust your query.\"\n\n        cutoff_date = latest_date - timedelta(days=n_days)\n        filtered_df = df[df['date'] &gt;= cutoff_date]\n\n        if filtered_df.empty:\n            return None, f\"\u26a0\ufe0f Warning: No data available for the last {n_days} days.\"\n\n        return filtered_df, None\n\n    start_cols = [col for col in df.columns if re.search(r'\\b(starts|begins)\\b', col.lower())]\n    end_cols = [col for col in df.columns if re.search(r'\\b(ends|finishes)\\b', col.lower())]\n\n    if not start_cols or not end_cols:\n        return None, \"\u26a0\ufe0f Warning: No valid date column ('date', 'start-*', 'end-*') found in the dataset.\"\n\n    start_col = start_cols[0]\n    end_col = end_cols[0]\n\n    df[start_col] = pd.to_datetime(df[start_col], errors='coerce')\n    df[end_col] = pd.to_datetime(df[end_col], errors='coerce')\n\n    latest_end = df[end_col].max()\n    earliest_start = df[start_col].min()\n\n    max_available_days = (latest_end - earliest_start).days\n    if n_days &gt; max_available_days:\n        return None, f\"\u26a0\ufe0f Warning: The maximum available date range is {max_available_days} days. Please adjust your query.\"\n\n    cutoff_date = latest_end - timedelta(days=n_days)\n\n    filtered_df = df[(df[start_col] &gt;= cutoff_date) &amp; (df[end_col] &lt;= latest_end)]\n\n    if filtered_df.empty:\n        return None, f\"\u26a0\ufe0f Warning: No data available for the last {n_days} days.\"\n\n    return filtered_df, None\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.extract_columns_from_query","title":"extract_columns_from_query","text":"<pre><code>extract_columns_from_query(query, available_columns)\n</code></pre> <p>Detect potential column names mentioned in a natural-language query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>Free-form user text.</p> required <code>available_columns</code> <p>List of column names to match against.</p> required <p>Returns:</p> Type Description <p>A list of best-guess column names (may be empty if none found).</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>def extract_columns_from_query(self, query, available_columns):\n    \"\"\"Detect potential column names mentioned in a natural-language query.\n\n        Args:\n            query: Free-form user text.\n            available_columns: List of column names to match against.\n\n        Returns:\n            A list of best-guess column names (may be empty if none found).\n        \"\"\"\n    words = re.findall(r'\\w+', query.lower())\n    seen = set()\n    detected_columns = []\n\n    for word in words:\n        if len(word) &lt; 2:\n            continue\n\n        match = self.find_best_column_match(word, available_columns)\n        if match and match not in seen:\n            detected_columns.append(match)\n            seen.add(match)\n\n    detected_columns = [col for col in detected_columns if col in available_columns]\n    return detected_columns\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.extract_column_name","title":"extract_column_name","text":"<pre><code>extract_column_name(query, field_name)\n</code></pre> <p>Extract a column referred to as <code>as &lt;FIELD_NAME&gt;</code> in the query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>User text potentially containing the pattern.</p> required <code>field_name</code> <p>Logical field label to search for (e.g., <code>\"metric\"</code>).</p> required <p>Returns:</p> Type Description <p>Extracted column name or <code>None</code> if not present.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>def extract_column_name(self, query, field_name):\n    \"\"\"Extract a column referred to as ``as &lt;FIELD_NAME&gt;`` in the query.\n\n        Args:\n            query: User text potentially containing the pattern.\n            field_name: Logical field label to search for (e.g., ``\"metric\"``).\n\n        Returns:\n            Extracted column name or ``None`` if not present.\n        \"\"\"\n    import re\n\n    # Sadece 'X as FIELD' e\u015fle\u015fmeleri yakalan\u0131r\n    pattern = rf\"(\\w+)\\s+as\\s+{field_name}\"\n    match = re.search(pattern, query, re.IGNORECASE)\n    if match:\n        candidate = match.group(1).lower()\n        stopwords = {\"and\", \"as\", \"with\", \"or\", \"not\"}\n        if candidate in stopwords:\n            return None\n        return candidate\n    return None\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.extract_days_from_query","title":"extract_days_from_query  <code>staticmethod</code>","text":"<pre><code>extract_days_from_query(query)\n</code></pre> <p>Parse phrases like \u201clast N days\u201d from the user query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>Input text.</p> required <p>Returns:</p> Type Description <p>Integer number of days if detected; otherwise <code>None</code>.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>@staticmethod\ndef extract_days_from_query(query):\n    \"\"\"Parse phrases like \u201clast N days\u201d from the user query.\n\n        Args:\n            query: Input text.\n\n        Returns:\n            Integer number of days if detected; otherwise ``None``.\n        \"\"\"\n    match = re.search(r'(?:last\\s*)?(\\d+)\\s*(?:days|day)', query, re.IGNORECASE)\n    return int(match.group(1)) if match else None\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.generate_plots","title":"generate_plots","text":"<pre><code>generate_plots(data, columns)\n</code></pre> <p>Generate appropriate plots based on column-type combinations.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Source DataFrame used to draw figures.</p> required <code>columns</code> <p>Iterable of column pairs to visualize.</p> required <p>Returns:</p> Type Description <p>A collection of figure objects or file paths to saved plots.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>def generate_plots(self, data, columns):\n    \"\"\"Generate appropriate plots based on column-type combinations.\n\n        Args:\n            data: Source DataFrame used to draw figures.\n            columns: Iterable of column pairs to visualize.\n\n        Returns:\n            A collection of figure objects or file paths to saved plots.\n        \"\"\"\n    data = pd.DataFrame(data)\n    for col1, col2 in columns:\n        if col1 in data.columns and col2 in data.columns:\n            if os.path.exists(\"data/num_num.json\"):\n                with open(\"data/num_num.json\") as file:\n                    result = json.loads(file.read())\n                correlation_method = next(iter(result.keys())).lower()\n            else:\n                edaAnalysis(self.eda_cleaned_df, col1, col2)\n                with open(\"data/num_num.json\") as file:\n                    result = json.loads(file.read())\n                correlation_method = next(iter(result.keys())).lower()\n\n            return all_graphs(data, col1, col2, correlation_method)\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.determine_query_type","title":"determine_query_type  <code>async</code>","text":"<pre><code>determine_query_type(query)\n</code></pre> <p>Classify the user query into an analysis category.</p> <p>Uses LLM-based streaming classification with keyword fallbacks.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>End-user prompt.</p> required <p>Returns:</p> Type Description <p>One of ``{\"eda\",\"analyze\",\"shap\",\"geolift\",\"dowecon\",\"causalpy\",</p> <p>\"ts\",\"wiki\",\"plot\",\"ab\",\"assoc\",\"unknown\"}``.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def determine_query_type(self, query):\n    \"\"\"Classify the user query into an analysis category.\n\n        Uses LLM-based streaming classification with keyword fallbacks.\n\n        Args:\n            query: End-user prompt.\n\n        Returns:\n            One of ``{\"eda\",\"analyze\",\"shap\",\"geolift\",\"dowecon\",\"causalpy\",\n            \"ts\",\"wiki\",\"plot\",\"ab\",\"assoc\",\"unknown\"}``.\n        \"\"\"\n    classification_prompt = f\"\"\"\n    You are a smart AI assistant that classifies user queries into one of the following categories:\n\n    - eda \u2192 Summary statistics, distributions, correlation tests, variable types\n    - analyze \u2192 Metric behavior over time, performance trends, metric-level changes\n    - shap \u2192 SHAP values, feature importance, model interpretability\n    - geolift \u2192 Regional or geo-based impact, marketing uplift\n    - dowEcon \u2192 DoWhy/EconML causal inference, DAG-based reasoning\n    - causalPy \u2192 Bayesian or time-series causal analysis (e.g. synthetic control)\n    - ts \u2192 Time series analysis, Prophet, forecasting, seasonal decomposition\n    - wiki \u2192 General knowledge or definitions (e.g. \"What is CTR?\")\n    - plot \u2192 Requests for visualizations or chart generation\n    - ab \u2192 A/B testing, experiment comparison, statistical significance tests\n    - assoc \u2192 Association rules, market basket analysis, frequent itemset mining\n\n    Your task: Based on the user query, return ONLY the category name (`eda`, `analyze`, etc.) with no explanation or formatting.\n\n    User query:\n    \\\"{query}\\\"\n\n    Your answer:\n    \"\"\"\n\n    collected = \"\"\n    async for chunk in self.chat_model.astream(classification_prompt):\n        collected += chunk.content\n\n    response = collected.strip().lower()\n\n    valid_categories = {\n        \"eda\", \"analyze\", \"shap\", \"geolift\", \"dowecon\", \"causalpy\", \"ts\", \"wiki\", \"plot\", \"ab\", \"assoc\"\n    }\n\n    for cat in valid_categories:\n        if cat in response:\n            return cat\n\n    # Fallback keyword-based detection for AB Testing\n    ab_keywords = [\"a/b test\", \"ab test\", \"split test\", \"ab testing\", \"experiment comparison\", \"significance test\"]\n    if any(kw in query.lower() for kw in ab_keywords):\n        return \"ab\"\n\n    # Fallback keyword-based detection for Association Rules\n    assoc_keywords = [\n        \"association rules\", \"market basket\", \"apriori\", \"fpgrowth\", \"fp-growth\",\n        \"frequent itemset\", \"lift\", \"confidence\", \"support\"\n    ]\n    if any(kw in query.lower() for kw in assoc_keywords):\n        return \"assoc\"\n\n    if self.parse_causal_query(query):\n        return \"dowecon\"\n    elif self.parse_causalpy_query(query):\n        return \"causalpy\"\n    elif \"time series\" in query.lower() or \"forecast\" in query.lower():\n        return \"ts\"\n\n    return \"unknown\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.normalize","title":"normalize  <code>staticmethod</code>","text":"<pre><code>normalize(text)\n</code></pre> <p>Lowercase and strip special characters for robust matching.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>Input string.</p> required <p>Returns:</p> Type Description <p>Normalized string suitable for comparisons.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>@staticmethod\ndef normalize(text):\n    \"\"\"Lowercase and strip special characters for robust matching.\n\n        Args:\n            text: Input string.\n\n        Returns:\n            Normalized string suitable for comparisons.\n        \"\"\"\n    return re.sub(r'[^a-zA-Z0-9]', '', text.lower())\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.find_best_column_match","title":"find_best_column_match","text":"<pre><code>find_best_column_match(\n    user_column, available_columns, verbose=True\n)\n</code></pre> <p>Fuzzy-match the requested column name to the closest available one.</p> <p>Parameters:</p> Name Type Description Default <code>user_column</code> <p>Column name as provided by the user.</p> required <code>available_columns</code> <p>Valid columns in the dataset.</p> required <p>Returns:</p> Type Description <p>The best-matching column name, or <code>None</code> if no acceptable match.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>def find_best_column_match(self, user_column, available_columns, verbose=True):\n    \"\"\"Fuzzy-match the requested column name to the closest available one.\n\n        Args:\n            user_column: Column name as provided by the user.\n            available_columns: Valid columns in the dataset.\n\n        Returns:\n            The best-matching column name, or ``None`` if no acceptable match.\n        \"\"\"\n    user_column_cleaned = self.normalize(user_column)\n\n    column_mapping = {\n        self.normalize(col): col for col in available_columns\n    }\n\n    if user_column_cleaned in column_mapping:\n        matched = column_mapping[user_column_cleaned]\n        if verbose:\n            print(f\"\u2705 [EXACT MATCH] '{user_column}' \u2192 '{matched}'\")\n        return matched\n\n    for norm_col, original_col in column_mapping.items():\n        if user_column_cleaned in norm_col or norm_col.startswith(user_column_cleaned):\n            if verbose:\n                print(f\"\ud83d\udd0e [SUBSTRING MATCH] '{user_column}' \u2192 '{original_col}'\")\n            return original_col\n\n    closest_match = difflib.get_close_matches(\n        user_column_cleaned, column_mapping.keys(), n=1, cutoff=0.85\n    )\n    if closest_match:\n        matched = column_mapping[closest_match[0]]\n        if verbose:\n            print(f\"\ud83c\udf00 [FUZZY MATCH] '{user_column}' \u2192 '{matched}' (score \u2248 close)\")\n        return matched\n\n    if verbose:\n        print(f\"\u274c [NO MATCH] '{user_column}' \u2192 None\")\n\n    return None\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.validate_columns","title":"validate_columns  <code>staticmethod</code>","text":"<pre><code>validate_columns(cols, cleaned_df, raw_df=None)\n</code></pre> <p>Validate that requested columns exist in cleaned/raw datasets.</p> <p>Parameters:</p> Name Type Description Default <code>cols</code> <p>Column names to validate.</p> required <code>cleaned_df</code> <p>Cleaned DataFrame.</p> required <code>raw_df</code> <p>Optional raw DataFrame for cross-checks.</p> <code>None</code> <p>Returns:</p> Type Description <p><code>None</code> if all columns are valid; otherwise a descriptive error message.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>@staticmethod\ndef validate_columns(cols, cleaned_df, raw_df=None):\n    \"\"\"Validate that requested columns exist in cleaned/raw datasets.\n\n        Args:\n            cols: Column names to validate.\n            cleaned_df: Cleaned DataFrame.\n            raw_df: Optional raw DataFrame for cross-checks.\n\n        Returns:\n            ``None`` if all columns are valid; otherwise a descriptive error message.\n        \"\"\"\n    raw_columns = raw_df.columns.tolist() if raw_df is not None else []\n    for col in cols:\n        if col is None:\n            return \"\u274c One of the columns could not be matched.\"\n        if col not in cleaned_df.columns:\n            if raw_df is not None and col in raw_columns:\n                return f\"\u26a0\ufe0f Column '{col}' was removed during data cleaning.\"\n            return f\"\u274c Column '{col}' does not exist in the dataset.\"\n    return None\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.eda_analysis","title":"eda_analysis  <code>async</code>","text":"<pre><code>eda_analysis(user_query, cleaned_df)\n</code></pre> <p>Run EDA on two columns detected from the query.</p> <p>Detects/validates columns, executes statistical tests and plots (e.g., posterior predictive checks, MCMC traces, ACF), and streams an interpreted summary via <code>eda_agent</code>.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <p>Natural language request (must imply \u22652 columns).</p> required <code>cleaned_df</code> <p>EDA-ready DataFrame.</p> required <p>Yields:</p> Type Description <p>Markdown/text chunks summarizing EDA results and visuals.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def eda_analysis(self, user_query, cleaned_df):\n    \"\"\"Run EDA on two columns detected from the query.\n\n        Detects/validates columns, executes statistical tests and plots\n        (e.g., posterior predictive checks, MCMC traces, ACF), and streams an\n        interpreted summary via ``eda_agent``.\n\n        Args:\n            user_query: Natural language request (must imply \u22652 columns).\n            cleaned_df: EDA-ready DataFrame.\n\n        Yields:\n            Markdown/text chunks summarizing EDA results and visuals.\n        \"\"\"\n    detected_columns = self.extract_columns_from_query(user_query, cleaned_df.columns.tolist())\n\n    if len(detected_columns) &lt; 2:\n        yield \"Please specify at least two valid columns.\"\n        return\n\n    validate_msg = self.validate_columns(detected_columns, cleaned_df, self.df_raw)\n    if validate_msg:\n        yield validate_msg\n        return\n\n    print(\"\ud83e\udde0 Detected columns:\", detected_columns)\n    col1, col2 = detected_columns[:2]\n    print(\"\u27a1\ufe0f Using columns:\", col1, col2)\n\n    edaAnalysis(cleaned_df, col1, col2)\n\n    image_paths = [\"services/AI/plots/pp_check.png\", \"services/AI/plots/mcmc_trace.png\", \"services/AI/plots/mcmc_acf.png\"]\n    predefined_titles = [\"Posterior Predictive Check\", \"MCMC Trace Plot\", \"Autocorrelation Function (ACF)\"]\n    predefined_filenames = [\"pp_check.png\", \"mcmc_trace.png\", \"mcmc_acf.png\"]\n    json_files = {\n        \"num_num\": \"services/AI/data/num_num.json\",\n        \"num_cat\": \"services/AI/data/num_cat.json\",\n        \"cat_cat\": \"services/AI/data/cat_cat.json\"\n    }\n\n    run_test(image_paths, predefined_titles, predefined_filenames, \"services/AI/plots/scientific_image_analysis.json\", \"eda\")\n\n    try:\n        async for chunk in self.eda_agent(json_files, cleaned_df, col1, col2, user_query):\n            yield chunk\n    except Exception as e:\n        print(\"\u274c EDA Agent Exception:\", str(e))\n        yield \"EDA analysis failed due to internal error.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.shap_analysis","title":"shap_analysis  <code>async</code>","text":"<pre><code>shap_analysis(user_query, cleaned_df)\n</code></pre> <p>Compute and explain SHAP values for a detected target variable.</p> <p>Trains the best-fit model for the target and streams SHAP interpretation via <code>shap_agent</code>.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <p>Query mentioning a target metric (e.g., <code>\"CTR\"</code>).</p> required <code>cleaned_df</code> <p>Cleaned DataFrame used for modeling.</p> required <p>Yields:</p> Type Description <p>Narrative chunks covering global/local importance and caveats.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def shap_analysis(self, user_query, cleaned_df):\n    \"\"\"Compute and explain SHAP values for a detected target variable.\n\n        Trains the best-fit model for the target and streams SHAP interpretation\n        via ``shap_agent``.\n\n        Args:\n            user_query: Query mentioning a target metric (e.g., ``\"CTR\"``).\n            cleaned_df: Cleaned DataFrame used for modeling.\n\n        Yields:\n            Narrative chunks covering global/local importance and caveats.\n        \"\"\"\n    available_columns = cleaned_df.columns.tolist()\n    target_var = self.extract_shap_target_column(user_query, available_columns)\n\n    if not target_var:\n        yield \"\u274c Could not detect a target variable for SHAP analysis. Try asking about a specific variable like 'CTR' or 'conversions'.\"\n        return\n\n    validate_msg = self.validate_columns([target_var], cleaned_df, self.df_raw)\n    if validate_msg:\n        yield validate_msg\n        return\n\n    try:\n        getBestModel(cleaned_df, target_var, query=user_query)\n    except Exception as e:\n        print(\"\u274c Error in SHAP model training:\", str(e))\n        yield f\"\u274c Failed to compute SHAP analysis: {e}\"\n        return\n\n    try:\n        async for chunk in self.shap_agent(target_var, user_query):\n            yield chunk\n    except Exception as e:\n        print(\"\u274c Shap Agent Exception:\", str(e))\n        yield \"Shap analysis failed due to internal error.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.ts_analysis","title":"ts_analysis  <code>async</code>","text":"<pre><code>ts_analysis(user_query, cleaned_df)\n</code></pre> <p>Perform time-series analysis (Prophet forecasts / Granger tests).</p> <p>Expands ranges to daily level, infers forecast horizon and metric(s), runs forecasts and/or Granger causality, optionally builds a dashboard, and streams explanations via <code>ts_agent</code>.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <p>Forecast/causality question (may include horizon like \u201cnext 30 days\u201d).</p> required <code>cleaned_df</code> <p>Time-series-ready DataFrame.</p> required <p>Yields:</p> Type Description <p>Stepwise summaries and final conclusions with saved artifacts.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def ts_analysis(self, user_query, cleaned_df):\n    \"\"\"Perform time-series analysis (Prophet forecasts / Granger tests).\n\n        Expands ranges to daily level, infers forecast horizon and metric(s),\n        runs forecasts and/or Granger causality, optionally builds a dashboard,\n        and streams explanations via ``ts_agent``.\n\n        Args:\n            user_query: Forecast/causality question (may include horizon like \u201cnext 30 days\u201d).\n            cleaned_df: Time-series-ready DataFrame.\n\n        Yields:\n            Stepwise summaries and final conclusions with saved artifacts.\n        \"\"\"\n    expander = DailyDistributionExpander()\n    metrics_to_expand = cleaned_df.select_dtypes(include=[np.number]).columns.tolist()\n    dashboard=None\n    daily_df = expander.expand(\n        cleaned_df,\n        metrics_to_expand,\n        start_col='date_start',\n        end_col='date_stop',\n        id_col='campaign_name'\n    )\n\n    daily_df.columns = [\n        col.replace(\"daily_\", \"\") if col.startswith(\"daily_\") else col\n        for col in daily_df.columns\n    ]\n\n    query = user_query.lower()\n    found_cols = [col for col in metrics_to_expand if col.lower() in query]\n    forecast_horizon = 30\n\n    day_match = re.search(r\"(\\d+)\\s*(g[\u00fcu]n|day[s]?)\", query)\n    company = None\n    for c in daily_df[\"campaign_name\"].unique().tolist():\n        if re.search(rf\"\\b{re.escape(c.lower())}\\b\", query.lower()):\n            company = c\n            break\n    if day_match:\n        forecast_horizon = int(day_match.group(1))\n    if len(found_cols) == 0:\n        process = {\"mode\": \"general\", \"forecast\": False, \"granger\": False, \"columns\": [], \"horizon\": forecast_horizon}\n\n    elif len(found_cols) == 1:\n        process= {\"mode\": \"single_metric\", \"forecast\": True, \"granger\": True, \"columns\": found_cols,\n                \"horizon\": forecast_horizon}\n\n    elif len(found_cols) == 2:\n        process= {\"mode\": \"pairwise_granger\", \"forecast\": False, \"granger\": True, \"columns\": found_cols,\n                \"horizon\": None}\n\n    else:\n        process= {\"mode\": \"multi_column_ambiguous\", \"forecast\": False, \"granger\": False, \"columns\": found_cols,\n                \"horizon\": None}\n\n    analyzer = TimeSeriesAnalyzer(df=daily_df, company=company, country=\"TR\")\n\n    if process[\"mode\"] == \"general\":\n        all_columns = metrics_to_expand\n        all_results = []\n\n        for col in all_columns:\n            result = analyzer.run_prophet(col=col, horizon=process[\"horizon\"])\n            result[\"metric\"] = col\n            all_results.append(result)\n\n        with open(f\"services/AI/data/ts_metrics.json\", \"w\") as f:\n            json.dump(all_results, f, indent=4)\n\n\n    elif process[\"mode\"] == \"single_metric\" and len(process[\"columns\"]) == 1:\n        col = process[\"columns\"][0]\n\n        forecast_result = analyzer.run_prophet(col=col, horizon=process[\"horizon\"])\n\n        granger_result = analyzer.run_granger(col1=col, col2=None)\n\n        dashboard = analyzer.plot_forecast_dashboard()\n\n        combined_result = {\n            \"metric\": col,\n            \"forecast_result\": forecast_result,\n            \"granger_result\": granger_result\n        }\n        output_path = f\"services/AI/data/ts_metrics.json\"\n        with open(output_path, \"w\") as f:\n            json.dump(combined_result, f, indent=4)\n\n        # dashboard.servable(\"Forecast Dashboard\")\n\n\n    elif process[\"mode\"] == \"pairwise_granger\" and len(process[\"columns\"]) == 2:\n        col1, col2 = process[\"columns\"]\n\n        granger_result = analyzer.run_granger(col1=col1, col2=col2)\n\n        result_data = {\n            \"mode\": \"pairwise_granger\",\n            \"col1\": col1,\n            \"col2\": col2,\n            \"granger_result\": granger_result\n        }\n\n        filename = f\"services/AI/data/ts_metrics.json\"\n\n        with open(filename, \"w\") as f:\n            json.dump(result_data, f, indent=4)\n\n        print(f\"Granger result saved to {filename}\")\n\n\n    else:\n        print(\"No valid processing mode matched.\")\n\n    try:\n        async for chunk in self.ts_agent(user_query, dashboard):\n            yield chunk\n    except Exception as e:\n        print(\"\u274c Time Series Agent Exception:\", str(e))\n        yield \"Time Series analysis failed due to internal error.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.geo_analysis","title":"geo_analysis","text":"<pre><code>geo_analysis(user_query, df)\n</code></pre> <p>Run GeoLift power/impact analysis from a structured query.</p> <p>Parses metric/location/date, optional hyperparameters (budget, cpic, alpha, treatment start/duration), renames columns to GeoLift schema, executes <code>powerAnalysis</code>, and returns an interpreted summary via <code>geo_agent</code>.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <p>Structured query (e.g., <code>Using revenue as metric ...</code>).</p> required <code>df</code> <p>DataFrame containing metric, location, and date columns.</p> required <p>Returns:</p> Type Description <p>Natural-language explanation of the GeoLift setup and results.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>def geo_analysis(self, user_query, df):\n    \"\"\"Run GeoLift power/impact analysis from a structured query.\n\n        Parses metric/location/date, optional hyperparameters (budget, cpic, alpha,\n        treatment start/duration), renames columns to GeoLift schema, executes\n        ``powerAnalysis``, and returns an interpreted summary via ``geo_agent``.\n\n        Args:\n            user_query: Structured query (e.g., ``Using revenue as metric ...``).\n            df: DataFrame containing metric, location, and date columns.\n\n        Returns:\n            Natural-language explanation of the GeoLift setup and results.\n        \"\"\"\n    import os\n    import re\n\n    budget_value = 10000\n    cpic = None\n    alpha = 0.05\n    treatment_start = None\n    treatment_duration = None\n    #df = pd.read_csv(\"geo_data.csv\")\n    #raw_columns = df.columns.tolist()\n    raw_columns = self.df_raw.columns.tolist()\n    available_columns = df.columns.tolist()\n    removed = []\n\n    # \ud83e\udde0 Kolonlar\u0131 query'den \u00e7\u0131karmaya \u00e7al\u0131\u015f\n    parsed = self.parse_geolift_query(user_query)\n    if not parsed:\n        return \"\u274c Could not extract metric, location, and date columns from your query. Use formats like: 'Using spend as metric and region as location and date as date'.\"\n\n    metric_col = self.find_best_column_match(parsed[\"metric\"], available_columns)\n    location_col = self.find_best_column_match(parsed[\"location\"], available_columns)\n    date_col = self.find_best_column_match(parsed[\"date\"], available_columns)\n\n    # \u2705 Kolonlar\u0131n mevcudiyetini kontrol et\n    for col_name, var in [(\"Metric\", metric_col), (\"Location\", location_col), (\"Date\", date_col)]:\n        if not var:\n            removed.append(f\"\u274c {col_name} column not specified or matched in the dataset.\")\n        elif var not in raw_columns:\n            removed.append(f\"\u274c {col_name} column '{var}' does not exist in the dataset.\")\n        elif var not in available_columns:\n            removed.append(f\"\u26a0\ufe0f {col_name} column '{var}' was removed during data cleaning.\")\n\n    if any(msg.startswith(\"\u274c\") or msg.startswith(\"\u26a0\ufe0f Metric\") for msg in removed):\n        return \"\\n\".join(removed) + \"\\n\u274c Cannot proceed with GeoLift analysis.\"\n\n    if match := re.search(r\"budget (\\d+(?:\\.\\d+)?)\", user_query, re.IGNORECASE):\n        budget_value = float(match.group(1))\n\n    if match := re.search(r\"cpic (\\d+(?:\\.\\d+)?)\", user_query, re.IGNORECASE):\n        cpic = float(match.group(1))\n\n    if match := re.search(r\"alpha (\\d+(?:\\.\\d+)?)\", user_query, re.IGNORECASE):\n        alpha = float(match.group(1))\n\n    if match := re.search(r\"treatment start (\\d{4}-\\d{2}-\\d{2})\", user_query, re.IGNORECASE):\n        treatment_start = match.group(1)\n\n    if match := re.search(r\"treatment duration (\\d+)\", user_query, re.IGNORECASE):\n        treatment_duration = int(match.group(1))\n\n    # \ud83d\udd04 GeoLift i\u00e7in rename et\n    df = df.rename(columns={\n        date_col: \"time\",\n        location_col: \"location\",\n        metric_col: \"Y\"\n    })\n\n    os.makedirs(\"services/AI/data\", exist_ok=True)\n\n    powerAnalysis(\n        df=df,\n        date_id=\"time\",\n        location_id=\"location\",\n        y_id=\"Y\",\n        budget=budget_value,\n        cpic=cpic,\n        treatment_start=treatment_start,\n        treatment_duration=treatment_duration,\n        alpha=alpha\n    )\n\n    return self.geo_agent(\"services/AI/data/model_summaries.json\", user_query)\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.dowhy_econml_analysis","title":"dowhy_econml_analysis","text":"<pre><code>dowhy_econml_analysis(user_query, cleaned_df)\n</code></pre> <p>Estimate causal effects with DoWhy/EconML and interpret results.</p> <p>Parses treatment/outcome/confounders (and optional instrument, treatment_time, target_unit), validates variables, runs <code>causalModel</code>, generates diagnostics, and summarizes results via <code>dowhy_agent</code>.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <p>Causal query (key-value format).</p> required <code>cleaned_df</code> <p>Cleaned DataFrame suitable for causal estimation.</p> required <p>Returns:</p> Type Description <p>Final narrative; prepended with warnings if variables were missing/removed.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>def dowhy_econml_analysis(self, user_query, cleaned_df):\n    \"\"\"Estimate causal effects with DoWhy/EconML and interpret results.\n\n        Parses treatment/outcome/confounders (and optional instrument, treatment_time,\n        target_unit), validates variables, runs ``causalModel``, generates diagnostics,\n        and summarizes results via ``dowhy_agent``.\n\n        Args:\n            user_query: Causal query (key-value format).\n            cleaned_df: Cleaned DataFrame suitable for causal estimation.\n\n        Returns:\n            Final narrative; prepended with warnings if variables were missing/removed.\n        \"\"\"\n    import os\n\n    parsed = self.parse_causal_query(user_query)\n\n    if not parsed:\n        return \"\u274c Could not parse the query format...\"\n\n    treatment_var = parsed[\"treatment\"]\n    outcome_var = parsed[\"outcome\"]\n    confounders_var = parsed[\"confounders\"]\n    instrument_var = parsed.get(\"instrument\")\n    treatment_time_var = parsed.get(\"treatment_time\")\n    target_unit_var = parsed.get(\"target_unit\") or treatment_var\n\n    raw_columns = self.df_raw.columns.tolist()\n    available_columns = cleaned_df.columns.tolist()\n    removed = []\n\n    # 1. treatment\n    if treatment_var not in raw_columns:\n        removed.append(f\"\u274c Treatment column '{treatment_var}' does not exist in the dataset.\")\n    elif treatment_var not in available_columns:\n        removed.append(f\"\u26a0\ufe0f Treatment column '{treatment_var}' was removed due to high VIF.\")\n\n    # 2. outcome\n    if outcome_var not in raw_columns:\n        removed.append(f\"\u274c Outcome column '{outcome_var}' does not exist in the dataset.\")\n    elif outcome_var not in available_columns:\n        removed.append(f\"\u26a0\ufe0f Outcome column '{outcome_var}' was removed due to high VIF.\")\n\n    # 3. instrument\n    if instrument_var:\n        if instrument_var not in raw_columns:\n            removed.append(f\"\u274c Instrument column '{instrument_var}' does not exist in the dataset.\")\n            instrument_var = None\n        elif instrument_var not in available_columns:\n            removed.append(f\"\u26a0\ufe0f Instrument column '{instrument_var}' was removed due to high VIF.\")\n            instrument_var = None\n\n    # 4. target_unit\n    if target_unit_var not in raw_columns:\n        removed.append(f\"\u274c Target unit column '{target_unit_var}' does not exist in the dataset.\")\n        target_unit_var = treatment_var\n    elif target_unit_var not in available_columns:\n        removed.append(f\"\u26a0\ufe0f Target unit column '{target_unit_var}' was removed due to high VIF.\")\n        target_unit_var = treatment_var\n\n    # 5. confounders\n    valid_confounders = []\n    removed_confounders = []\n    missing_confounders = []\n\n    for c in confounders_var:\n        if c not in raw_columns:\n            missing_confounders.append(c)\n        elif c not in available_columns:\n            removed_confounders.append(c)\n        else:\n            valid_confounders.append(c)\n\n    if missing_confounders:\n        removed.append(f\"\u274c These confounders do not exist in the dataset: {missing_confounders}\")\n    if removed_confounders:\n        removed.append(f\"\u26a0\ufe0f These confounders were removed due to high VIF: {removed_confounders}\")\n\n    confounders_var = valid_confounders\n\n    # 6. Kritik eksikler varsa i\u015flemi iptal et\n    if any(msg.startswith(\"\u274c\") or msg.startswith(\"\u26a0\ufe0f Treatment\") or msg.startswith(\"\u26a0\ufe0f Outcome\") for msg in\n           removed):\n        return \"\\n\".join(removed) + \"\\n\u274c Cannot proceed with analysis due to missing key variables.\"\n\n    # 4. Kolon isimlerini normalize et\n    treatment_var = self.find_best_column_match(treatment_var, available_columns)\n    outcome_var = self.find_best_column_match(outcome_var, available_columns)\n    if instrument_var:\n        instrument_var = self.find_best_column_match(instrument_var, available_columns)\n    confounders_var = [self.find_best_column_match(c, available_columns) for c in confounders_var]\n    target_unit_var = self.find_best_column_match(target_unit_var, available_columns)\n\n    # 5. Son kontrol\n    validate_msg = self.validate_columns(\n        [treatment_var, outcome_var, target_unit_var] +\n        ([instrument_var] if instrument_var else []) +\n        confounders_var,\n        cleaned_df,\n        self.df_raw\n    )\n    if validate_msg:\n        return validate_msg\n\n    # 6. Analizi \u00e7al\u0131\u015ft\u0131r\n    os.makedirs(\"services/AI/data\", exist_ok=True)\n    os.makedirs(\"services/AI/plots\", exist_ok=True)\n\n    causalModel(\n        cleaned_df,\n        treatment=treatment_var,\n        outcome=outcome_var,\n        confounders=confounders_var,\n        instrument=instrument_var,\n        treatment_time=treatment_time_var,\n        target_unit=target_unit_var\n    )\n\n    image_paths = [\"services/AI/plots/unobserved_confounder_heatmap.png\"]\n    predefined_titles = [\"DoWhy Unobserved Confounder Heatmap\"]\n    predefined_filenames = [\"unobserved_confounder_heatmap.png\"]\n    json_file = \"services/AI/data/dowhy_econml_causal.json\"\n\n    run_test(image_paths, predefined_titles, predefined_filenames, \"services/AI/plots/dowhy_image_analysis.json\",\n             \"dowhy\")\n    dowhy_result = self.dowhy_agent(json_file, user_query)\n\n    # 7. Uyar\u0131lar\u0131 analizin ba\u015f\u0131na ekleyerek d\u00f6nd\u00fcr\n    if removed:\n        return \"\\n\".join(removed) + \"\\n\\n\u2705 Analysis completed:\\n\" + dowhy_result\n    else:\n        return dowhy_result\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.causalPy_analysis","title":"causalPy_analysis","text":"<pre><code>causalPy_analysis(user_query, cleaned_df)\n</code></pre> <p>Run CausalPy synthetic control (Sklearn and Bayesian) and explain impact.</p> <p>Parses outcome/predictors/treatment_time, validates variables, executes <code>synthetic_control</code> variants, saves plots/JSON, and summarizes via <code>causalpy_agent</code>.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <p>CausalPy query (e.g., <code>Using revenue as outcome, ...</code>).</p> required <code>cleaned_df</code> <p>Cleaned DataFrame.</p> required <p>Returns:</p> Type Description <p>Narrative summary; warnings (if any) are prepended to the final text.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>def causalPy_analysis(self, user_query, cleaned_df):\n    \"\"\"Run CausalPy synthetic control (Sklearn and Bayesian) and explain impact.\n\n        Parses outcome/predictors/treatment_time, validates variables, executes\n        ``synthetic_control`` variants, saves plots/JSON, and summarizes via\n        ``causalpy_agent``.\n\n        Args:\n            user_query: CausalPy query (e.g., ``Using revenue as outcome, ...``).\n            cleaned_df: Cleaned DataFrame.\n\n        Returns:\n            Narrative summary; warnings (if any) are prepended to the final text.\n        \"\"\"\n    parsed = self.parse_causalpy_query(user_query)  # \u2705 Ayn\u0131 regex yap\u0131s\u0131 kullan\u0131l\u0131r\n\n    if not parsed:\n        return \"\u274c Could not parse the query format for CausalPy. Use formats like: 'Using X as outcome, analyze the causal effect with predictors [A, B, C] at time 10'.\"\n\n    outcome_var = parsed[\"outcome\"]\n    predictors_var = parsed[\"predictors\"]\n    treatment_time_var = parsed.get(\"treatment_time\")\n\n    raw_columns = self.df_raw.columns.tolist()\n    available_columns = cleaned_df.columns.tolist()\n    removed = []\n\n    # Outcome\n    if outcome_var not in raw_columns:\n        removed.append(f\"\u274c Outcome column '{outcome_var}' does not exist in the dataset.\")\n    elif outcome_var not in available_columns:\n        removed.append(f\"\u26a0\ufe0f Outcome column '{outcome_var}' was removed due to high VIF.\")\n\n    # Predictors\n    valid_predictors = []\n    removed_predictors = []\n    missing_predictors = []\n\n    for c in predictors_var:\n        if c not in raw_columns:\n            missing_predictors.append(c)\n        elif c not in available_columns:\n            removed_predictors.append(c)\n        else:\n            valid_predictors.append(c)\n\n    if missing_predictors:\n        removed.append(f\"\u274c These predictors do not exist in the dataset: {missing_predictors}\")\n    if removed_predictors:\n        removed.append(f\"\u26a0\ufe0f These predictors were removed due to high VIF: {removed_predictors}\")\n\n    predictors_var = valid_predictors\n\n    # Check if critical elements are missing\n    if any(msg.startswith(\"\u274c\") or msg.startswith(\"\u26a0\ufe0f Outcome\") for msg in removed):\n        return \"\\n\".join(removed) + \"\\n\u274c Cannot proceed with analysis due to missing key variables.\"\n\n    # Match actual column names (fuzzy matching)\n    outcome_var = self.find_best_column_match(outcome_var, available_columns)\n    predictors_var = [self.find_best_column_match(c, available_columns) for c in predictors_var]\n\n    validate_msg = self.validate_columns([outcome_var] + predictors_var, cleaned_df, self.df_raw)\n    if validate_msg:\n        return validate_msg\n\n    # Run analysis\n    os.makedirs(\"services/AI/data\", exist_ok=True)\n    os.makedirs(\"services/AI/plots\", exist_ok=True)\n\n    try:\n        synthetic_control(\n            df=cleaned_df,\n            outcome=outcome_var,\n            predictors=predictors_var,\n            treatment_time=treatment_time_var\n        )\n\n        image_paths = [\n            \"services/AI/plots/synthetic_control_with_sklearn.png\",\n            \"services/AI/plots/synthetic_control_with_bayesian.png\"\n        ]\n        predefined_titles = [\n            \"Synthetic Control (Sklearn-Based)\",\n            \"Bayesian Synthetic Control (PyMC)\"\n        ]\n        predefined_filenames = [\n            \"synthetic_control_with_sklearn.png\",\n            \"synthetic_control_with_bayesian.png\"\n        ]\n        json_file = \"services/AI/data/sklearn_and_bayesian_causal_impact_summary.json\"\n\n        if not os.path.exists(json_file):\n            return \"\u274c Error: JSON file containing causal analysis results was not created.\"\n\n        run_test(image_paths, predefined_titles, predefined_filenames,\n                 \"services/AI/plots/bayesian_sklearn_image_analysis.json\", \"causalpy\")\n        result = self.causalpy_agent(json_file, user_query)\n\n    except Exception as e:\n        result = f\"\u274c An error occurred during CausalPy analysis: {str(e)}\"\n\n    return \"\\n\".join(removed) + \"\\n\\n\u2705 Analysis completed:\\n\" + result if removed else result\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.combined_analysis","title":"combined_analysis  <code>async</code>","text":"<pre><code>combined_analysis(query)\n</code></pre> <p>Route a user query to the appropriate analysis pipeline and stream outputs.</p> <p>Uses <code>determine_query_type</code> and clears previous state (non-wiki). Dispatches to EDA/SHAP/TS/GeoLift/DoWhy-EconML/CausalPy/AB/Assoc or general agent/search.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>End-user question.</p> required <p>Yields:</p> Type Description <p>Streaming results produced by the selected pipeline.</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def combined_analysis(self, query):\n    \"\"\"Route a user query to the appropriate analysis pipeline and stream outputs.\n\n        Uses ``determine_query_type`` and clears previous state (non-wiki). Dispatches to\n        EDA/SHAP/TS/GeoLift/DoWhy-EconML/CausalPy/AB/Assoc or general agent/search.\n\n        Args:\n            query: End-user question.\n\n        Yields:\n            Streaming results produced by the selected pipeline.\n        \"\"\"\n    query_type = await self.determine_query_type(query)\n    print(f\"\ud83e\udde0 DEBUG: Determined Query Type \u2192 {query_type}\")\n    if query_type != \"wiki\":\n        self.checkpointer.delete_thread(self.user_id)\n    if query_type == \"dowecon\":\n        print(\"\ud83d\udd0d Running **Causal Inference Analysis With DoWhy and EconML**...\")\n        dowhy_results = self.dowhy_econml_analysis(query, self.df_raw.copy())\n        self.console.print(Markdown(dowhy_results))\n        print(\"\u2705 Analysis results saved.\")\n        yield dowhy_results\n\n    elif query_type == \"causalpy\":\n        print(\"\ud83d\udd0d Running **Bayesian CausalPy Analysis**...\")\n        causalPy_res = self.causalPy_analysis(query, self.df_raw.copy())\n        self.console.print(Markdown(causalPy_res))\n        print(\"\u2705 Analysis results saved.\")\n        yield causalPy_res\n\n    elif query_type == \"eda\":\n        print(\"\ud83d\udd0d Running **EDA Analysis**...\")\n        async for chunk in self.eda_analysis(query, self.eda_cleaned_df):\n            yield chunk\n\n    elif query_type == \"shap\":\n        print(\"\ud83d\udd0d Running **SHAP Analysis**...\")\n        async for chunk in self.shap_analysis(query, self.causal_cleaned_df):\n            yield chunk\n\n    elif query_type == \"geolift\":\n        print(\"\ud83d\udd0d Running **GeoLift Analysis**...\")\n        geo_df = self.df_raw.copy().dropna()\n        async for chunk in self.geo_analysis(query, geo_df):\n            yield chunk\n\n    elif query_type == \"analyze\":\n        print(\"\ud83d\udd0d Running **General Agent Analysis**...\")\n        async for chunk in self.analyze_agent(query):\n            yield chunk\n\n    elif query_type == \"wiki\":\n        print(\"\ud83d\udd0d Running **Wikipedia Searching**...\")\n        async for chunk in self.wiki_agent(query):\n            yield chunk\n\n    elif query_type == \"ts\":\n        print(\"\ud83d\udd0d Running **Time Series Analysis**...\")\n        async for chunk in self.ts_analysis(query, self.ts_cleaned_df):\n            yield chunk\n\n\n    elif query_type == \"ab\":\n        print(\"\ud83d\udd0d Running **A-B Testing Analysis**...\")\n        get_analysis(self.ts_cleaned_df, query)\n        async for chunk in self.ab_agent(query):\n            yield chunk\n\n    elif query_type == \"assoc\":\n        print(\"\ud83d\udd0d Running **Association Rules**...\")\n        run_assoc(self.ts_cleaned_df, query)\n        async for chunk in self.assoc_agent(query):\n            yield chunk\n    else:\n        yield \"\u274c Could not determine the analysis type. Please refine your query.\"\n</code></pre>"},{"location":"api/herakleitos/#thales.herakleitos.Herakleitos.combined_analysis_plots","title":"combined_analysis_plots  <code>async</code>","text":"<pre><code>combined_analysis_plots(query)\n</code></pre> <p>Generate visualizations when the query intent is plotting.</p> <p>Detects plotting intent, coerces datetime-like object columns, extracts target columns, forms pairwise combinations, and produces figures via <code>generate_plots</code>.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>Visualization request mentioning \u22652 columns.</p> required <p>Returns:</p> Type Description <p>A list of figure objects or saved file paths (implementation-specific).</p> Source code in <code>src/thales/herakleitos.py</code> <pre><code>async def combined_analysis_plots(self, query):\n    \"\"\"Generate visualizations when the query intent is plotting.\n\n        Detects plotting intent, coerces datetime-like object columns, extracts target\n        columns, forms pairwise combinations, and produces figures via ``generate_plots``.\n\n        Args:\n            query: Visualization request mentioning \u22652 columns.\n\n        Returns:\n            A list of figure objects or saved file paths (implementation-specific).\n        \"\"\"\n    query_type = await self.determine_query_type(query)\n    print(f\"\ud83e\udde0 DEBUG: Determined Query Type \u2192 {query_type}\")\n\n    if query_type == \"plot\":\n        print(\"\ud83d\udd0d Running **PLOT Analysis**...\")\n\n        plot_df = self.df_raw.dropna()\n        datetime_cols = []\n        for col in plot_df.select_dtypes(include=['object']).columns:\n            try:\n                converted = pd.to_datetime(plot_df[col], errors='coerce')\n                if converted.notna().sum() / len(converted) &gt; 0.7:\n                    datetime_cols.append(col)\n                    plot_df[col] = converted\n            except Exception:\n                pass\n\n        print(f\"\u2705 Identified datetime columns: {datetime_cols}\")\n        available_columns = plot_df.columns.tolist()\n        detected_columns = self.extract_columns_from_query(query, available_columns)\n\n        if len(detected_columns) &lt; 2:\n            print(\"\u274c Please specify at least two valid columns for visualization.\")\n            return\n\n        column_combinations = list(combinations(detected_columns, 2))\n        plots = self.generate_plots(plot_df, column_combinations)\n        print(\"\u2705 Plot successfully generated!\")\n        return plots\n</code></pre>"},{"location":"guides/getting-started/","title":"Getting Started","text":""},{"location":"guides/getting-started/#install","title":"Install","text":"<p>```bash pip install -e .</p>"},{"location":"guides/query-examples/","title":"Query Examples by Type","text":"<p>Use these examples as templates for forming queries in Herakleitos. Replace placeholder column names (e.g., <code>clicks</code>, <code>revenue</code>, <code>region</code>) with actual dataset columns.</p>"},{"location":"guides/query-examples/#eda-exploratory-data-analysis","title":"<code>eda</code> \u2014 Exploratory Data Analysis","text":"<ul> <li>\u201cExplore the relationship between clicks and revenue over the last 30 days.\u201d</li> <li>\u201cShow distributions and correlation between impressions and CTR.\u201d</li> <li>\u201cCompare cost vs conversions with summary stats and tests.\u201d</li> <li>\u201cRun EDA on sessions and avg_order_value.\u201d</li> </ul>"},{"location":"guides/query-examples/#analyze-agent-trends-behavior","title":"<code>analyze</code> \u2014 Agent, Trends &amp; Behavior","text":"<ul> <li>\u201cHow did revenue evolve over time? Any notable trends or spikes?\u201d</li> <li>\u201cAnalyze performance changes for CTR last month.\u201d</li> <li>\u201cWhat explains the drop in conversions last week?\u201d</li> <li>\u201cInvestigate anomalies in cost_per_acquisition.\u201d</li> </ul>"},{"location":"guides/query-examples/#shap-model-interpretability-target-detection-required","title":"<code>shap</code> \u2014 Model Interpretability (Target Detection Required)","text":"<ul> <li>\u201cExplain SHAP for CTR and identify the most important drivers.\u201d</li> <li>\u201cCompute SHAP values to interpret conversions.\u201d</li> <li>\u201cWhich features most influence revenue according to SHAP?\u201d</li> <li>\u201cProvide feature importance using SHAP for retention_rate.\u201d</li> </ul>"},{"location":"guides/query-examples/#geolift-georegional-uplift","title":"<code>geolift</code> \u2014 Geo/Regional Uplift","text":"<p><pre><code>Using spend as metric and region as location and date as date.\n</code></pre> <pre><code>Using revenue as metric and geo as location and ds as date; budget 20000 cpic 3.5 alpha 0.1 treatment start 2024-09-01 treatment duration 21.\n</code></pre> <pre><code>Using conversions as metric and city as location and date as date.\n</code></pre> <pre><code>Using sales as metric and market as location and dt as date; alpha 0.05.\n</code></pre></p>"},{"location":"guides/query-examples/#dowecon-dowhy-econml-causal-inference","title":"<code>dowecon</code> \u2014 DoWhy / EconML Causal Inference","text":"<p><pre><code>treatment=ad_spend; outcome=conversions; confounders=[seasonality, device, channel]; instrument=budget_cap; treatment_time=date; target_unit=campaign_id\n</code></pre> <pre><code>treatment=discount; outcome=revenue; confounders=[weekday, traffic]\n</code></pre> <pre><code>treatment=exposure; outcome=signup; confounders=[age, city, device]; instrument=assignment; target_unit=user_id\n</code></pre> <pre><code>treatment=promo; outcome=ctr; confounders=[geo, hour, platform]; treatment_time=ds\n</code></pre></p> <p>Tip: Keep names exactly as your columns; the pipeline will fuzzy-match but valid columns are required.</p>"},{"location":"guides/query-examples/#causalpy-synthetic-control-bayesian-sklearn","title":"<code>causalpy</code> \u2014 Synthetic Control (Bayesian &amp; Sklearn)","text":"<p><pre><code>Using revenue as outcome, analyze the causal effect with predictors [impressions, clicks, cost] at time 2024-06-15\n</code></pre> <pre><code>Using sales as outcome, analyze the causal effect with predictors [footfall, ad_spend] at time 10\n</code></pre> <pre><code>Using conversions as outcome, analyze the causal effect with predictors [sessions, ctr, cpc] at time 2023-12-01\n</code></pre> <pre><code>Using signup as outcome, analyze the causal effect with predictors [traffic, device_share] at time 25\n</code></pre></p>"},{"location":"guides/query-examples/#ts-time-series-forecasting","title":"<code>ts</code> \u2014 Time Series &amp; Forecasting","text":"<ul> <li>\u201cForecast revenue for the next 45 days.\u201d</li> <li>\u201cRun Granger causality between impressions and clicks.\u201d</li> <li>\u201cForecast conversions for Acme_Campaign for the next 30 days.\u201d</li> <li>\u201cDecompose seasonality for sessions and predict 60 days ahead.\u201d</li> </ul> <p>The horizon is parsed from phrases like \u201cnext 30 days\u201d; including a campaign name helps select a company/series.</p>"},{"location":"guides/query-examples/#wiki-knowledge-definitions","title":"<code>wiki</code> \u2014 Knowledge / Definitions","text":"<ul> <li>\u201cWhat is CTR?\u201d</li> <li>\u201cExplain Prophet in time-series forecasting.\u201d</li> <li>\u201cWhat does Granger causality mean?\u201d</li> <li>\u201cDefine SHAP values.\u201d</li> </ul>"},{"location":"guides/query-examples/#plot-visualizations-requires-2-columns","title":"<code>plot</code> \u2014 Visualizations (Requires \u22652 Columns)","text":"<ul> <li>\u201cPlot date vs revenue.\u201d</li> <li>\u201cVisualize clicks against conversions.\u201d</li> <li>\u201cCreate charts for cost, and impressions.\u201d</li> </ul> <p>The plotting pipeline auto-casts object columns to datetime if \u226570% parse; still, include a datetime column when possible.</p>"},{"location":"guides/query-examples/#ab-ab-testing","title":"<code>ab</code> \u2014 A/B Testing","text":"<ul> <li>\u201cA/B test Variant A vs Variant B on conversion_rate; is the lift significant?\u201d</li> <li>\u201cCompare control vs treatment for CTR; report p-values and effect size.\u201d</li> <li>\u201cEvaluate significance for signup_rate between A and B.\u201d</li> <li>\u201cWhich variant wins on revenue_per_user?\u201d</li> </ul>"},{"location":"guides/query-examples/#assoc-association-rules-market-basket","title":"<code>assoc</code> \u2014 Association Rules / Market Basket","text":"<ul> <li>\u201cMine association rules for product_basket (top 50 rules).\u201d</li> <li>\u201cShow frequent itemsets and rules with high lift and confidence.\u201d</li> <li>\u201cFind associations among category purchases.\u201d</li> <li>\u201cMarket basket analysis on items; summarize strongest patterns.\u201d</li> </ul>"},{"location":"guides/query-examples/#quick-guidance","title":"Quick Guidance","text":"<ul> <li>Name columns explicitly in your query (e.g., <code>date</code>, <code>revenue</code>, <code>region</code>) to help <code>extract_columns_from_query</code> and validators.  </li> <li>For GeoLift, always use: <code>Using &lt;metric&gt; as metric and &lt;location&gt; as location and &lt;date&gt; as date (+ optional budget, cpic, alpha, treatment start, treatment duration)</code>.  </li> <li>For DoWhy/EconML, use key-value pairs exactly as shown; lists use <code>[a, b, c]</code>.  </li> <li>For CausalPy, stick to: <code>Using &lt;outcome&gt; as outcome, ... predictors [a, b] at time &lt;t&gt;</code> (date or index).  </li> <li>For TS, include the horizon (\u201cnext 30 days\u201d) and, if applicable, a campaign identifier present in your data.  </li> <li>For Plot, include two valid columns.</li> </ul>"},{"location":"todo/todos/","title":"Possible Extensions for Herakleitos Project","text":""},{"location":"todo/todos/#1-time-series-forecasting-enhancements","title":"\ud83d\udd39 1. Time Series &amp; Forecasting Enhancements","text":"<ul> <li>Forecasting models (Prophet, ARIMA, NeuralProphet, AutoTS, etc.) \u2192 \u201cForecast conversions or revenue for the next 30 days.\u201d</li> <li>Anomaly Detection (residual-based, ADTK, Kats, Isolation Forest) \u2192 \u201cDetect unusual spikes in CTR.\u201d</li> <li>Change Point Detection (e.g., ruptures, Bayesian changepoint) \u2192 \u201cIdentify when trends or seasonality shifted.\u201d</li> <li>Seasonality Clustering \u2192 Group campaigns or products with similar time-series patterns.</li> </ul>"},{"location":"todo/todos/#2-nlp-semantic-analysis","title":"\ud83d\udd39 2. NLP &amp; Semantic Analysis","text":"<ul> <li>Topic Modeling / Clustering \u2192 Automatically extract themes from queries, logs, or feedback.</li> <li>Sentiment Analysis \u2192 Analyze customer reviews or campaign text for sentiment trends.</li> <li>Keyword Extraction \u2192 Detect the most relevant features or terms in text data.</li> </ul>"},{"location":"todo/todos/#3-feature-engineering-utilities","title":"\ud83d\udd39 3. Feature Engineering Utilities","text":"<ul> <li>Lagged Feature Generation \u2192 Create lag and rolling-window features for time-series models.</li> <li>Interaction Features \u2192 Automatically generate and test feature interactions.</li> <li>Outlier Detection &amp; Treatment \u2192 Identify and treat anomalies using z-score, IQR, or Isolation Forest.</li> </ul>"},{"location":"todo/todos/#4-model-monitoring-explainability","title":"\ud83d\udd39 4. Model Monitoring &amp; Explainability","text":"<ul> <li>Drift Detection \u2192 Monitor distribution shifts between training and live data.</li> <li>Counterfactual Explanations (e.g., Alibi, DiCE) \u2192 \u201cWhat if ad spend increased by 20%?\u201d</li> <li>Global vs Local Explainability Dashboards \u2192 SHAP + PDP (Partial Dependence Plots) + ICE (Individual Conditional Expectation).</li> </ul>"},{"location":"todo/todos/#5-causal-inference-extensions","title":"\ud83d\udd39 5. Causal Inference Extensions","text":"<ul> <li>Heterogeneous Treatment Effect (HTE) Estimation \u2192 \u201cWhich customer segments benefit more from treatment?\u201d</li> <li>Meta-Learners (T-Learner, S-Learner, X-Learner) wrappers for treatment effect modeling.</li> <li>Sensitivity Analysis \u2192 Evaluate robustness of causal inference to hidden confounders.</li> </ul>"},{"location":"todo/todos/#6-cross-agent-pipelines","title":"\ud83d\udd39 6. Cross-Agent Pipelines","text":"<ul> <li>Hybrid Analysis \u2192 Chain EDA \u2192 SHAP \u2192 Causal analysis in one query.</li> <li>Recommendation Agent \u2192 Synthesize EDA, A/B testing, and causal results into actionable next steps.</li> </ul>"},{"location":"todo/todos/#7-visualization-dashboards","title":"\ud83d\udd39 7. Visualization &amp; Dashboards","text":"<ul> <li>Interactive Dashboards with Plotly / Altair / Streamlit.</li> <li>Automated EDA Reports (via ydata-profiling or sweetviz) for dataset summaries.</li> <li>Custom Visualization Agent \u2192 Generate plots based on query intent (histograms, scatterplots, causal graphs).</li> </ul>"},{"location":"todo/todos/#8-data-source-integrations","title":"\ud83d\udd39 8. Data Source Integrations","text":"<ul> <li>SQL Connectors (Postgres, BigQuery, Snowflake) \u2192 Query data directly from databases.</li> <li>Ad Platform APIs (Google Ads, Meta Ads) \u2192 Pull campaign data for real-time analysis.</li> <li>Cloud Storage Connectors (S3, GCS, Azure Blob) \u2192 Load files seamlessly.</li> </ul> <ul> <li>Short-term: Anomaly Detection + Change Point Detection \u2192 strong value for monitoring.  </li> <li>Medium-term: HTE estimation + drift detection \u2192 makes it a true production-grade analytics toolkit.  </li> <li>Long-term: Interactive dashboards + connectors \u2192 positions the project as a versatile analytics product.</li> </ul>"}]}